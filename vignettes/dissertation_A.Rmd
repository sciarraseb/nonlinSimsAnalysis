---
shorttitle        : "Measurement timing"
format          : "pandoc"
header-includes:
  - \usepackage{nccmath}
  - \usepackage{caption}
  - \usepackage{textcomp} #for copyright symbol on title page
  - \usepackage{longtable}
  - \usepackage{setspace}
  - \usepackage{booktabs}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
  - \usepackage{amsthm} 
  - \usepackage{amsmath} ##needed for argmax
  - \DeclareMathOperator*{\argmax}{arg\,max}
  - \usepackage{setspace} #needed to doublespace caption text (using \doublespacing)
  - \usepackage[labelfont = {bf, up}]{caption} 
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \usepackage{upgreek}  #required for non-italicized Greek letters
  - \usepackage{subcaption}
  - \captionsetup[figure]{labelfont={normalfont, bf}, singlelinecheck=false, labelsep=newline}
  - \DeclareCaptionJustification{double}{\DoubleSpacing}
  - \DeclareCaptionFont{figCaptionFont}{\fontfamily{phv}} #sets caption font to sans serif font of Helvetica 
  - \DeclareCaptionFont{figCaptionSize}{\footnotesize} #set caption font size to footnote 
  - \DeclareCaptionFont{figCaptionStyle}{\textup}  #set caption font to non-italicized font  
  - \DeclareCaptionLabelSeparator{captionSep}{\newline\newline} #separates figure label and figure title with required white space
  - \captionsetup[figure]{labelfont={figCaptionStyle, bf}, font = {figCaptionFont,figCaptionSize, figCaptionStyle}, labelsep = captionSep, justification=raggedright}
  - \captionsetup[table]{font = {figCaptionFont,figCaptionSize,figCaptionStyle}, labelfont={bf}, labelsep=captionSep, justification = raggedright, margin = {0cm,0cm}}
  - \newenvironment{helvenv}{\fontfamily{phv}\selectfont}{}
  - \raggedbottom #ensures text starts from top of page and any white space is at the botom

#environment numbering 
  - \setcounter{section}{0} 
  - \makeatletter \renewcommand\thesection{} \renewcommand\thesubsection{\@arabic\c@section.\@arabic\c@subsection} \makeatother
  
  - \newtheorem{theorem}{Theorem}
  - \newtheorem{example}[theorem]{Example}
  
  #modifies heading levels of 4-5 to follow apa7
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

  
author: 
  - name          : "Sebastian Sciarra "
    affiliation   : "1"
    corresponding : yes    
    email         : "ssciarra@uoguelph.ca"
affiliation: 
  - id            : "1"
    institution   : "University of Guelph"
keywords          : "measurement timing, nonlinear "
wordcount         : "5554 words"
floatsintext      : yes
linkcolor         : blue
figsintext        : yes 
figurelist        : no
tablelist         : no
footnotelist      : no
numbersections    : yes
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa7"
csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  markdown: 
    wrap: 72
bibliography: dissertation_references.bib
---

```{r package_loading, include=F}
#install_github(repo = 'sciarraseb/nonlinSims')
#load packages
library(easypackages)
packages <- c('devtools','tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'nonlinSims','papaja', 
              'ggbrace', 'cowplot')
libraries(packages)
load_all()
```

```{r knitting_setup, echo=F, include=F}
#import raw data files (needed for computing variances)
exp_1_raw <-convert_raw_var_to_sd(raw_data = read_csv('Data/exp_1_zero.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)
  
exp_2_raw <-convert_raw_var_to_sd(raw_data = read_csv('Data/exp_2_zero.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "sample_size"), factor)

exp_3_raw <-convert_raw_var_to_sd(raw_data = read_csv('Data/exp_3_zero.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)


#unfiltered data 
param_summary_exp_1 <- readRDS(file = 'data/uf_param_summary_exp_1.RData')
param_summary_exp_2 <- readRDS(file = 'data/uf_param_summary_exp_2.RData')
param_summary_exp_3 <- readRDS(file = 'data/uf_param_summary_exp_3.RData')

#create analytical versions of summary data 
exp_1_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1, exp_num = 1)
exp_2_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_2, exp_num = 2)
exp_3_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3, exp_num = 3)

#create condition summary data sets 
cond_summary_exp_1 <- compute_condition_summary(param_summary_data = param_summary_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))
cond_summary_exp_2 <- compute_condition_summary(param_summary_data = param_summary_exp_2, facet_var = 'measurement_spacing', 
                  ind_vars = c('number_measurements', 'measurement_spacing', 'sample_size'))
cond_summary_exp_3 <- compute_condition_summary(param_summary_data = param_summary_exp_3, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))
```

```{r pre_knitting_setup, echo=F, eval=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_zero.csv')  
exp_2 <- read_csv(file = 'data/exp_2.csv')
exp_3 <- read_csv(file = 'data/exp_3.csv')

#data cleaning procedure for each data set
#filter out values for each parameter in each condition 
exp_1_filtered <- remove_outliers(data = exp_1)
exp_2_filtered <- remove_outliers(data = exp_2)
exp_3_filtered <- remove_outliers(data = exp_3)
  
#convert variance values to SD values for random effect parameters 
exp_1_cleaned <- convert_var_to_sd(param_summary_datadata = exp_1_filtered)
exp_2_cleaned <- convert_var_to_sd(data = exp_2_filtered)
exp_3_cleaned <- convert_var_to_sd(data = exp_3_filtered)

#compute summary values 
param_summary_exp_1 <- compute_parameter_summary(data = exp_1_cleaned, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2_cleaned, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3_cleaned, exp_num = 3)

#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_2, file = 'data/param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/param_summary_exp_3.RData')
```

```{r obsolete_metadata_storing_importing, eval=F, include=F}
##store classes of each column 
col_types_exp_1 <- unlist(lapply(X = param_summary_exp_1, FUN = class))
col_types_exp_2 <- unlist(lapply(X = param_summary_exp_2, FUN = class))
col_types_exp_3 <- unlist(lapply(X = param_summary_exp_3, FUN = class))

#create data.frame that stores classes of data columns 
col_types_df <- data.frame('exp_num' = c(rep(x = 1, times = length(col_types_exp_1)),
                                         rep(x = 2, times = length(col_types_exp_2)),
                                         rep(x = 3, times = length(col_types_exp_3))), 
                           'variable_types' = c(col_types_exp_1, col_types_exp_2, col_types_exp_3))

#create data fame that stores levels of factor variables 
exp_1_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_1)
exp_2_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_2)
exp_3_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_3)

##store classes of each column 
col_types_exp_1 <- unlist(lapply(X = param_summary_exp_1, FUN = class))
col_types_exp_2 <- unlist(lapply(X = param_summary_exp_2, FUN = class))
col_types_exp_3 <- unlist(lapply(X = param_summary_exp_3, FUN = class))

#create data.frame that stores classes of data columns 
col_types_df <- data.frame('exp_num' = c(rep(x = 1, times = length(col_types_exp_1)),
                                         rep(x = 2, times = length(col_types_exp_2)),
                                         rep(x = 3, times = length(col_types_exp_3))), 
                           'variable_types' = c(col_types_exp_1, col_types_exp_2, col_types_exp_3))

#create data fame that stores levels of factor variables 
exp_1_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_1)
exp_2_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_2)
exp_3_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_3)

#write meta data + data for factor levels 
write_csv(x = col_types_df, file = 'data/col_types.csv')
write_csv(x = exp_1_factor_levels, file = 'data/exp_1_factor_levels.csv')
write_csv(x = exp_2_factor_levels, file = 'data/exp_2_factor_levels.csv')
write_csv(x = exp_3_factor_levels, file = 'data/exp_3_factor_levels.csv')

#read in .csv files with experimental data already in summarized version 
col_types_df <-read_csv(file = 'data/col_types.csv')
exp_1_factor_levels <- read_csv(file = 'data/exp_1_factor_levels.csv')
exp_2_factor_levels <- read_csv(file = 'data/exp_2_factor_levels.csv')
exp_3_factor_levels <- read_csv(file = 'data/exp_3_factor_levels.csv')

#relevel factors columns 
param_summary_exp_1 <- relevel_factors(param_summary_data = param_summary_exp_1, factor_levels_df = exp_1_factor_levels)
param_summary_exp_2 <- relevel_factors(param_summary_data = param_summary_exp_2, factor_levels_df = exp_2_factor_levels)
param_summary_exp_3 <- relevel_factors(param_summary_data = param_summary_exp_3, factor_levels_df = exp_3_factor_levels)
```

```{r pre_knitting_setup_unfiltered, echo=F, eval=F, include=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_zero.csv')
exp_2 <- read_csv(file = 'data/exp_2_zero.csv')
exp_3 <- read_csv(file = 'data/exp_3_zero.csv')

#compute parameter summary statistics  
param_summary_exp_1 <- compute_parameter_summary(data = exp_1, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3, exp_num = 3)

#necessary factor conversions 
param_summary_exp_1$number_measurements <- factor(param_summary_exp_1$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_1$midpoint <- factor(param_summary_exp_1$midpoint, levels = c(80, 180,280))

param_summary_exp_2$number_measurements <- factor(param_summary_exp_2$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_2$sample_size <- factor(param_summary_exp_2$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

param_summary_exp_3$number_measurements <- factor(param_summary_exp_3$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_3$sample_size <- factor(param_summary_exp_3$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/uf_param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_2, file = 'data/uf_param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/uf_param_summary_exp_3.RData')
```

```{=tex}
\begin{titlepage}
  \begin{center}
    \vspace*{3cm}
    
  \textbf{Is Timing Everything? Measurement Timing and the Ability to Sccurately Model Longitudinal Data}
    
  \vspace{2cm} 
    by \\ Sebastian Sciarra 
    
      
  \vspace{2cm} 
   In partial fulfilment of requirements \\ 
   for the degree of \\
   Doctor of Philosophy \\ 
   in \\ 
   Psychology
    

  \vspace{2cm} 
    Guelph, Ontario, Canada \\ 
    \textcopyright \text{ Sebastian Sciarra, September 2022}

  
  \end{center}
\end{titlepage}
```

```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```

```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```



```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```

# Methods

```{=tex}
\nointerlineskip
\vfill
\newpage
```

## Overview of Variables Used in Simulations

### Independent Variables

Because my simulation experiments built on @coulombe2016, the
independent variables manipulations I used largely mirrored the
independent variable manipulations from @coulombe2016. As a reference,
Table \ref{tab:coulombe2016} lists the levels used for the independent
variables in @coulombe2016. One last point to mention is that the
independent variable manipulations were computed in the context of a
360-day period since many organizational processes are governed by
annual events (e.g., performance reviews, annual returns, regulatory
processes, etc.). Table \ref{tab:myValues} lists the levels used for
the independent variables in my simulations experiments.

(ref:coulombe2016) @coulombe2016

```{r coulombe2016, echo=F}

coulombe_df <- data.frame('Independent variable' = c('Number of measurements (NM)', 'Time structuredness (TS)', 'Sample size (S)'), 
                          'Levels' = c('3, 5, 7, 9', '0.4, 1 (response window length)', '30, 50, 100, 200, 500'), check.names = F)

kbl(x = coulombe_df, booktabs = TRUE, format = 'latex', longtable = T, 
      align = c('l', 'c'),
      caption = 'Levels Used for Independent Variables in (ref:coulombe2016)', 
    escape=F) %>%
   kable_styling(latex_options= c('hold_position'), font_size = 10, position =
                   'left')
```

```{r myValues, echo=F}
 myValues_df <- data.frame('Independent variabe' = c('Number of measurements (NM)', 'Time structuredness (TS)', 'Sample size (S)', 'Measurement spacing (MS)', 'Pattern of change (population value set for the fixed-effect days-to-halfway elevation parameter [$\\upbeta_{fixed}$])'), 
                          'Levels' = c('5, 7, 9, and 11', 
                                       'Time structured, fast response rate ($a_{fast}$ = 0.37), and slow response rate ($a_{slow}$ = 0.15)', 
                                       '30, 50, 100, 200, 500, and 1000', 
                                       'Equal, time-interval increasing, time-interval decreasing, middle-and-extreme', 
                                       '80, 180, and 280 days'), check.names = F)

kbl(x = myValues_df, booktabs = TRUE, format = 'latex', longtable = T, 
      align = c('l', 'l'),
      caption = 'Levels Used for Independent Variables in my Simulations', 
    escape=F) %>%
  column_spec(column = 1, width = '6cm') %>%
  column_spec(column = 2, width = '10cm') %>%
   kable_styling(latex_options= c('hold_position', 'repeat_header'), font_size = 10, position = 'left')
```

#### Sample Size

Sample size values were borrowed from @coulombe2016 with one difference.
Because my experiments investigated the effects of measurement timing
factors on the ability to model nonlinear patterns, which are inherently
more complex than linear patterns of change, a sample size value of *n*
= 1000 was added as the largest sample size. Therefore, the following
values were used for my sample size manipulation: 30, 50, 100, 200, 500,
and 1000 (see Table \ref{tab:myValues}). Importantly, in experiments where
sample size was not manipulated (i.e., Experiment 1), the sample size
value used corresponded to the average sample size used in
organizational research [*n* = 225\; @bosco2015].

#### Number of Measurements

(ref:loehlin2017) [@loehlin2017]

The exact set of values used by @coulombe2016 for the number of
measurements could not be used in my simulations because doing so would
have created non-identified models. Specifically, the smallest value
used for the number of measurements in @coulombe2016 of 3 measurements
could not be used in my simulations because it would not have provided
sufficient degrees of freedom for estimating the nonlinear latent growth
curve model in my simulations. The model used in my simulations
estimated 9 parameters (*p* = 9; 4 fixed-effects + 4 random-effects + 1
error) and so the minimum number of measurements (or observed variables)
required for model identification (and to allow model comparison) would
was 4.\footnote{Degrees of freedom is
calculated by multiplying the number of observed variables (\textit{p})
by \textit{p} + 1 and dividing it by 2 (\textit{p}[{\textit{p} +
1}]/2; see (ref:loehlin2017)}Because my proposed simulation experiments
were intended to map onto the manipulations used by @coulombe2016, the
second-smallest value used for the number of measurements in
@coulombe2016 was 5 (see Table \ref{tab:coulombe2016}), and so my
simulations used 5 measurements as the smallest measurement number
value. Importantly, a larger value of 11 was added to test for a
possible effect of a high measurement number. Therefore, my simulation
experiments used the following values in manipulating the number of
measurements: 5, 7, 9, and 11 (see Table \ref{tab:myValues}).

#### Spacing of Measurements

The only study to manipulate measurement spacing (to my knowledge) was
@timmons2015. Measurement spacing in @timmons2015 was manipulated in the
following four ways:

1)  **Equal spacing**: measurements were divided by intervals of
    equivalent lengths.
    
2)  **Time-interval increasing spacing**: intervals that divided measurements
    increased in length over time.

3)  **Time-interval decreasing spacing**: intervals that divided measurements
    decreased in length over time.

4)  **Middle-and-extreme spacing**: measurements were clustered near the
    beginning, middle, and end of the data collection period.

\noindent To maintain consistency with the established literature, my
experiments manipulated measurement spacing in the same way as
@timmons2015 presented above. (Note that I developed a procedure for generating measurement schedules for each of the four measurement spacing conditions in [Appendix A][Appendix A: Procedure for generating measurement schedules in measurement spacing conditions]). 

Table \@ref(tab:measurementDays) lists the measurement days that will be
used for all measurement spacing-measurement number cells. The first
column lists the type of measurement spacing (i.e., equal, time-interval
increasing, time-interval decreasing, or middle-and-extreme); the second
column lists the number of measurements (5, 7, 9, or 11); the third
column lists the measurement days that correspond to each measurement
number-measurement spacing condition; and the fourth column lists the
interval lengths that characterize each set of measurements. Note that
the interval lengths are equal for the equal spacing, increase over time
for the time-interval increasing spacing, and decrease over time for the
time-interval decreasing spacing, For cells with middle-and-extreme
spacing, the measurement days and and interval lengths corresponding to
the middle of the measurement window have been emboldened.

```{r measurementDays, echo=F}
time_period <- 360
num_measurements <- seq(from = 5, to = 11, by = 2)
smallest_int_length <- 30

#meausurement days 
equal_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_9 <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_11 <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'equal')$measurement_days

time_inc_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days
time_inc_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days
time_inc_9 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days, 2)
time_inc_11 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days, 2)

time_dec_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days
time_dec_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days
time_dec_9 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days, 2)
time_dec_11 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days, 2)

mid_ext_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_9 <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_11 <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days


#measurement intervals
equal_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_9_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_11_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'equal')$interval_lengths

time_inc_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths
time_inc_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths
time_inc_9_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths, 2)
time_inc_11_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths, 2)

time_dec_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths
time_dec_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths
time_dec_9_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths, 2)
time_dec_11_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths, 2)

mid_ext_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_9_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_11_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths


measurement_days_df <- data.frame('Measurement spacing' = c('Equal', '', '', '', 
                                                            'Time-interval increasing', '', '', '', 
                                                            'Time-interval decreasing', '', '', '', 
                                                            'Middle-and-extreme', '', '', ''), 
                                  'Number of measurements' = rep(num_measurements, times = 4), 
                                  'Measurement days' = c(paste(equal_5, collapse = ', '), 
                                                         paste(equal_7, collapse = ', '), 
                                                         paste(equal_9, collapse = ', '), 
                                                         paste(equal_11, collapse = ', '), 
                                                         
                                                         paste(time_inc_5, collapse = ', '),
                                                         paste(time_inc_7, collapse = ', '),
                                                         paste(time_inc_9, collapse = ', '),
                                                         paste(time_inc_11, collapse = ', '),
                                                         
                                                         paste(time_dec_5, collapse = ', '),
                                                         paste(time_dec_7, collapse = ', '),
                                                         paste(time_dec_9, collapse = ', '),
                                                         paste(time_dec_11, collapse = ', '),
                                                         
                                                        '1, \\textbf{150, 180, 210}, 360',
                                                        '1, 30, \\textbf{150, 180, 210}, 330, 360',
                                                        '1, 30, 60, \\textbf{150, 180, 210}, 300, 330, 360',
                                                        '1, 30, 60, \\textbf{120, 150, 180, 210, 240,} 300, 330, 360'), 
                                  
                                  'Interval lengths' = c(paste(equal_5_int, collapse = ', '), 
                                                         paste(equal_7_int, collapse = ', '), 
                                                         paste(equal_9_int, collapse = ', '), 
                                                         paste(equal_11_int, collapse = ', '), 
                                                         
                                                         paste(time_inc_5_int, collapse = ', '),
                                                         paste(time_inc_7_int, collapse = ', '),
                                                         paste(time_inc_9_int, collapse = ', '),
                                                         paste(time_inc_11_int, collapse = ', '),
                                                         
                                                         paste(time_dec_5_int, collapse = ', '),
                                                         paste(time_dec_7_int, collapse = ', '),
                                                         paste(time_dec_9_int, collapse = ', '),
                                                         paste(time_dec_11_int, collapse = ', '),
                                                         
                                                        '150, \\textbf{30, 30}, 150',
                                                         '30, 120, \\textbf{30, 30}, 120, 30',
                                                         '30, 30, 90, \\textbf{30, 30}, 90, 30, 30',
                                                         '30, 30, 60, \\textbf{30, 30, 30, 30}, 60, 30, 30'),
                                  check.names = F)

kbl(x = measurement_days_df, booktabs = TRUE, format = 'latex', longtable = T, 
      align = c('l', 'l'), 
    linesep = c(rep('', times = 3),
            '\\cmidrule{1-4}\\addlinespace'), 
      caption = 'Measurement Days Used for All Measurement Number-Measurement Spacing Conditions ', 
    escape=F) %>%
   kable_styling(latex_options= c('hold_position'), font_size = 10, position = 'left') %>%  
    footnote(general =  "For conditions with middle-and-extreme spacing, the measurement days and and interval lengths corresponding to the middle of the measurement window have been emboldened.",  threeparttable = T,  escape = F, general_title = '\\\\textit{Note.}\\\\hspace{-1.25pc}')%>%
  landscape(margin = '1cm')

```

#### Time Structuredness {#sec:time-structuredness}

(ref:coulombe2016f) [@coulombe2016]

The manipulation of time structuredness was adopted from the
manipulation used in @coulombe2016 with a slight modification. In
@coulombe2016, time-unstructured data were generated according to an
exponential pattern such that most data were obtained at the beginning
of the response window, with a smaller amount of data being obtained
towards the end of the response window. Importantly, @coulombe2016
employed a non-continuous function for generating time-unstructured
data: A binning method was employed such that 80% of the data were
obtained within a time period equivalent to 12% (fast response rate) or
30% (slow response rate) of the entire response window. Using a response
window length of 10 days with a fast response rate, the procedure
employed by @coulombe2016 for generating time-unstructured data would
have generated the following percentages of data in each of the four bins [note that, using the data generation procedure for @coulombe2016, the effective response window length was 4 days instead of 10 days]\footnote{The data generation procedure in (ref:coulombe2016) for a fast response rate assumed that all of the data were
collected within the initial 40\% length of the nominal response window length (4 days
in the current example).}:

1)  Bin 1: 60% of the data would be generated in the initial 10% length
    of the response window (0--0.4 day).
2)  Bin 2: 20% of the data would be generated in the next 20% length of
    the response response window (0.4--1.2 days).
3)  Bin 3: 10% of the data would be generated in the next 30% length of
    the response window (1.2--2.4 days).
4)  Bin 4: the remaining 10% of the data would be generated in the
    remaining 40% length of the response window (2.4--4 days).

\noindent Note that, summing the data percentages and time durations
from the first two bins yields an 80% cumulative response rate that is
obtained in the initial 12% length of the full-length response window of 10 days (i.e., $(\frac{1.2}{10})*100\% = 12\%$). Also note
that, in @coulombe2016, a data point in each bin was randomly assigned a
measurement time within the bin's time range. In the current example
where the full-length response window had a length of 10 days, a data point obtained
in the first bin would be randomly assigned a measurement time between
0--0.4).

Although @coulombe2016 generated time-unstructured data to
resemble data collection conditions---response rates have been shown to
follow an exponential pattern [@pan2010; @dillman2014]---the use of a
pseudo-continuous binning function for generating time-unstructured data
lacked ecological validity. Therefore, the simulations here used a
continuous function to create more realistic versions of
time-unstructured data. Specifically, the exponential function shown
below in Equation \@ref(eq:exponential) was used:
\useshortskip
```{=tex}
\begin{align}
  y =  M(1 - e^{-ax})
  (\#eq:exponential)
\end{align}
```
\useshortskip
\noindent  where $x$ stores the time delay for a measurement at a particular time point, $y$ represents the cumulative response percentage achieved at a given $x$ time delay, $a$ sets the rate of growth of the cumulative response percentage over time, and $M$ sets the range of possible $y$ values. Two important points need to be made with respect to the $M$ parameter (range of possible $y$ values) and the response window length used in
the current simulations. First, because the range of possible values for the
cumulative response percentage ($y$) is 0--1 (data can be collected from a 0% to a maximum of 100% of respondents; $\{y: 0 \le y \le 1 \}$), the $M$
parameter had a value of 1 ($M = 1$). Second, the response window length
in the current simulations was 36 days, and so the range of possible time delay values was between 0--36 ($\{x: 0 \le x \le 36 \}$).\footnote{A value of 36 days was used because the generation of time-unstructured data had to remain independent of the manipulation of measurement number (i.e., the response window lengths used in generating time-unstructured data could not vary with the number of measurements). To ensure the manipulations of measurement number and time structuredness remained independent, the reponse window length had to remain constant for all measurement number conditions with equal spacing. Looking at Table @ref(tab:measurementDays), the longest possible response window that fit within all measurement number conditions with equal spacing was the interval length of the 11-measurement condition (i.e., 36 days).}

To replicate the time structuredness manipulation in @coulombe2016 using the continuous exponential function of Equation \@ref(eq:exponential),  the growth rate parameter ($a$) had to be calibrated to achieve a cumulative
response rate of 80% after either 12% or 30% of the response window
length of 36 days. The derivation below solves for $a$, with Equation
\ref{eq:growth-rate} showing the equation for $a$.

```{=tex}
\begin{align} 
y &= M(1 - e^{-ax}) \nonumber \\
y &= M - Me^{-ax} \nonumber \\
y &= 1 - e^{-ax} \nonumber \\
e^{-ax} &=  1 -y \nonumber \\ 
-ax\log(e) &= \log(1 - y) \nonumber \\ 
a &= \frac{\log(1 - y)}{-x} 
  (\#eq:growth-rate)
\end{align}
```

\noindent Because the target response rate was 80%, $y$ took on a value
of .80 ($y = .80$). Given that the response window length in the current
simulations was 36 days, $x$ took on a value of 4.32 (12% of 36) when
time-unstructured data were defined by a fast response rate and 10.80
(30% of 36) when time-unstructured data were defined by a slow response
rate. Using Equation \ref{eq:growth-rate} yielded the following growth
rate parameter values for fast and slow response rates ($a_{fast}$,
$a_{slow}$):

```{=tex}
\begin{align}
a_{fast} &= \frac{\log(1 - .80)}{-4.32} = 0.37 \nonumber \\ 
a_{slow} &= \frac{\log(1 - .80)}{-10.80} = 0.15 
\end{align}
```

\noindent Therefore, to obtain 80% of the data with a fast response rate
(i.e., in 4.32 days), the growth parameter ($a$) needed to have a value
of 0.37 ($a_{fast} = 0.37$) and, to obtain 80% of the data with a slow
response rate (i.e., in 10.80 days), the growth parameter ($a$) needed
to have a value of 0.15 ($a_{slow} = 0.15$). Using the above growth rate
values derived for the fast and slow response growth rate parameters
($a_{fast}$, $a_{slow}$), the following functions were generated for
fast and slow response rates:

```{=tex}
\begin{align}
  f_{fast}(x) =  M(1 - e^{a_{fast}x}) = M(1 - e^{-0.37x}) and 
  (\#eq:fast-cdf)
\end{align}
```
```{=tex}
\begin{align}
  f_{slow}(x)  =  M(1 - e^{-a_{slow}x}) =  M(1 - e^{-0.15x}). 
  (\#eq:slow-cdf)
\end{align}
```
\noindent Using Equations \ref{eq:fast-cdf}--\ref{eq:slow-cdf}, Figure
\ref{fig:cdf_plots} shows the resulting cumulative distribution
functions (CDF) for time-unstructured data that show the cumulative
response percentage as a function of time. Panel A shows the cumulative
distribution function for a fast response rate (Equation
\ref{eq:fast-cdf}), where an 80% response rate was obtained in 4.32
days. Panel B shows the cumulative distribution function for a slow
response rate (Equation \ref{eq:slow-cdf}), where an 80% response rate
was obtained in 10.80 days.

```{r cdf-response-rate, include=F, eval=F}

#1) Generate CDFs
day <- seq(from = 0, to = 36, by = 0.01)
M <- 1
satiation_value <- 0.8
satiation_point_fast <- 4.32
satiation_point_slow <- 10.80

a_fast <- log(1 - satiation_value)/-satiation_point_fast
a_slow <- log(1 - satiation_value)/-satiation_point_slow

#y data
y_fast <- M*(1 - exp(-a_fast*day))
y_slow <- M*(1 - exp(-a_slow*day))

cdf_data <- data.frame('response_rate' = factor(c(rep('fast', times = length(y_fast)), 
                                           rep('slow', times = length(y_slow)))), 
                       'day' = rep(day, times = 2), 
                       'cumulative_response' = c(y_fast, y_slow))

cdf_data$response_rate <- factor(cdf_data$response_rate, 
                                 labels = c(bquote(expr = "bold(A:~CDF~(Fast~response~rate))"),
                                            bquote(expr =  "bold(B:~CDF~(Slow~response~rate))")))
                       
v_line_data <- data.frame(
  response_rate =c("bold(A:~CDF~(Fast~response~rate))", "bold(B:~CDF~(Slow~response~rate))"), 
  x = c(4.32, 10.80), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0, 0))

h_line_data <- data.frame(
  response_rate = c("bold(A:~CDF~(Fast~response~rate))", "bold(B:~CDF~(Slow~response~rate))"), 
  x = c(0, 0), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0.8, 0.8))

cdf_plots <- ggplot(cdf_data, aes(x = day, y = cumulative_response)) + 
  geom_line(size = 3) + 
  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.80, 1.00)) +
  theme_classic(base_family = 'Helvetica') + 
  #facet_wrap(facets = ~ response_rate, scales = 'free', labeller = label_parsed) + 
  facet_wrap_custom( ~ response_rate, scales = "free", ncol = 2, nrow = 1 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(
                                          scale_override(1,
                                            scale_x_continuous(
                                              breaks = c(0, 4.32, 18, 24, 36),
                                              limits = c(0, 36))), 
                                          scale_override(2,
                                            scale_x_continuous(
                                              breaks = c(0, 10.80, 18, 24, 36),
                                              limits = c(0, 36))))) +  #vertical lines 
  geom_segment(data = v_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 2) + 
  geom_segment(data = h_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 2) + 

  labs(y = 'Cumulative response percentage', x = 'Response window day') + 
  
  theme(strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),

              #axis details
      axis.text = element_text(size = 50, color = 'black'),
      axis.title = element_text(size = 70),
      #axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'), 
        strip.background = element_rect(fill = "white", color = "white"), 
        strip.text = element_text(hjust = 0, size = 16))


#create PDF of faceted plot
set_panel_size(p = cdf_plots, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/cdf_plots.pdf')

```

```{=tex}
\begin{figure}
  \caption{Cumulative Distribution Functions (CDF) With Fast and Slow Response Rates}
  \label{fig:cdf_plots}
  \includegraphics{Figures/cdf_plots}
  \caption*{Note. \textup{Panel A shows the cumulative distribution function for a fast response rate (Equation \ref{eq:fast-cdf}), where an 80\% response rate is obtained in 4.32 days.  Panel B shows the cumulative distribution function for a slow response rate (Equation \ref{eq:slow-cdf}), where an 80\% response rate is obtained in 10.80 days.}}
\end{figure}
```

#### Population Values Set for The Fixed-Effect Days-to-Halfway Elevation Parameter $\upbeta_{fixed}$ (pattern of change)

In the proposed set of simulations where change will follow a logistic function, the pattern of change will be manipulated by setting the days-to-halfway elevation parameter ($\upbeta_{fixed}$) to a value of either 80, 180, or 280 days (see
Table \ref{tab:myValues} and Figure \ref{fig:combined_plot}A). 

### Dependent Variables

#### Convergence Success Rate

The proportion of iterations in a cell where models converged defined
the **convergence success rate**.\footnote{ Specifically, convergence was obtained if the convergence code returned by OpenMx was 0.}.
Equation \@ref(eq:convergence) below shows the calculation used to
compute teh convergence success rate: :

```{=tex}
\begin{align}
  \text{Convergence success rate} =  \frac{\text{Number of models that successfully converged}}{n},
  (\#eq:convergence) 
\end{align}
```
\noindent where *n* represents the cell size.

#### Bias

Bias was calculated to evaluate the accuracy with which each logistic
function parameter was estimated. As shown below in Equation
\@ref(eq:bias), **bias** was obtained by calculating the difference
between the population value set for a parameter and the average
estimated value in each cell.

\useshortskip

```{=tex}
\begin{align}
  \text{Bias} =  \text{Population value for parameter} - \text{Average estimated value}
  (\#eq:bias) 
\end{align}
```
## Overview of Data Generation and Analysis

### Data Generation

Data for each simulation experiment were generated using R [@rstudio].
To generate the data, the **multilevel logistic function** shown below
in Equation \@ref(eq:logFunction-generation) was used:

```{=tex}
\begin{align}
  y_{ij} = \uptheta_j + \frac{\upalpha_j - \uptheta_j}{{1 + e^\frac{\upbeta_j - time_i}{\upgamma_j}}} + \upepsilon_{ij}, 
(\#eq:logFunction-generation)
\end{align}
```

\noindent where $\uptheta$ represents the baseline parameter, $\upalpha$
represents the maximal elevation parameter, $\upbeta$ represents the
days-to-halfway elevation parameter, and $\upgamma$ represents
triquarter-halfway delta parameter. Note that, values for $\uptheta$,
$\upalpha$, $\upbeta$, and $\upgamma$ were generated for each *j* person
across all *i* time points, with an error value being randomly generated
at each *i* time point($\upepsilon_{ij}$). In other words, unique
response patterns were generated for each person in each of the 1000
data sets generated per cell.

(ref:borenstein2009) @borenstein2009

Figure \ref{fig:combined_plot}A shows that the baseline parameter
($\uptheta$) sets the starting value of the curve, which in the current
example has a value of 3.00 ($\uptheta$ = 3.00). Figure
\ref{fig:combined_plot}B shows that the maximal elevation parameter
($\upalpha$) sets the ending value of the curve, which in the current
example has a value of 3.32 ($\upalpha$ = 3.32). Note that a difference
of 0.32 was selected to represent the average effect size in
organizational research [@bosco2015].
\footnote{The average effect size in organizational research is $r = .16$. Using the formula for converting correlation coefficients to Cohen's $\mathit{d}$ values, a value of $r = .16$ corresponds to Cohen's $\mathit{d}$ = 0.32 ((ref:borenstein2009)).}
Figure \ref{fig:combined_plot}C shows that the days-to-halfway elevation
parameter ($\upbeta$) sets the number of days needed to reach 50% of the
difference between the baseline and maximal elevation. In the current
example, the baseline-maximal elevation difference is 0.32
($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32), and so the days-to-halfway
elevation parameter defines the number of days needed to reach a value
of 3.16. Given that the days-to-halfway elevation parameter is set to
180 in the current example ($\upbeta = 180$), then 180 days are needed
to go from a value of 3.00 to a value of 3.16. Figure
\ref{fig:combined_plot}D shows that the halfway-triquarter delta
parameter ($\upgamma$) sets the number of days needed to go from halfway
elevation to approximately 73% of the baseline-maximal elevation
difference of 0.32. Given that 73% of the baseline-maximal elevation
difference is 0.23 and the halfway-triquarter delta is set to 40 days
($\upgamma = 40$), then 40 days are needed to go from the halfway point
of 3.16 to the triquarter point of approximately 3.23.

```{r logistic-interpretation-plot, eval=F, include=F}
#setup variables for logistic curve 
time <- seq(from = 1, to = 360, by = 1)
theta <- 3
alpha <- 3.32
beta <- 180
gamma <- 40

logistic_data <- data.frame('day' = time, 
                            'curve_score' = theta + (alpha - theta)/(1 + exp((beta - time)/gamma))) 

#make first and last values exactly equal to theta and alpha 
logistic_data$curve_score[c(1, 360)] <- c(theta, alpha)

baseline <- logistic_data$curve_score[logistic_data$day == 1]
halfway_value <- logistic_data$curve_score[logistic_data$day == beta]
triquarter_value <- logistic_data$curve_score[logistic_data$day == beta + gamma]
maximal_elevation <- logistic_data$curve_score[logistic_data$day == 360]

#df for points 
point_df <- data.frame('day' = c(1, beta, beta+gamma, 360), 
                       'curve_score' = c(baseline, halfway_value, triquarter_value, maximal_elevation), 
                       'beta_brace' = factor(c('beta', 'beta', 'NA', 'NA')),
                       'beta_label' = rep('d[beta]', times = 4), 
                       
                       'gamma_brace' = factor(c('NA', 'gamma', 'gamma', 'NA')), 
                       'gamma_label' = rep('d[gamma]', times = 4),
                       
                       'total_brace' = factor(c('total', 'NA', 'NA', 'total')), 
                       'total_label' = rep('d[total]', times = 4))

font_size <- 8
title_font <- 30
axis_text_size <- 20
axis_title_size <- 24

theta_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(A:~Baseline~(theta)))) + 
  #theta 
  geom_segment(x = 10, xend = 360, y = baseline, yend = baseline, linetype = 5, size = 1) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = baseline, yend = baseline, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text', x = 440, y = 3.05, label = 'Baseline \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 440, y = 3.00, label = 'theta == 3.00', parse = T, size = font_size) + 

   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))


alpha_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(B:~Maximal~elevation~(alpha)))) + 
  #theta 
  geom_segment(x = -3, xend = 360, y = maximal_elevation, yend = maximal_elevation, linetype = 5, size = 1) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = maximal_elevation, yend = maximal_elevation, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text',  x = 440, y = 3.27, label = 'Maximal \nelevation \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 440, y = 3.20, label = 'alpha == 3.32', parse = T, size = font_size) + 

   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))


beta_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label =  expression(bold(C:~Days~to~halfway~elevation~(beta)))) + 
  #theta 
    geom_segment(x = 130, xend = 175, y = 3.16, yend = 3.16, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 180, xend = 180, y = 3.16, yend = 2.98, linetype = 2, size = 1) + #vertical dashed line 
  annotate(geom = 'text', x = 55, y = 3.14, label = 'Days to halfway \nelevation', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 55, y = 3.08, label = 'beta == 180~days', parse = T, size = font_size) + 
  
   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))

gamma_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(D:~`Halfway-triquarter`~'delta'~(gamma)))) +
  
  #gamma 
  geom_segment(x = 175, xend = 215, y = 3.233, yend = 3.233, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 220, xend = 220, y = 3.233, yend = 2.98, linetype = 2, size = 1) + #vertical dashed line 
  annotate(geom = 'text', x = 100, y = 3.21, label = 'Halfway-triquarter delta', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 105, y = 3.15, label = 'gamma == 40~days', parse = T, size = font_size) + 
  
  #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))

combined_plot <- ggarrange(theta_plot, alpha_plot, beta_plot, gamma_plot)
ggsave(plot = combined_plot, filename = 'Figures/combined_plot.pdf', width = 18, height = 12)


complete_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 1) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360))+
  annotate(geom = 'text', x = 50, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = 5) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 3) +

  #beta
  annotate(geom = 'text', x = 85, y = 3.15, label = 'Days to halfway \nelevation', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 90, y = 3.12, label = 'beta == 180~days', parse = T, size = font_size) +
  geom_segment(x = 130, xend = 175, y = 3.16, yend = 3.16, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 180, xend = 180, y = 3.16, yend = 2.98, linetype = 2, size = 0.3) + #vertical dashed line 
  
  #gamma
  annotate(geom = 'text', x = 97, y = 3.233, label = 'Halfway-triquarter delta', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 105, y = 3.21, label = 'gamma == 40~days', parse = T, size = font_size) + 
  geom_segment(x = 175, xend = 215, y = 3.233, yend = 3.233, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 220, xend = 220, y = 3.233, yend = 2.98, linetype = 2, size = 0.3)+  #vertical dashed line  
  
  coord_cartesian(clip = 'off') + 
  #theta 
  geom_segment(x = 10, xend = 360, y = baseline, yend = baseline, linetype = 3, size = 0.3) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = baseline, yend = baseline, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text', x = 425, y = 3.03, label = 'Baseline \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 425, y = 3.00, label = 'theta == 3.00', parse = T, size = font_size) + 

  #alpha 
  geom_segment(x = -3, xend = 360, y = maximal_elevation, yend = maximal_elevation, linetype = 3, size = 0.3) + #vertical dashed line  
  geom_segment(x = 400, xend = 365, y = maximal_elevation, yend = maximal_elevation, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) +      #horizontal arrow
  annotate(geom = 'text', x = 430, y = 3.30, label = 'Maximal \nelevation \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 430, y = 3.26, label = 'alpha == 3.32', parse = T, size = font_size) + 
  
   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold',size = title_font), 
        axis.title = element_text(size = 16), 
        axis.text = element_text(size = 13, colour = 'black'))
  
    ##brace information
  #stat_brace(data = point_df %>% filter(beta_brace == 'beta'), 
  #           mapping = aes(group = beta_brace, label = beta_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) + 
  #
  #stat_brace(data = point_df %>% filter(gamma_brace == 'gamma'), 
  #           mapping = aes(group = gamma_brace, label = gamma_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) +
  #
  #stat_brace(data = point_df %>% filter(total_brace == 'total'), 
  #           mapping = aes(group = total_brace, label = total_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) + 
  #
  #description box 
  #annotate(geom = 'rect', xmin = 235, xmax = 355, ymin = 3.02, ymax = 3.15, alpha = 0.1, color = 'black') + 
  #annotate(geom = 'text', x = 295, y = 3.13, label = 'd[total] == alpha~-~theta == 0.32', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.09, label = 'd[beta] == 0.5~(d[total]) == 0.16', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.06, label = 'd[gamma] == 0.23~(d[total]) == 0.07', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.03, label = 'd[beta]~+~d[gamma] == 0.73~(d[total]) == 0.23', parse = T, size = 4.5) + 

ggsave(plot = complete_plot, filename = 'Figures/complete_logistic_exp_plot.pdf', width = 9, height = 6)
```

```{=tex}
\begin{figure}[H]
  \caption{Description of Each Parameter of Four-Parameter Logistic Function}
  \label{fig:combined_plot}
  \includegraphics{Figures/combined_plot} \hfill{}
  \caption*{Note. \textup{Panel A shows that the baseline parameter ($\uptheta$) sets the starting value of the of curve, which 
in the current example has a value of 3.00 ($\uptheta$ = 3.00). Panel B shows that the maximal elevation parameter ($\upalpha$) sets the ending value of the curve, which in the current example has a value of 3.32 ($\upalpha$ = 3.32). Panel C shows that the days-to-halfway elevation parameter ($\upbeta$) sets the number of days needed to reach 50\% of the difference between the baseline and maximal elevation. In the current example, the baseline-maximal elevation difference is 0.32 ($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32), and so the days-to-halfway elevation parameter defines the number of days needed to reach a value of 3.16. Given that the days-to-halfway elevation parameter is set to 180 in the current example ($\upbeta = 180$), then 180 days are neededto go from a value of 3.00 to a value of 3.16. Panel D shows that the halfway-triquarter delta parameter ($\upgamma$) sets the number of days needed to go from halfway elevation to approximately 73\% of the baseline-maximal elevation difference of 0.32 ($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32). Given that 73\% of the baseline-maximal elevation difference is 0.23 and the halfway-triquarter delta is set to 40 days ($\upgamma = 40$), then 40 days are needed to go from the halfway point of 3.16 to the triquarter point of approximately 3.23).}}
\end{figure}
```

The logistic growth function (Equation \ref{eq:logFunction-generation}
was used because it is a common pattern of organizational change [or
institutionalization\; @lawrence2001]. Institutionalization curves follow
an s-shaped pattern of the logistic growth function, and so their rates
of change can be represented by the days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta$, $\upgamma$,
respectively), and the success of the change can be defined by the
magnitude of the difference between baseline and maximal elevation
parameters ($\upalpha$ - $\uptheta$, respectively).

#### Simulating Time Structuredness

To simulate time-unstructured data, response rates at each collection
point followed an exponential pattern described by either a fast or slow
response rate (for a review, see section on [time
structuredness](#sec:time-structuredness)). Importantly, data generated
for each person at each time point had to be sampled according to a
probability density function defined by either the fast or slow response
rate cumulative distribution function. In the current context, a
**probability density function** describes the probability of sampling
any given time delay value $x$ where the range of time delay values is
0--36 ($\{x : 0 \le x \le  36 \}$). To obtain the probability density functions
for fast and slow response rates, the response rate function shown in
Equation \@ref(eq:exponential) was differentiated with respect to $x$ to
obtain the function shown below in Equation \ref{eq:pdf-function}\footnote{Euler's notation for differentiation is used to represent derivatives. In words, $\frac{\partial f(x)}{\partial x}$ means that the derivative of the function $f(x)$ is taken with respect to $x$.}:

```{=tex}
\begin{align}
f^\prime = \frac{\partial f(x)}{\partial x} &= \frac{\partial}{\partial x}M(1 - e^{-ax}). \nonumber \\
&= M (e^{-ax}a)
(\#eq:pdf-function)
\end {align}
```

\noindent To compute the probability density function for the fast
response rate cumulative distribution function, the growth rate
parameter $a$ was set to 0.37 in Equation \ref{eq:pdf-function} to
obtain the following function in Equation \ref{eq:fast-pdf-function}:

```{=tex}
\begin{align}
f^\prime_{fast}(x) = M (e^{-a_{fast}x}a_{fast}) = M (e^{-0.37x}0.37). 
(\#eq:fast-pdf-function)
\end {align}
```
\noindent To compute the probability density function for the slow
response rate cumulative distribution function, the growth rate
parameter $a$ was set to 0.15 in Equation \ref{eq:pdf-function} to
obtain the following function in Equation \ref{eq:slow-pdf-function}:

```{=tex}
\begin{align}
f^\prime_{slow}(x) = M (e^{-0.15}a_{slow}) = M (e^{-0.15}0.15). 
(\#eq:slow-pdf-function)
\end {align}
```
Figure \ref{fig:cdf-pdf-plots} shows the fast and slow response
cumulative distribution functions (CDF) and their corresponding
probability density functions (PDF). Panel A shows the cumulative
distribution function for the fast response rate (with a growth
parameter value $a$ set to 0.37; see Equation \ref{eq:fast-cdf}) and
Panel B shows the probability density function that results from
computing the derivative of the fast response rate cumulative
distribution function with respect to $x$ (see Equation
\ref{eq:fast-pdf-function}). Panel C shows the cumulative distribution
function for the slow response rate (with a growth parameter value $a$
set to 0.15; see Equation \ref{eq:slow-cdf})) and Panel D shows the
probability density function that results from computing the derivative
of the slow response rate cumulative distribution function with respect
to $x$ (see Equation \ref{eq:slow-pdf-function} and section on [time
structuredness](#sec:time-structuredness) for more discussion). For the
fast response rate functions, an 80% response rate is obtained after
4.32 days or, equivalently, 80% of the area underneath the probability
density function is obtained at 4.32 days
($\int^{4.32}_{0} f_{fast}^\prime (x) = 0.80$; the integral from 0 to 4.32 of the probability density function for a fast response rate $f^\prime(x)_{fast}$ is 0.80). For the slow response
rate functions, an 80% response rate is obtained after 10.80 days or,
equivalently, 80% of the area underneath the probability density
function is obtained at 10.80 days
($\int^{10.80}_{0} f_{slow}^\prime (x) = 0.80$; the integral from 0 to 10.80 of the probability density function for a slow response rate $f^\prime(x)_{slow}$ is 0.80).

```{r pdf-time-structuredness, eval=F, include=F}
#1) Generate CDFs
day <- seq(from = 0, to = 36, by = 0.01)
M <- 1
satiation_value <- 0.8
satiation_point_fast <- 4.32
satiation_point_slow <- 10.80

a_fast <- log(1 - satiation_value)/-satiation_point_fast
a_slow <- log(1 - satiation_value)/-satiation_point_slow

#y data
y_fast <- M*(1 - exp(-a_fast*day))
y_slow <- M*(1 - exp(-a_slow*day))

#probability values
cdf_fast <- expression(M*(1 - exp(-a_fast*day)))
cdf_slow <- expression(M*(1 - exp(-a_slow*day)))

pdf_fast <- D(expr = cdf_fast, 'day')
pdf_slow <- D(expr = cdf_slow, 'day')

probability_values_fast<- eval(pdf_fast)
probability_values_slow <- eval(pdf_slow)


cdf_pdf_data <- data.frame('response_rate' = factor(c(rep('fast', times = length(y_fast)), 
                                           rep('slow', times = length(y_slow)))), 
                       'day' = rep(day, times = 2), 
                       'CDF' = c(y_fast, y_slow), 
                       'PDF' = c(probability_values_fast, probability_values_slow))

cdf_pdf_data_long <- cdf_pdf_data %>%
  pivot_longer(cols = c(CDF, PDF), names_to = 'prob_dist',
  names_ptypes = factor(levels = c('CDF', 'PDF'))) %>% 
  unite('dist_type', c('response_rate', 'prob_dist')) %>%
  mutate(dist_type = factor(dist_type, levels = c('fast_CDF', 'slow_CDF','fast_PDF', 
                                                   'slow_PDF')))

cdf_pdf_data_long$dist_type <- recode_factor(cdf_pdf_data_long$dist_type,   
                                             fast_CDF = 'bold(A:~CDF~(Fast~response~rate))', 
                                             slow_CDF = 'bold(C:~CDF~(Slow~response~rate))', 
                                             fast_PDF = 'bold(B:~PDF~(Fast~response~rate))', 
                                             slow_PDF = 'bold(D:~PDF~(Slow~response~rate))')
                
#lines showing 80% mark    
v_line_data <- data.frame(
  dist_type =c("bold(A:~CDF~(Fast~response~rate))", "bold(C:~CDF~(Slow~response~rate))"), 
  x = c(4.32, 10.80), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0, 0))

h_line_data <- data.frame(
  dist_type = c("bold(A:~CDF~(Fast~response~rate))", "bold(C:~CDF~(Slow~response~rate))"), 
  x = c(0, 0), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0.8, 0.8))

#needed for shading
pdf_shading_data <- cdf_pdf_data_long %>% 
  filter(str_detect(dist_type, pattern = 'bold\\(B') & day <= 4.32 | 
         str_detect(dist_type, pattern = 'bold\\(D') & day <= 10.80)

#needed for points 
point_data <- data.frame(
  dist_type =c(rep("bold(A:~CDF~(Fast~response~rate))", times = 1), 
               rep("bold(C:~CDF~(Slow~response~rate))", times = 1)),
  x = c(4.32, 10.80), 
  y = c(0.8, 0.8))

#arrows 
arrow_data <- data.frame(
  dist_type =c(rep("bold(A:~CDF~(Fast~response~rate))", times = 1), 
               rep("bold(C:~CDF~(Slow~response~rate))", times = 1)),
  xmin = c(4.32, 10.80), 
  xmax = c(10, 17), 
  ymin = c(0.8, 0.8), 
  ymax = c(0.25, 0.25))


#equations 
equation_data <- data.frame(
  dist_type =c(rep("bold(A:~CDF~(Fast~response~rate))", times = 4), 
               rep("bold(C:~CDF~(Slow~response~rate))", times = 4), 
               rep("bold(B:~PDF~(Fast~response~rate))", times = 3), 
               rep("bold(D:~PDF~(Slow~response~rate))", times = 3)),
  
  label = c("f[fast](x) == M(1 - e^{-a[fast]~x})", "a[fast] == 0.37", "M ==1", "0.80 == 1(1-e^{-0.37(4.32)})", 
            "f[slow](x) == M(1 - e^{-a[slow]~x})", "a[slow] == 0.15", "M == 1", "0.80 == 1(1-e^{-0.15(10.80)})",
            
            "f[fast]^{phantom() * minute }(x) * {phantom() == phantom()} * frac(partialdiff *f[fast](x),  partialdiff *x) * {phantom() == phantom()} * M(e^{a[fast]*x} * a[fast])",
            "integral(f[fast]^{phantom() * minute}, 0, 4.32)*(x) == f[fast](4.32) - f[fast](0)", "phantom() == 0.80", 
            
            "f[slow]^{phantom() * minute }(x) * {phantom() == phantom()} * frac(partialdiff *f[slow](x),  partialdiff *x) * {phantom() == phantom()} * M(e^{a[slow]*x} * a[slow])",
            "integral(f[slow]^{phantom() * minute}, 0, 10.80)*(x) == f[slow](10.80) - f[slow](0)", "phantom() == 0.80"), 
  x = c(18, 17, 18, 18, 
        24, 25, 24, 24, 
        22, 22, 20.5, 
        22, 22, 20.5),
  y = c(rep(c(0.8, 0.65, 0.50, 0.2), times = 2), 
        0.35, 0.15, 0.10, 
        0.35, 0.15, 0.10))


           
cdf_pdf_plot <- ggplot(cdf_pdf_data_long, aes(x = day, y = value)) + 
  geom_line(size = 1.5) + 
  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.80, 1.00)) +
  theme_classic(base_family = 'Helvetica') + 
  
  geom_area(data = pdf_shading_data, mapping = aes(x = day, y = value), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 1.5) +
  geom_text(data = equation_data, inherit.aes = F, mapping = aes(x = x, y = y, label = label), parse = T, size = 9) + 
  geom_point(data = point_data, inherit.aes = F, mapping = aes(x = x , y = y), size = 4) + 
  
  #arrows
  geom_segment(data = arrow_data, inherit.aes = F, mapping = aes(x = xmin, xend = xmax, y = ymin, yend = ymax), 
               arrow = arrow(length = unit(0.3, 'cm')), size = 1)  + 
  
    #vertical lines 
  geom_segment(data = v_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 1) + 
  geom_segment(data = h_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 1)  + 



  facet_wrap_custom( ~ dist_type, scales = "free", ncol = 2, nrow = 2 , dir = 'v',
                     labeller = label_parsed,  

                            scale_overrides = list(
                            scale_override(1,
                              scale_x_continuous(
                                breaks = c(0, 4.32, 18, 24, 36),
                                limits = c(0, 36))), 
                          
                            scale_override(which = 2,
                              scale_y_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4),
                                limits = c(0, 0.4))),
                             scale_override(which = 2,
                              scale_x_continuous(breaks = c(0, 4.32, 18, 24, 36),
                                limits = c(0, 36))),
                            
                            scale_override(which = 3,
                               scale_x_continuous(
                                breaks = c(0, 10.80, 18, 24, 36),
                                limits = c(0, 36))), 
                         
                            scale_override(4,
                              scale_x_continuous(
                                breaks = c(0, 10.80, 18, 24, 36),
                                limits = c(0, 36))), 
                            scale_override(which = 4,
                                scale_y_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4),
                                limits = c(0, 0.4))))) +  


  labs( x = 'Response window day') + 
  
  theme(strip.text.x = element_text(face = 'bold', hjust = 0, size = 30, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),
        strip.background = element_rect(fill = "white", color = "white"), 

        #axis details
        axis.text = element_text(size = 22, color = 'black'),
        axis.title = element_text(size = 28),
        axis.line = element_line(size = 1),
        axis.ticks.length.x = unit(x = 0.5, units = 'cm'), 
        axis.title.x = element_text(margin = unit(c(1, 0, 0, 0), "cm")),
        axis.ticks = element_line(size = 1, colour = 'black'),

      panel.spacing.y = unit(x = 2, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
       

g <- ggplotGrob(cdf_pdf_plot)

#customize y-axis label 
g$grobs[[28]]$children$GRID.text.24299$label <- paste("Density (probability, f'(x))", str_pad('', width = 13), "Response percentage (f(x))")
g$grobs[[28]]$children$GRID.text.24299$y <- grid::unit(0.52,"npc")
g$grobs[[28]]$children$GRID.text.24299$x <- grid::unit(-0.2,"npc")

plot_converted <- as_ggplot(g)

#create PDF of faceted plot
set_panel_size(p = plot_converted, height = unit(x = 32, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/cdf_pdf_plots.pdf')
```

```{=tex}
\begin{figure}[H]
  \caption{Cumulative Distribution Functions (CDF) and Probability Density Functions (PDF) for Fast and Slow Response Rates}
  \label{fig:cdf-pdf-plots}
  \includegraphics{Figures/cdf_pdf_plots} \hfill{}
  \caption*{Note. \textup{Panel A shows the cumulative distribution function for the fast response rate (with a growth parameter value $a$ set to 0.37; see Equation \ref{eq:fast-cdf}) and Panel B shows the probability density function that results from computing the derivative of the fast response rate cumulative distribution function with respect to $x$ (see Equation \ref{eq:fast-pdf-function}). Panel C shows the cumulative distribution function for the slow response rate (with a growth parameter value $a$ set to 0.15; see Equation \ref{eq:slow-cdf}) and Panel D shows the probability density function that results from computing the derivative of the slow response rate cumulative distribution function with respect to $x$ (see Equation \ref{eq:slow-pdf-function} and section \ref{sec:time-structuredness} for more discussion on time structuredness). For the fast response rate functions, an 80\% response rate is obtained after 4.32 days or, equivalently, 80\% of the area underneath the probability density function is obtained at 4.32 days ($\int^{4.32}_{0} f_{fast}^\prime (x) = 0.80$). For the slow response rate functions, an 80\% response rate is obtained after 10.80 days or, equivalently, 80\% of the area underneath the probability density function is obtained at 10.80 days ($\int^{10.80}_{0} f_{slow}^\prime (x) = 0.80$).}}
\end{figure}
```
Having computed probability density functions for fast and slow response
rates, time delays could be generated to create time-unstructured data. To generate time-unstructured data for a
person at a given time point, a time delay wasfirst
generated by sampling values according to the probability density function defined by either a fast or slow response rate (Equations \ref{eq:fast-pdf-function}--\ref{eq:slow-pdf-function}). The sampled time delay was then added to the value of the current measurement day, with the combined measurement day then being plugged into the logistic function (Equation \ref{eq:logFunction-generation}) along with a set of person-specific parameter values to generate an observed score at a given time point for a given person. 

#### Population Values Used for Logistic Function Parameters

(ref:bosco2015) [@bosco2015]

Table \@ref(tab:parameterValues) lists the parameter values that will be
used for the population parameters. As mentioned in the section on [data
generation], the difference between baseline and maximal elevation
parameters ($\uptheta$ and $\upalpha$, respectively) corresponded to to
the effect size most commonly observed in organizational research
[@bosco2015]. To facilitate interpretation of the results, data were
generated to resemble the commonly used Likert (range of 1--5) by using
a standard deviation of 1.00 and change was assumed to occur over a
period of 360 days. The decision to generate data in the context of a
360-day period was made because many organizational processes are often
governed by annual events (e.g., performance reviews, annual returns,
regulations, etc.). Importantly, because @coulombe2016 set covariances
between parameters to zero, all the simulation experiments used
zero-value covariances.

```{r parameterValues, echo=F}
#specify parameters for parameter table 
theta <- 3
alpha <- 3 + .32*1
beta <- 180
gamma <- 20

sd_alpha <- 0.05
sd_theta <- 0.05
sd_beta <- 10
sd_gamma <- 4

sd_error <- 0.03


#table of parameter values
parameterValues_df <- data.frame('Parameter' = c('Parameter means',
                                         'Baseline, $\\uptheta$',
                                         'Maximal elevation, $\\upalpha$', 
                                         'Days-to-halfway elevation, $\\upbeta$', 
                                         'Triquarter-halfway delta, $\\upgamma$', 
                                         
                         'Variability and covariability (in standard deviations)', 
                              'Baseline standard deviation, $\\uppsi_{\\uptheta}$',
                              'Maximal elevation standard deviation, $\\uppsi_{\\upalpha}$', 
                              'Days-to-halfway elevation standard deviation, $\\uppsi_{\\upbeta}$',
                              'Triquarter-halfway delta standard deviation, $\\uppsi_{\\upgamma}$',
                         
                              'Baseline-maximal elevation covariability, $\\uppsi_{\\uptheta\\upalpha}$',
                              'Baseline-days-to-halfway elevation covariability, $\\uppsi_{\\uptheta\\upbeta}$',
                              'Baseline-triquarter-halfway delta covariability, $\\uppsi_{\\uptheta\\upgamma}$',
                         
                              'Maximal elevation-days-to-halfway elevation covariability, $\\uppsi_{\\upalpha\\upbeta}$',
                              'Maximal elevation-triquarter-halfway delta covariability, $\\uppsi_{\\upalpha\\upgamma}$',
                         
                              'Days-to-halfway elevation-triquarter-halfway delta covariability, $\\uppsi_{\\upbeta\\upgamma}$',
                          
                              'Residual standard deviation, $\\uppsi_{\\upepsilon}$'), 
                         'Value' = c('', theta, alpha, beta, gamma, 
                                     '', sd_theta, sd_alpha, sd_beta, sd_gamma, 
                                     0, 0, 0, 0, 0,0,  sd_error), check.names = F)

#round numbers to that they print with two significant numbers
parameterValues_df$Value <- round(as.numeric(as.character(parameterValues_df$Value)), 3)
parameterValues_df$Value <- formatC(round(parameterValues_df$Value, 3), format='f', digits=2)

#replace '  NA' with empty string 
parameterValues_df$Value[parameterValues_df$Value ==" NA"] <- ''


kbl(parameterValues_df, booktabs = TRUE, format = 'latex', longtable = T, 
    linesep = c(rep('', times = 4), '\\addlinespace\\addlinespace', 
                rep('', times = 11))
    , 
    align = c('l', 'c'), 
    caption = "Values Used for Multilevel Logistic Function Parameters", 
    escape = F) %>%
   add_indent(positions = c(2:5, 7:16, 17), level_of_indent = 2) %>%
   kable_styling(latex_options= c('hold_position', 'repeat_header'), position = 'left', font_size = 10) %>%
  footnote(general =  "The difference between $\\\\alpha$ and $\\\\theta$ corresponds to the 50$\\\\mathrm{^{th}}$ percentile Cohen's $d$ value of 0.32 in organizational psychology (Bosco et al., 2015).",  threeparttable = T,  escape = F, general_title = '\\\\textit{Note.}\\\\hspace{-1pc}') %>%
   column_spec(column = 1, width = '12 cm')
```

### Nonlinear Latent Growth Curve Model Used to Analyze Each Generated Data Set

The sections that follow will first review the framework used to build
latent growth curve models and then explain how nonlinear functions can
be modified to fit into this framework.

#### Brief Review of the Latent Growth Curve Model Framework

(ref:meredith1990browne1993) [@meredith1990; @browne1993]

(ref:blozis2004) [@blozis2004]

The latent growth curve model proposed by @meredith1990
is briefly reviewed here [for a review, see @preacher2008]. Consider an example where data are collected at five time
points ($T = 5$) to yield five observations for each $p$ person
($\mathbf{y_p} = [y_1, y_2, y_3, y_4, y_5$). A simple model to fit is
one where change over is defined by a straight line and each person's
pattern of change is some variation of this straight line. In modelling
parlance, an intercept-slope model is fit where both the intercept and
slope are random effects whose values are allowed to vary for each
person. Intercept and slope parameters can be algebraically represented
by a two-column matrix that represents the effect of each parameter on
the outcome variable $y$ at each $i$ time point. Because the effect of
the intercept parameter is constant over time, a column of 1s is used to
represent its effect. For the slope parameter, a pattern of linear
growth can be specified filling the second column with a series of
monotonically increasing numbers such as
0--4.\footnote{The set of numbers specified for the slope starts at zero because there is presumably no effect of any variable at the first time point.}The matrix $\mathbf{\Uplambda}$ below shows a two-column matrix that
specifies the effects for an intercept and slope parameter:

$$ 
\mathbf{\Uplambda} = 
\begin{bmatrix}
1 & 0 \\ 
1 & 1 \\ 
1 & 2 \\ 
1 & 3 \\
1 & 4 \\
\end{bmatrix}
$$

\noindent To create a model that allows different linear patterns to be
fit to each person's data, a weight can be applied to each column of
$\mathbf{\Uplambda}$ and each weight can vary across individuals.\footnote{The columns of $\mathbf{\Uplambda}$ are called basis curves (ref:blozis2004) or basis functions (ref:meredith1990browne1993) because each column specifies a particular component of change.}That is, each $p$ person's pattern of change is predicted with a unique set of weights in $\mathbf{\upiota_p}$ that determines the extent to
which each basis column of $\mathbf{\Uplambda}$ contributes to that
person's change over time. Discrepancies between the values predicted by
$\mathbf{\Uplambda\upiota_p}$ and a person's observed scores across all
five time points are stored in an error vector
$\mathbf{\mathcal{E}_p}$. Thus, a person's observed data ($\mathbf{y_p}$) is
constructed using the expression shown below in Equation \ref{eq:sem-framework}:

```{=tex}
\begin{align}
 y_p = \mathbf{\Uplambda\upiota_p} + \mathbf{\mathcal{E}_p}.
 (\#eq:sem-framework)
\end{align}
```

\noindent Note that Equation \ref{eq:sem-framework} defines the general structural equation modelling framework. 

#### Fitting a Nonlinear Function in the Structural Equation Modelling Framework

Unfortunately, the logistic function of Equation
\ref{eq:logFunction-generation}---where each parameter was estimated as a
fixed- and random-effect---could not be directly used in a latent growth curve model because it would have violated the linear nature of the structural equation modelling framework (Equation \ref{eq:sem-framework}). Structural equation models only permit linear combinations---specifically, the
products of matrix-vector and/or matrix-matrix multiplication---and so
directly fitting a nonlinear function such as the logistic function in
Equation \ref{eq:logFunction-generation} would not have been possible.

One solution to fitting the logistic function within the structural equation modelling framework was to implement the structured latent curve modelling approach
[@browne1991; @browne1993; for an excellent review, see @preacher2015]. Briefly, the structured latent curve modelling approach constructs a Taylor series approximation of a nonlinear function so that the nonlinear function can be fit into the structural equation modelling framework (Equation \ref{eq:sem-framework}). The sections that follow will present the structured latent curve modelling approach in four parts such that 1) Taylor series approximations will first be reviewed, 2) a Taylor series approximation will then be constructed for the logistic function, 3) the logistic Taylor series approximation will be modified and fit into the structural equation modelling framework, and 4) the process of parameter estimation will be reviewed. 

##### Taylor Series Approximations

A Taylor series uses derivative information of a nonlinear function to
construct a linear approximation.\footnote{Linear functions are
defined as functions where no parameter exists within its own partial
derivative. For example, none of the parameters in the polynomial
equation of $y = a + bt + ct^2 + dt^3$ exist within their own partial
derivative: $\frac{\partial y}{\partial a} = 1$,
$\frac{\partial y}{\partial b} = t$,
$\frac{\partial y}{\partial c} = t^2$, and
$\frac{\partial y}{\partial d} = t^3$. Conversely, the logistic function
is nonlinear because $\upbeta$ and $\upgamma$ exist in their own
partial derivatives. For example, the derivative of the logistic function  $y = \uptheta + \frac{\upalpha - \uptheta}{1 + e^{\frac{\upbeta - t}{\upgamma}}} $with respect to $\upbeta$ is $\frac{(\uptheta - \upalpha) (e^{\frac{\upbeta - t}{\upgamma}})(\frac{1}{\upgamma})}{1 + (e^{\frac{\upbeta - t}{\upgamma}})^2}$and so is nonlinear because it contains $\upbeta$.}Equation \ref{eq:taylor} shows the general formula for a Taylor series such that

```{=tex}
\begin{align}
P^N(f(x), a)= \sum^{N}_{n = 0} \frac{f^na}{n !}(x-a)^n,
(\#eq:taylor)
\end{align}
```

\noindent where $N$ is the highest derivative order of the function $f(a)$ that is taken beginning from a zero-value derivative order ($n=0$), $a$ is the point where the Taylor series is derived, and $x$ is the point where the
Taylor series is evaluated. As an example, consider  $f(x) = \cos(x)$. Note that, across the continuum of $x$ values (i.e., from $-\infty$ to $\infty$), $\cos(x)$ returns values between -1 and 1 in an oscillatory manner. Computing the second-order Taylor series approximation of $f(x) = \cos(x)$ yields the following function shown in Equation \ref{eq:example-taylor}:

```{=tex}
\begin{align} 
P^2(\cos(x), a) &=  \frac{\frac{\partial^0 \cos(a)}{\partial a^0}}{0!}(x -a)^0 + \frac{\frac{\partial^1 \cos(a)}{\partial a^1}}{1!}(x -a)^1 + \frac{\frac{\partial^2 \cos(a)}{\partial a^2}}{2!} (x -a)^2 \nonumber \\ 
&=  \frac{\cos(0)}{0!}(x -0)^0 - \frac{\sin(0)}{1!}(x -0)^1 - \frac{\cos(0)}{2!}(x -0)^2  \nonumber \\ 
&=  \frac{1}{1}1 - \frac{0}{1}x - \frac{1}{2}x^2  \nonumber \\ 
P^2(\cos(x), 0) &=  1- \frac{1}{2}x^2. 
  (\#eq:example-taylor)
\end{align}
```
\noindent Note that that the second-order Taylor series of $\cos(x)$
perfectly estimates $\cos(x)$ when the point of evaluation $x$ is set
equal to the point of derivation $a$ and estimates $\cos(x)$ with an
increasing amount of error as the difference between $x$ and $a$
increases (see Example \ref{exm:taylor-estimates}).

```{example, taylor-estimates, echo=T}
Estimates of Taylor series approximation of $f(x) = \cos(x)$ as the difference between the point of evaluation $\mathrm{x}$ and the point of derivation $\mathrm{a}$ increases.

 \noindent \textup{Taylor series approximation of $f(x) = \cos(x)$ estimates values that are exactly equal to the values returned by $f(x) = \cos(x)$ when the point of evaluation \textit{x} is set to the point of derivation \textit{a}. The example below computes the value predicted by the Taylor series approximation of $f(x) = \cos(x)$ and by $f(x) = \cos(x)$ when \textit{x} = \textit{a} = 0.}

\useshortskip
\begin{align*}
P^2(\cos(x=0), a=0) &= \cos(x=0) \nonumber \\ 
1- \frac{1}{2}x^2 &=  \cos(0) \nonumber \\ 
1- \frac{1}{2}0^2 &=  1 \nonumber \\ 
1- 0 &=  1 \nonumber \\ 
1 &=  1 \nonumber \\ 
\end{align*}
\vspace*{-25mm}

 \noindent \textup{Taylor series approximation of $f(x) = \cos(x)$ estimates a value that is clearly not equal ($neq$) to the value returned by $f(x) = \cos(x)$when the difference between the point of evaluation \textit{x} and the point of derivation \textit{a} is smaller. The example below computes the value predicted by the Taylor series approximation of $f(x) = \cos(x)$ and by $f(x) = \cos(x)$ when \textit{x} = 1 and  \textit{a} = 0.} 

\useshortskip
\begin{align*}
P^2(\cos(x = 1), 0) &\thickapprox \cos(x = 1) \nonumber \\ 
1- \frac{1}{2}x^2 &\thickapprox   \cos(1) \nonumber \\ 
1- \frac{1}{2}1^2 &\thickapprox   0.54 \nonumber \\ 
1- 0.5 &\thickapprox   0.54 \nonumber \\ 
0.5 &\thickapprox 0.54 \nonumber \\ 
\end{align*}
\vspace*{-25mm}

 \noindent\textup{Taylor series approximation of $f(x) = \cos(x)$ estimates a value that is clearly not equal ($neq$) to the value returned by $f(x) = \cos(x)$ when the difference between the point of evaluation \textit{x} and the point of derivation \textit{a} is larger The example below computes the value predicted by the Taylor series approximation of $f(x) = \cos(x)$ and by $f(x) = \cos(x)$ when \textit{x} = 4 and  \textit{a} = 0.} 


\useshortskip
\begin{align*}
P^2(\cos(x = 4), 0) &\neq \cos(x = 4) \nonumber \\ 
1- \frac{1}{2}x^2 &\neq  \cos(4) \nonumber \\ 
1- \frac{1}{2}4^2 &\neq  -0.65 \nonumber \\ 
1- 16 &\neq  -0.65 \nonumber \\ 
0.5 &\neq  -0.65 \nonumber \\ 
\end{align*}
\vspace*{-25mm}

\noindent \hrulefill
```

\noindent Figure \ref{fig:taylor-vs-nonlin} plots the nonlinear function
of $\cos(x)$ and its second-order Taylor series $P^2(\cos(x)) = 1- \frac{1}{2}x^2$. The
second order Taylor series perfectly estimates $\cos(x)$ when the point
of evaluation ($x$) equals the point of derivation ($a$; $x = a = 0$),
but incurs an increasingly large amount of error as the difference
between the point of evaluation and the point of derivation increases.
For example, at $x = 10$, $\cos(10) = -0.84$, but the Taylor series
outputs a value of -49.50 ($P^2(cos(50)) = 1- \frac{1}{2}10^2 = -49.50$). Therefore, Taylor series' are approximations because they are locally accurate.

```{r taylor-vs-nonlin, include=F, eval=F}

x <- seq(from = 0, to = 10, by = 0.1)
taylor_data <- 1- 0.5*(x)^2
cos_data <- cos(x)

combined_data <- data.frame('x' = x, Taylor = taylor_data, Cos = cos_data, check.names = F)

combined_data_long <- combined_data %>% 
  pivot_longer(cols = c('Cos' , 'Taylor'), names_to = 'curve_type', 
               names_ptypes = factor())

taylor_vs_nonlin_plot <- ggplot(data = combined_data_long, mapping = aes(x = x, y = value, group = curve_type, linetype = curve_type)) + 
  geom_line(size = 1) + 
  labs(linetype = 'Curve type') + 
  annotate(geom = 'text', label = 'P^2*(cos(x)) == 1 - frac(1, 2)*x^2', x = 5, y = -30, parse=T, size = 7) + 
  
  #expression(paste(P^{2}*(cos(x)), ', ', b == 6))

  annotate(geom = 'text', label = 'f(x) == cos(x)', x = 8, y = -10, parse=T, size = 7) + 
  
  geom_segment(inherit.aes = F, mapping = aes(x = 8, xend = 8, y = -9, yend = -1), 
               arrow = arrow(length = unit(0.3, 'cm')), size = 0.5) +
  
  geom_segment(inherit.aes = F, mapping = aes(x = 5, xend = 5, y = -28, yend = -13), 
               arrow = arrow(length = unit(0.3, 'cm')), size = 0.5) +
  scale_y_continuous(name = 'Curve value') + 
  scale_x_continuous(name = 'Point of evaluation (x)', breaks = seq(from = 0, to = 10, by =1)) + 
  theme_classic(base_family = 'Helvetica') + 
  theme(legend.text = element_text(size = 12, color = 'black'), 
        legend.title = element_text(size = 16, color = 'black'), 
        axis.text =element_text(size = 12, color = 'black'), 
        axis.title = element_text(size = 16, color = 'black')) 
  
ggsave(filename = 'Figures/taylor_vs_nonlin.pdf', plot =taylor_vs_nonlin_plot, width = 9, height = 6)


```

```{=tex}
\begin{figure}[H]
  \caption{Estimation Accuracy of Taylor Series Approximation of Nonlinear Function (cos(x))}
  \label{fig:taylor-vs-nonlin}
  \includegraphics{Figures/taylor_vs_nonlin} \hfill{}
  \caption*{Note. \textup{The second order Taylor series perfectly estimates $\cos(x)$ when the point of evaluation ($x$) equals the point of derivation ($a$; $x = a = 0$), but incurs an increasingly large amount of error as the difference between the point of evaluation and the point of derivation increases. For example, at $x = 10$, $\cos(x) = -0.84$, but the Taylor series outputs a value of -49.50 ($P^2(cos(50)) = 1- \frac{1}{2}10^2 = -49.50$). }}
\end{figure}
```

##### Taylor Series Approximation of the Logistic Function

Given that a Taylor series provides a linear approximation of a
nonlinear function and the structural equation modelling framework is linear, the structured latent curve modelling approach uses Taylor series approximations to construct linear representations of nonlinear functions [@browne1991; @browne1993]. In the current simulations, a Taylor series approximation was constructed for the logistic function (Equation \ref{eq:logistic}). Note that, because the logistic function had four parameters ($\uptheta$,
$\upalpha$, $\upbeta$, $\upgamma$), derivatives were computed with
respect to each of the parameters. Using a derivative order set to one
($n = 1$), the following Taylor series was constructed for the logistic
function (Equation \ref{eq:logistic-approx}):

```{=tex}
\begin{align}
 P^1(L(\Uptheta, t)) = L + \frac{\partial L}{\partial \uptheta}(x_{\uptheta}-a_{\uptheta})^1 + \frac{\partial L}{\partial \upalpha}(x_{\upalpha}-a_{\upalpha})^1 + \frac{\partial L}{\partial \upbeta}(x_{\upbeta}-a_{\upbeta})^1 + \frac{\partial L}{\partial \upgamma_{\upgamma}}(x-a_{\upgamma})^1, 
(\#eq:logistic-approx)
\end{align}
```
\noindent where $\mathbf{L(\Uptheta, t)}$ represents the logistic function shown below in
Equation \ref{eq:logistic}:

```{=tex}
\begin{align}
  \mathbf{L(\Uptheta, t)} = \uptheta + \frac{\upalpha - \uptheta}{{1 + e^\frac{\upbeta - t}{\upgamma}}} + \upepsilon, 
(\#eq:logistic)
\end{align}
```

\noindent with $\Uptheta = [\uptheta, \upalpha, \upbeta, \upgamma]$ and  $\mathbf{L(\Uptheta, t)}$ being a vector of scores at all $\mathbf{t}$ time points. In the current context, because each parameter of the logistic function had a unique meaning (see section on [data generation][Data generation]), the point of derivation $a$ differed for each parameter---using the same $a$ value for each parameter to construct the
Taylor series approximation of the logistic function would have yielded
a practically useless equation. Because the logistic Taylor series
approximation (Equation \ref{eq:logistic-approx}) was deployed in a
statistical model (i.e., the structural equation modelling framework), the derivation values
($a_{\uptheta}$, $a_{\upalpha}$, $a_{\upbeta}$, $a_{\upgamma}$) were set
to the mean values estimated by the analysis for each parameter. Thus, the
derivation values were replaced with the following terms:

-   $a_{\uptheta} = \hat{\uptheta}$
-   $a_{\upalpha} = \hat{\upalpha}$
-   $a_{\upbeta} = \hat{\upbeta}$
-   $a_{\upgamma} = \hat{\upgamma}$

\noindent where that a caret $\hat{}$ indicates the mean value estimated for a parameter by the analysis. In order to estimate curves for each $p$ person, the values of
evaluation ($x_{\uptheta}$, $x_{\upalpha}$, $x_{\upbeta}$,
$x_{\upgamma}$) corresponded to the parameter values computed for a
given person ($\uptheta_p$, $\upalpha_p$, $\upbeta_p$, $\upgamma_p$). Thus, the evaluation values were replaced with the following terms:

-   $x_{\uptheta} = \uptheta_p$
-   $x_{\upalpha} = \upalpha_p$
-   $x_{\upbeta} = \upbeta_p$
-   $x_{\upgamma} = \upgamma_p$

\noindent Substituting the above values for the derivation and evaluation values of $x$ and $a$ in the initial logistic Taylor series approximation (Equation \ref{eq:logistic-approx}) yielded the following expression for the logistic Taylor series approximation (Equation \ref{eq:taylor-full}):

```{=tex}
\begin{align}
 P^1(L(\Uptheta, t)) = L(\Uptheta, t) + \frac{\partial L}{\partial \uptheta}(\uptheta_i-\hat{\uptheta})^1 + \frac{\partial L}{\partial \upalpha}(\upalpha_i-\hat{\upalpha_i})^1 + \frac{\partial L}{\partial \upbeta}(\upbeta-\hat{\upbeta})^1 + \frac{\partial L}{\partial \upgamma_{\upgamma}}(\upbeta-\hat{\upbeta})^1.
(\#eq:taylor-full)
\end{align}
```

\noindent Therefore, because the Taylor series was derived using the mean values estimated for each parameter ($\hat{\uptheta}$, $\hat{\upalpha}$, $\hat{\upbeta}$,
$\hat{\upgamma}$), it provided a perfect approximation of the estimated
population curve---the evaluation values for each parameter would have
been set to their corresponding mean estimated value. To estimate the curve of any given $p$ person, the evaluation values could be offset from their corresponding derivation value (i.e., mean estimated value for a parameter) by using the set of parameter values computed for that person ($\uptheta_p$, $\upalpha_p$, $\upbeta_p$, $\upgamma_p$). Note that, because Taylor series approximations are only locally accurate, the predicted curves for any given $p$ person become increasingly inaccurate curves as the difference between the derivation and evaluation values increases (e.g., $\uptheta_i-\hat{\uptheta}$).

##### Fitting the Logistic Taylor Series Approximation Into the Structual Equation Modelling Framework 

Although the logistic Taylor series approximation provides an accurate
estimation of the logistic function, the function in (Equation
\ref{eq:taylor-full}) is modified in the structured latent curve
modelling approach so that it can more effectively fit into the structural equation modelling framework (Equation \ref{eq:sem-framework}). The partial derivative information is stored in the matrix $\mathbf{\Uplambda}$ such that

$$ 
\mathbf{\Uplambda} = 
\begin{bmatrix}
\frac{\partial L(\Uptheta, t_1)}{\partial \uptheta} & \frac{\partial L(\Uptheta, t_1)}{\partial \upalpha}  &  \frac{\partial L(\Uptheta, t_1)}{\partial \upbeta} & \frac{\partial L(\Uptheta, t_1)}{\partial \upgamma}   \\ 
\frac{\partial L(\Uptheta, t_2)}{\partial \uptheta}  & \frac{\partial L(\Uptheta, t_2)}{\partial \upalpha} &  \frac{\partial L(\Uptheta, t_2)}{\partial \upbeta} & \frac{\partial L(\Uptheta, t_2)}{\partial \upgamma} & \\ 
\vdots & \vdots & \vdots & \vdots \\ 
\frac{\partial L(\Uptheta, t_n)}{\partial \uptheta} & \frac{\partial L(\Uptheta, t_n)}{\partial \upalpha}  & \frac{\partial L(\Uptheta, t_n)}{\partial \upbeta} & \frac{\partial L(\Uptheta, t_n)}{\partial \upgamma} \\
\end{bmatrix}.
$$

\noindent As in the structural equation modelling framework where each column of
$\mathbf{\Uplambda}$ specified a basis curve (i.e., a loading of a
growth parameter onto all time points), each column of $\mathbf{\Uplambda}$ here
in the structured latent curve modelling approach contains the loadings
of a logistic function parameter onto all the $n$ time points, with the loadings being determined by the partial derivative of logistic function with respect to that parameter. To predict unique curves for each person, each column can be multiplied by a specific weight $\mathbf{\upiota_p}$ that contains person-specific deviations from each mean estimated parameter value as shown below:

$$ 
\mathbf{\upiota_p} = 
\begin{bmatrix}
\hat{\uptheta} - \uptheta_p   \\ 
\hat{\upalpha} - \upalpha_p   \\ 
\hat{\upbeta} - \upbeta_p \\ 
\hat{\upgamma_i} - \upgamma_p \\
\end{bmatrix},
$$ 


\noindent where a caret ($\hat{}$) indicates the mean value estimated
for a given parameter and a subscript $p$ indicates a parameter value
computed for a person. With a matrix $\mathbf{\Uplambda}$ containing
logistic function parameter loadings and a vector $\mathbf{\upiota_p}$ containing
person-specific weights, the Taylor series of Equation
\ref{eq:taylor-full} that predicted a person's scores over time can be
rewritten to become the following expression of Equation
\ref{eq:slcm-nonsem}:

```{=tex}
\begin{align}
 \mathbf{y_p} = \mathbf{L(\Uptheta, t)} + \mathbf{\Uplambda\upiota_p} + \mathbf{\mathcal{E}_p}.
 (\#eq:slcm-nonsem)
\end{align}
```

\noindent Importantly, because of the logistic function ($\mathbf{L(\Uptheta, t)}$) in the
above expression (Equation \ref{eq:slcm-nonsem}), the model no longer
fits into the general structural equation modelling framework (Equation \ref{eq:sem-framework}). To modify Equation \ref{eq:slcm-nonsem} such that it fits into the structural equation modelling framework, the structured latent curve modelling approach recognizes that the logistic function ($\mathbf{L(\Uptheta, t)}$) is invariant under a scaling constant and uses this property to rewrite  $\mathbf{L(\Uptheta, t)}$ as a weighted sum of the partial derivative loading matrix [$\mathbf{\Uplambda}$\; @shapiro1987]. Briefly, the
logistic function vector $\mathbf{L(\Uptheta, t)}$ is invariant under a constant scaling
property because, given some constant scalar value $k \ge 0$ and a set
of parameter values ($\Uptheta$), there exists another set of parameter
values ($\tilde{\Uptheta}$) that can produce the same values (see
Equation \ref{eq:icsf} and Example \ref{exm:icsf-ex} below).

```{=tex}
\begin{align}
 k\mathbf{L(\Uptheta, t)} = \mathbf{L(\tilde{\Uptheta}, t)}
 (\#eq:icsf)
\end{align}
```

```{example, icsf-ex, echo=T}
Invariability under a constant scaling factor of logistic function (Equation \ref{eq:logistic}).  

\noindent \textup{Given $t = [0, 1, 2, 3]$, $\Uptheta = [\uptheta = 3.00$, $\upalpha = 3.32$, $\upbeta = 180.00$, $\upgamma = 20.00$], and some constant scaling factor $k = 2.00$, then there exists some set of parameter values $\tilde{\Uptheta}$ that produces the same values as $kL(\Uptheta)$. In the current example, $\tilde{\Uptheta} = [\uptheta = 6.00$, $\upalpha = 6.64$, $\upbeta = 180.00$, $\upgamma = 20.00$].} 

\useshortskip
\begin{align*}
\mathbf{kL(\Uptheta, t)} &= \mathbf{L(\tilde{\Uptheta}, t)} \nonumber \\ 
2*[3.00, 3.02, 3.30, 3.32] &=  [6.00, 6.04, 6.60, 6.64] \nonumber \\ 
[6.00, 6.04, 6.60, 6.64]  &= [6.00, 6.04, 6.60, 6.64] 1 \nonumber \\ 
\end{align*}
\useshortskip
\vspace*{-25mm}

\noindent \hrulefill
```

\noindent If a function has the property of being invariant under a
scaling factor, then it can also be expressed as the following
matrix-vector product shown in Equation \ref{eq:logistic-matrix-vector}
[@shapiro1987]:

\begin{align}
 \mathbf{L(\Uptheta, t)} = \mathbf{\Lambda\uptau},
(\#eq:logistic-matrix-vector)
\end{align}

\noindent where $\mathbf{\Uplambda}$ contains the partial derivative loadings\footnote{This is also known as a Jacobian matrix.} and
$\mathbf{\uptau}$ is a vector whose values are otbained by pre-multiplying the output of the logistic function ($\mathbf{L(\Uptheta, t)}$) by the inverse of the partial derivative loading matrix ${\Lambda\uptau}^{-1}$. Solving for $\mathbf{\uptau}$ yields a vector whose contents contain the mean values estimated for parameters that enter the logistic function in a linear way and
zeroes for parameters that enter the function in a nonlinear way (i.e.,
parameters that exist within their own partial derivative). Hence, $\mathbf{\uptau}$ is often called a mean vector [@blozis2004; @preacher2015].  In the current example, $\uptheta$ and $\upalpha$ enter the logistic function
in a linear way and $\upbeta$ and $\upgamma$ enter the logistic function
in a nonlinear way and so the first two entries of $\mathbf{\uptau}$
contain the values estimated for $\uptheta$ and $\upalpha$ (i.e.,
$\hat{\uptheta}$ and $\hat{\upalpha}$) and the last two entries contain zeroes. Example \ref{exm:tau-vector} below shows that the first two
values of $\mathbf{\uptau}$ are indeed the values estimated for
$\uptheta$ and $\upalpha$ and the last two values are zero.

```{example, tau-vector, echo=T}
Computation of mean vector $\mathbf{\uptau}$. 
  
 \noindent \textup{Given the parameter estimates of $\hat{\uptheta} = 3.00$, $\hat{\upalpha} = 3.32$, $\hat{\upbeta} = 180.00$, and $\hat{\upgamma} = 20.00$ and $\mathbf{t}$ = [0, 1, 2, 3], $\mathbf{\uptau}$ = [3.00, 3.32, 0, 0], then } 

\useshortskip
\begin{align*}
\mathbf{L(\Uptheta, t)} &= \mathbf{\Lambda\uptau} \\ 
[3.00, 3.02, 3.30, 3.32] &= \begin{bmatrix}
1.00 & 0.00 & 0.00  & 0.00 \\ 
0.95  & 0.05 & -0.00 & 0.00 \\ 
0.05 & 0.95 & -0.00 & -0.00 \\ 
0.00 & 1.00  & 0.00 & 0.00 \\
\end{bmatrix} \mathbf{\uptau} \\ 
\begin{bmatrix}
1.00 & 0.00 & 0.00  & 0.00 \\ 
0.95  & 0.05 & -0.00 & 0.00 \\ 
0.05 & 0.95 & -0.00 & -0.00 \\ 
0.00 & 1.00  & 0.00 & 0.00 \\
\end{bmatrix}^{-1}
\begin{bmatrix} 
3.00 \\ 3.02 \\ 3.30 \\ 3.32
\end{bmatrix} &=  \mathbf{\Lambda\uptau} \\ 
 \mathbf{\uptau} &= [3.00, 3.32, 0, 0]\\
\end{align*}
\vspace*{-25mm}

\noindent \hrulefill
```

\noindent With $\mathbf{L(\Uptheta, t)} = \mathbf{\Uplambda\uptau}$, Equation \ref{eq:slcm-nonsem} can be rewritten in a linear equation as shown below in Equation \ref{eq:taylor-linear}:

\begin{align}
 \mathbf{y_p} = \mathbf{\Uplambda\uptau} + \mathbf{\Uplambda\upiota_p} + \mathbf{\mathcal{E}_p}.
 (\#eq:taylor-linear)
 \end{align}
 
\noindent The mean vector $\mathbf{\uptau}$ and vector of
person-specific deviations $\mathbf{\upiota_p}$ can be combined into a
new vector $\mathbf{s_p}$ that represents the person-specific weights
applied to the basis curves in $\mathbf{\Uplambda}$ such that

$$  
\mathbf{s_p} = \mathbf{\uptau + \upiota_p} =
\begin{bmatrix} 
\hat{\uptheta} + \hat{\uptheta} - \uptheta_p \\ 
\hat{\upalpha} + \hat{\upalpha} - \upalpha_p \\ 
0 + \hat{\upbeta} - \upbeta_p \\ 
0 + \hat{\upgamma} - \upgamma_p \\ 
\end{bmatrix}
$$

\noindent and 

\begin{align}
\mathbf{y_p} = \mathbf{\Uplambda s_p} + \mathbf{\mathcal{E}_p}. 
(\#eq:taylor-final)
\end{align}

\noindent Because the expected value of the person-specific weights
($\mathbf{s_p}$) is the mean vector ($\mathbf{\uptau}$;
$\mathbb{E}[{\mathbf{s_p}}] = \mathbf{\uptau}$, the expected set
of scores predicted across all people ($\mathbb{E}[{\mathbf{y_p}}]$) gives back the original expression for the logistic function matrix-vector product in Equation
\ref{eq:logistic-matrix-vector} as shown below in Equation \ref{eq:expected-value}:

\begin{align}
 \mathbb{E}[{\mathbf{y_p}}] = \mathbf{\Uplambda\uptau} = \mathbf{L(\Uptheta, t)}. 
(\#eq:expected-value)
\end{align}

\noindent Therefore, the structured latent curve modelling approach
successfully reproduces the output of the nonlinear logistic function
(Equation \ref{eq:logistic}) with the linear function of Equation
\ref{eq:taylor-final}. Note that that no error term exists in Equation \ref{eq:expected-value} because the expected value of the error
values is zero ($\mathbb{E}[{\mathbf{\mathcal{E}_p}}] = 0$).

##### Estimating Parameters in the Structured Latent Curve Modelling Approach 

To estimate parameter values, the full-information maximum
likelihood shown in Equation \ref{eq:fiml-person} was computed for each
person (i.e., likelihood of observing a $p$ person's data given the
estimated parameter values):

\begin{align}
\mathcal{L}_p = k_p \ln(2\pi) + \ln(|\mathbf{\Sigma_p}| + (\mathbf{y_p} - \mathbf{\upmu_p})^\top \mathbf{\Sigma_p}^{-1}(\mathbf{y_p} - \mathbf{\upmu_p}),
(\#eq:fiml-person)
\end{align}


\noindent where $k_p$ is the number of non-missing values for a given
$p$ person, $\mathbf{\Sigma_p}$ is the model-implied covariance matrix
with rows and columns filtered at time points where person $p$ has
missing data, $\mathbf{y_p}$ is a vector containing the data points that
were collected for a $p$ person (i.e., filtered data), and
$\mathbf{\upmu_p}$ is the model-implied mean vector that is filtered at
time points where person $p$ has missing data. Note that, because all
simulations assumed complete data across all times points, no filtering
procedures were executed [for a review of the filtering procedure, see @boker2020, Chapter 5]. Thus, computing the above full-information
maximum likelihood in Equation \ref{eq:fiml-person} was equivalent to
computing the below likelihood function in Equation
\ref{eq:ml-estimation}:

\begin{align}
\mathcal{L}_p = k_p \ln(2\pi) + \ln(|\mathbf{\Sigma}| + (\mathbf{y_p} - \mathbf{\upmu})^\top \mathbf{\Sigma}^{-1}(\mathbf{y_p} - \mathbf{\upmu}),  
(\#eq:ml-estimation)
\end{align}

\noindent where $\mathbf{\Sigma}$ is the model-implied covariance matrix,
$\mathbf{y_p}$ contains the data collected from a $p$ person, and
$\mathbf{\upmu}$ is the model-implied mean vector. The model-implied
covariance matrix $\mathbf{\Sigma}$ is computed using Equation
\ref{eq:covariance} below:

\begin{align}
\mathbf{\Sigma} = \mathbf{\Uplambda\Uppsi\Uplambda} + \mathbf{\Upomega}_{\mathcal{E}},   
(\#eq:covariance)
\end{align}

\noindent where $\mathbf{\Uppsi}$ is the random-effect covariance matrix
and $\mathbf{\Upomega}_{\mathcal{E}}$ contains the error variances at
each time point. The mean vector $\mathbf{\upmu}$ was computed using
Equation \ref{eq:mean-structure} shown below:

\begin{align}
\mathbf{\upmu} = \mathbf{\Uplambda\uptau}. 
(\#eq:mean-structure)
\end{align}

\noindent Parameter estimation was conducted by finding values for the model-implied
covariance matrix $\mathbf{\Sigma}$ and the model-implied mean vector
$\mathbf{\upmu}$ that maximized the sum of log-likelihoods across all $P$ people
(see Equation \ref{eq:max-ll} below):

\begin{align}
\mathcal{L} = \underset{\mathbf{\Sigma},\mathbf{\upmu} }{\argmax} \sum^P_{p = 1} \mathcal{L}_p.
(\#eq:max-ll)
\end{align}

\noindent In OpenMx, the above problem was solved using the sequential
least squares quadratic program [for a review, see @kraft1994].

## Analysis of Dependent Variables

Among the several effect size metrics---at a broad level, effect size
metrics can represent standardized differences or variance-accounted-for
measures that are corrected or uncorrected for sampling error---the corrected
variance-accounted-for effect size metric of partial $\upomega^2$ was
chosen. Partial $\upomega^2$ has two desirable properties. First, partial
$\upomega^2$ is a less biased estimate of effect size than other
variance-accounted for measures were computed to investigate the effects
of experimental variables on the bias and variability of each logistic
parameter estimate. The effect size metric of partial $\upomega^2$
provides an unbiased estimate of effect size with larger cell sizes
(e.g., $n \ge 100$; [@okada2013]). Second, partial $\upomega^2$ is more
robust to assumption violations of normality and homogeneity of variance
[@yigit2018]. Given that the variability of parameter estimates was
often non-normally distributed across cells, effect size values computed
with using partial $\upomega^2$ should be relatively less biased than
other variance-accounted-for effect size metrics (e.g., $\eta^2$). To
compute partial $\upomega^2$ value for each experimental effect,
Equation \ref{eq:partial-omega} shown below was used:

```{=tex}
\begin{align}
\text{partial} \upomega^2 = \frac{\sigma^2_{effect}}{\sigma^2_{effect} + MSE} 
(\#eq:partial-omega)
\end{align}
```

\noindent where $\sigma^2_{effect}$ represents the variance attributable
to an effect and $MSE$ is the mean squared error.

### Analysis of Convergence Success Rate

For the analysis of convergence success rate, the mean convergence
success rate was computed for each condition (see section on
[convergence success rate]). Because convergence rates exhibited little
variability across cells due to the nearly unanimous high rates,
examining the effects of any independent variable on these rates using
partial $\upomega^2$ values would provided little information, and so
only descriptive statistics were reported (see [Appendix
B](#appendix-a-convergence-rates))

### Analysis of Bias

Bias was computed by calculating the raw difference between the each
parameter's estimate from a given model's output in a cell iteration and
the corresponding population value used for the parameter (see Equation
\ref{eq:bias}).

### Analysis of Variability in Parameter Estimation

To compute partial $\upomega^2$ values for variability in parameter
estimation, a Brown-Forsythe test was computed and the appropriate
sum-of-squares terms were used to compute partial $\upomega^2$ values.
To compute the Brown-Forsythe test, median absolute values were computed
from the median for each estimated value in each cell as shown in
Equation \ref{eq:brown-forsythe} shown below:
$$\text{Median absolute deviation}_{cell} = |\text{Parameter estimate}_i - \text{Median parameter estimate}_{cell}| $$
\begin{align}
\text{Median absolute deviation} = |\text{Parameter estimate} - \text{Median parameter estimate}_{cell}|.
(\#eq:brown-forsythe)
\end{align}

\noindent An ANOVA was then computed on the median absolute deviation
values, with the terms in Equation \ref{eq:partial-omega} extracted from
the ANOVA output to compute partial $\upomega^2$ values. Note that
deviations from the median value in each cell were used because using
the median protects against the biasing effects of skewed distributions
that were observed in the current simulation experiments [@brown1974].



```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```
# Experiment 1

```{=tex}
\nointerlineskip
\vfill
\newpage
```
## Overview of Data Processing and Modelling Procedure

Due to the considerable number of analyses conducted in each
experiment the sections that follow serve to equip
the reader with a framework to efficiently navigate the results sections
of each experiment. In the following sections, I will present overviews
of the following topics: a) Data pre-processing, b) meaning of logistic function parameters, c) presentation of variability in parameter estimation, d) interpretation of parameter estimation plots, and e) the model estimation procedure. 

### Pre-Processing of Data and Model Convergence

After collecting the output from the simulations, non-converged models
(and their corresponding parameter estimates) were removed from
subsequent analyses. Tables \ref{tab:conv-exp-1}--\ref{tab:conv-exp-3}
in [Appendix B](#appendix-a-convergence-rates) provide the convergence
success rates for each cell in each of the three simulation experiments.
Model convergence was almost always above 90% and convergence rates
rates below 90% only occurred in the following frequencies in each
experiment:

-   Experiment 1: two instances of sub-90% model convergence rates (see
    Table \ref{tab:conv-exp-1})
-   Experiment 2: two instances of sub-90% model convergence rates (see
    Table \ref{tab:conv-exp-2})
-   Experiment 3: two instances of sub-90% model convergence rates (see
    Table \ref{tab:conv-exp-3})

\noindent Note that all instances of sub-90% model convergence occurred
with five measurements.

### Review of Logistic Function Parameters Used to Generate Data


Data in each experimental condition were generated using the the
logistic function shown below in Equation
\ref{eq:logFunction-generation2}:

```{=tex}
\begin{align}
y_{pi} = \uptheta_p + \frac{\upalpha_p - \uptheta_p}{{1 + e^\frac{\upbeta_p - time_i}{\upgamma_p}}} + \upepsilon_{pi}.
(\#eq:logFunction-generation2)
\end{align}
```

\noindent where $\uptheta$ represents the baseline parameter, $\upalpha$
represents the maximal elevation parameter, $\upbeta$ represents the
days-to-halfway elevation parameter, and $\upgamma$ represents
triquarter-halfway delta parameter. Note that, values for $\uptheta$,
$\upalpha$, $\upbeta$, and $\upgamma$ were generated for each *p* person
across all *i* time points, with an error value being randomly generated
at each *i* time point ($\upepsilon_{ij}$). In other words, unique
response patterns were generated for each person in each of the 1000
data sets generated per cell. For a review of the logistic function, see
the section on [data generation][Data generation].

### Presentation of Variability

Given that sampling error causes any population parameter to be
estimated with some degree of variability and that two of the three
simulation experiments manipulated sample size, variability was expected
to occur in the estimation of the logistic function parameters. Even in
situations where sample size was not manipulated (as in Experiment 1) and
where it may have seemed unusual for other independent variables to affect the
variability with which a parameter was estimated, variables outside of
sample size have been shown to affect the variability of parameter
estimation on occasion (e.g., @coulombe2016). Given that the variability
of parameter estimation may be affected in each simulation experiment,
the paragraphs that follow explain how variability was
operationalized and visualized.

Variability in the estimation of each logistic function parameter for
each experimental condition was operationalized as the range covered
by the middle 95% of estimated values. Consider an example where
variability in the days-to-halfway elevation parameter ($\upbeta$) is
being modelled in an experimental condition. Figure
\ref{fig:beta-histogram} shows a density distribution of values
estimated for the days-to-halfway elevation parameter ($\upbeta$). The
region of the density distribution shaded in gray represents the middle
95% of values estimated for the days-to-halfway elevation parameter
($\upbeta$) and the upper and lower values of this region set the upper
and lower values of the error bar that lies above the density
distribution. Therefore, I used error bars to represent variability in parameter estimation because using density distributions for each of the nine
parameters in each experimental cell would have been impractical given the
large number of cells in each experiment.

To visualize variability across multiple experimental conditions for one
logistic function parameter, parameter estimation plots were
constructed. Figure \ref{fig:beta-density-to-param-plot} shows the
procedure that was followed to create a parameter estimation plot. For
each measurement number-sample size condition, a density distribution was
computed for the values estimated for the days-to-halfway elevation
parameter ($\upbeta$), and the range covered by the middle 95% of values
in the density distribution was used to set the length of each error bar.
The plot at the bottom of Figure \ref{fig:beta-density-to-param-plot} is
a **parameter estimation plot** for the days-to-halfway elevation
parameter (specifically, the fixed-effect days-to-halfway elevation
parameter [$\upbeta_{fixed}$]) with the error bars showing the
variability with which $\upbeta_{fixed}$ is modelled in each sample
size-measurement number condition. This style of error bar was used
to represent variability for each parameter in each experimental
condition.

```{r variability-histograms, eval=F, include=F}
exp_2 <- read_csv(file = 'data/exp_2.csv')

generate_param_density_plot(raw_exp_data = exp_2, param_summary_data = param_summary_exp_2, spacing = 'Equal', num_measurements = 5, sample_size = 30)

```

```{=tex}
\begin{figure}
  \caption{Density Distribution of Values Estimated for the Days-to-Halfway Elevation Parameter ($\upbeta$)}
  \label{fig:beta-histogram}
  \includegraphics[height = 8cm, width = 20cm]{Figures/beta_fixed_Equal_5_30} \hfill{}
  \caption*{Note. \textup{Area shaded in gray represents the middle 95\% of estimated values. The upper and lower limits of the shaded areay define the upper and lower limits of the error bar on top of the density distribution.}}
\end{figure}
```
```{r beta-density-to-param-plot, eval=F, include=F}
num_measurements_levels <- as.numeric(levels(param_summary_exp_2$number_measurements))
sample_size_levels <- range(as.numeric(levels(param_summary_exp_2$sample_size)))
exp_2 <- read_csv(file = 'data/exp_2.csv')

for (num_measurements in num_measurements_levels) {
  
  for(sample_size in sample_size_levels){
    
    generate_param_density_plot(raw_exp_data = exp_2, param_summary_data = param_summary_exp_2, 
                                spacing = 'Equal', num_measurements = num_measurements,
                                sample_size = sample_size)
  }
}
```

```{=tex}
\begin{figure}
  \caption{Depiction of Modelling Procedure for Generating Error Bars on Parameter Estimation Plots}
  \label{fig:beta-density-to-param-plot}
  \includegraphics[height = 25cm, width = 10cm]{Figures/density_to_param_plot} \hfill{}
  \caption*{Note. \textup{Density distributions are generated for each experimental condition and the range covered by the middle 95\% of values in each frequnecy distribution is used to create an error bar. The plot at the bottom is a \textbf{parameter estimation plot} for the days-to-halfway elevation parameter ($\upbeta$) and it shows the accuracy with which $\upbeta$ is estimated across all sample size-measurement number combinations when measurement spacing is equal.}}
\end{figure}
```

### Interpreting a Parameter Estimation Plot

Given that several parameter estimation plots were presented in the
results sections of each experiment, I will provide an overview of how
to interpret these plots. Parameter estimation plots show two indicators
of estimation accuracy: bias and variability. In the sections that
follow, these two accuracy indicators are shown in parameter estimation
plots.

#### Bias

Figure \ref{fig:param-estimation-ex} shows a parameter estimation plot
for the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$). Estimates for the fixed-effect days-to-halfway
elevation parameter ($\upbeta_{fixed}$) are shown across all measurement
number-sample size combinations and the shaded gray line indicates the
population value set for the parameter ($\upbeta_{fixed}$ = 180). The
black shapes (squares, circles, triangles, diamonds) indicate the
average estimated value and the error bars show the range of values
covered by the middle 95% of estimated parameters (for a review, see
[Presentation of variability]).

**Bias** describes the extent to which an estimate either over- or
underestimates the population value. Looking at the parameter estimation
plot in Figure \ref{fig:param-estimation-ex}, systematic bias is
represented by the extent to which a black shape lies away from the gray
line (i.e., the population value). In the current example, the average
estimated values in each measurement number-sample size condition lie
close to the population value (the gray line), and so bias is nearly
trivial in each condition.

#### Variability

**Variability** describes by the length of the error bars in the
parameter estimation plot. In the current example of Figure
\ref{fig:param-estimation-ex}, variability decreases monotonically as
sample size and measurement number increase.

```{=tex}
\begin{figure}
  \caption{Parameter Estimation Plot for Fixed-Effect Days-to-Halfway Elevation Parameter ($\upbeta_{fixed}$)}
  \label{fig:param-estimation-ex}
  \includegraphics[height = 33cm, width = 15cm]{Figures/param_estimation_ex} \hfill{}
  \caption*{Note. \textup{The shaded gray line indicates the population value set for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Estimates for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) parameter are shown across all measurement number-sample size combinations and the shaded gray line indicates the population value set for the parameter ($\upbeta_{fixed}$ = 180). The black shapes (squares, circles, triangles, diamonds) indicate the average estimated value and the error bars show the range of values covered by the middle 95\% of estimated parameters. Parameter estimation plots show two markers of estimation accuracy: systematic bias and variability. \textbf{Systematic bias} describes the extent to which an estimate either over- or underestimates the population value. In the parameter estimation plot, systematic bias is represented by the extent to which a black shape falls off from the gray line (i.e., the population value). \textbf{Variability} is described by the length of the error bars in the parameter estimation plot. In the current example, systematic bias is very low because all of the average estimated values lie close to the population value (i.e., shaded gray line) and variability decreases monotonically as sample size increases.}}
\end{figure}
```

### Identifying Minimal Effect Sizes of Interest for Bias and Variability 

#### Minimal Effect Size for Bias 

#### Minimal Effect Size for Variability

### Model Estimation Procedure

Because a considerable number of parameters were estimated in each cell,
I will review the modelling procedure as a whole. Figure
\ref{fig:results-plot-primer} shows that each parameter of the logistic
function (for each parameter, see Figure \ref{fig:combined_plot}) was
modelled as a fixed and random effect. Values predicted for fixed-effect
parameters are constant across all individuals, whereas values predicted
for random-effect parameters represent the variability with which a
parameter is
estimated.\footnote{Estimating a random-effect for a parameter allows person-specific values to be computed for the parameter.}
In addition to the random- and fixed-effects estimated for each logistic
function parameter, an error term ($\upepsilon$) was also estimated. For
each cell, parameter estimation plots were be created for each logistic
function parameter that showed the accuracy with which that parameter
was modelled.

One important point to mention is that the results of Experiments 1--3
focused on the effects of experimental variables on day-unit parameters
(days-to-halfway elevation [$\upbeta$; Figure
\ref{fig:combined_plot}C] and halfway-triquarter delta
parameters[$\upgamma$; Figure \ref{fig:combined_plot}D]. Across all
three experiments, experimental variables had little effect on the
estimation of Likert-unit parameters (baseline [$\uptheta$; Figure
\ref{fig:combined_plot}A] and maximal elevation [$\upalpha$]; Figure
\ref{fig:combined_plot}B), and so including their estimation plots would
have added unnecessary length and complexity to the results sections of
each experiment. Note that the parameter estimation plots for
Likert-unit parameters were been included in [Appendix
C](#appendix-c-parameter-estimation-plots-for-likert-unit-parameters).

```{=tex}
\begin{figure}[H]
  \caption{Set of Parameters Estimated in Each Simulation Experiment}
  \label{fig:results-plot-primer}
  \includegraphics[height = 17cm, width = 15cm]{Figures/logistic_results_plot} \hfill{}
  \caption*{Note. \textup{Each parameter of the logistic function (for a review, see Figure \ref{fig:combined_plot}) is modelled as a fixed and random effect. Values predicted for fixed-effect parameters are constant across all individuals, whereas values predicted for random-effect parameters are unique across individuals. In addition the random- and fixed-effects estimated for each logistic function parameter, an error term ($\upepsilon$) is also estimated. For each experimental condition, parameter estimation plots will be created for each logistic function parameter that show the accuracy with which each parameter is modelled.}}
\end{figure}
```
## Results

Experiment 1 investigated the extent to which measurement spacing
schedules could accurately model logistic function parameters under
different patterns of change. Three variables were manipulated:
measurement spacing, number of measurements, and pattern of change.
Measurement spacing was manipulated by creating schedules defined by
either equal, time-increasing, time-decreasing, or middle-and-extreme
spacing. Number of measurements was manipulated to take on a value of
either 5, 7, 9, or 11 measurements. Pattern of change was manipulated
such that the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$) occurred at either 80, 180, or 280 days.

### Equal Spacing

```{r plots-equal-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Equal spacing',
                                x_axis_name = expression("Population value set for"~beta[fixed]), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -20, beta_upper = 20, ticks = 5)

```

```{r text-values-equal-exp1, echoF}
gamma_rand_equal_5_180 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 7, midpoint == 180, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci),
         estimate = as.integer(estimate)) 

gamma_fixed_equal_5_80 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, midpoint == 80, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

gamma_fixed_equal_5_180 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, midpoint == 180, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

gamma_fixed_equal_5_280 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, midpoint == 280, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

gamma_fixed_equal_7_180 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 7, midpoint == 180, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 
```

Figure \ref{fig:exp1_plot_equal} shows the parameter estimation plots
for the day-unit parameters when equal spacing was used (error bars
represent the middle 95% of estimated values and shaded horizontal lines
indicate the population values). Panels A--B show the parameter
estimation plots for the fixed- and random-effect days-to-halfway
elevation parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$,
respectively. Panels C--D show the parameter estimation plots for the
fixed- and random-effect triquarter-halfway elevation parameters
($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that, in
Panel A, estimates for $\upbeta_{fixed}$ are centered around their
corresponding population values (80, 180, and 280 days), and so the
y-axis represents error (in number of days) from the population value. Note that Table \ref{tab:omega-exp1-equal} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under equal spacing. 

For all simulations presented in Figure \ref{fig:exp1_plot_equal}, only
one instance of bias occurred. With five measurements and a population
value for the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$) set to 180, the random-effect triquarter-halfway
delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_equal}D)
was overestimated, with the average estimated value being
`r gamma_rand_equal_5_180$estimate` days (relative to a population value
of 4.00 days). Across all other conditions in Figure
\ref{fig:exp1_plot_equal}, no instance of bias occurred, as the average
estimated values for all day-unit parameters (as indicated by the black
dots) were close to their respective population values (indicated by the
gray lines).

With respect to variability, two general patterns of results emerged in
the estimation of day-unit parameters with equal spacing. First,
estimation of all day-unit parameters incurred considerable variability
with five measurements across all population values set for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$ =
{80, 180, 280}). For example, the fixed-effect halfway-triquarter delta
parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_equal}B) had an
error bar length of approximately
`r gamma_fixed_equal_5_80$upper_ci - gamma_fixed_equal_5_80$lower_ci`
days when $\upbeta_{fixed}$ was 80 (upper bound of
`r gamma_fixed_equal_5_80$upper_ci` days to lower bound of
`r gamma_fixed_equal_5_80$lower_ci` days), an error bar length of
approximately
`r gamma_fixed_equal_5_180$upper_ci - gamma_fixed_equal_5_180$lower_ci`
days when $\upbeta_{fixed}$ was 180 (upper bound of
`r gamma_fixed_equal_5_180$upper_ci` days to lower bound of
`r gamma_fixed_equal_5_180$lower_ci` days), and an error bar length of
approximately
`r gamma_fixed_equal_5_280$upper_ci - gamma_fixed_equal_5_280$lower_ci`
days (upper bound of `r gamma_fixed_equal_5_280$upper_ci` days to lower
bound of `r gamma_fixed_equal_5_280$lower_ci` days) when
$\upbeta_{fixed}$ was 280. Note that, in contrast, estimation for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$;
Figure \ref{fig:exp1_plot_equal}A) showed considerably low variability
with five measurements and a population value of 180. Second, the
considerable variability in parameter estimation observed with five
measurements largely diminished with seven measurements. As an example,
with a population value for $\upbeta_{fixed}$ of 180, the error bar
length for the fixed-effect triquarter-halfway delta parameter
($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_equal}B) spanned
approximately
`r gamma_fixed_equal_5_180$upper_ci - gamma_fixed_equal_5_180$lower_ci`
days with five measurements (upper bound of
`r gamma_fixed_equal_5_180$upper_ci` to a upper bound of
`r gamma_fixed_equal_5_180$lower_ci` days), but the length of this error
bar decreased to approximately
`r gamma_fixed_equal_7_180$upper_ci - gamma_fixed_equal_7_180$lower_ci`
days with seven measurements (upper bound of
`r gamma_fixed_equal_7_180$upper_ci` to a lower bound
`r gamma_fixed_equal_7_180$lower_ci` days).

```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Equal Spacing in Experiment 1}
  \label{fig:exp1_plot_equal}
  \includegraphics{Figures/exp1_plot_days_equal spacing} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that, in Panel A, estimates for $\upbeta_{fixed}$ are centered around their corresponding population values (80, 180, and 280 days), and so the y-axis represents error (in number of days) from the population value. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-equal} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp1-equal, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'equal', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'M', 'NM x M'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Equal Spacing in Experiment 1',
footnote = 'NM = number of measurements (5, 7, 9, 11), M = population value set for $\\\\upbeta_{fixed}$ (80, 180, 280), NM x M = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. \\\\phantom{ indicate conditions where}', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_equal}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_equal}D)'))
```

\newpage

### Time-Interval Increasing Spacing

```{r plots-time-increasing-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Time-interval increasing',
                                x_axis_name = expression("Population value set for"~beta[fixed]), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -70, beta_upper = 60, ticks = 10)
```

```{r density-plot-functions, include=F, eval=F}
compute_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_95_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_80_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_80_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_90_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_90_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_density <- function(error_bar_range, group, param_name, density_data) { 
  
  density_data <- density_data[density_data$group == group , ]
  
  density_lower_x <- min(which(density_data$x >= error_bar_range[1]))
  density_upper_x <- max(which(density_data$x <= error_bar_range[2]))
  
  day_values <- density_data$x[density_lower_x:density_upper_x]
  
  
  density_df <- data.frame('parameter' = param_name,
                           'day_value' = day_values,
                           'probability' = density_data$y[density_lower_x:density_upper_x], 
                           'max_density_value' = max(density_data$y),
                           'lower_ci' = error_bar_range[1], 
                           'upper_ci' = error_bar_range[2])

    return(density_df)
}
```

```{r exp1-density-plot-time-inc, include=F, eval=F}
##generate figure showing density distributions if gamma_fizxd at N = 500 and N = 1000 with middle 95% area shaded. Emphasize
##that longer error bars in  N = 1000 are likely a statistical artifact of the random number generating procedure. 
exp_1 <- read_csv('data/exp_1A.csv') %>% filter(code == 0) #load data 
exp_1 <- convert_raw_var_to_sd(raw_data = exp_1) #var to sd conversion 

parameter_names <- c(bquote(expr = bold(A:~gamma[random]~(beta[fixed]~" = 280, 5 measurements"))),
                     bquote(expr =bold(B:~gamma[random]~(beta[fixed]~" = 280, 7 measurements"))))
                     
#1) Extract estimates for four parameter gamma_fixed and beta_rand when N =500 or 1000, num_measurements == 5, spacing == equal. 
##Convert to long format, with parameter name going into unique column and estimate becoming new column 
param_data <- exp_1 %>%
  filter(number_measurements <= 7, measurement_spacing == 'time_inc', midpoint == 280) %>%
  select(locate_ivs(exp_1),'gamma_rand') %>%
  pivot_longer(cols = c(gamma_rand), values_to = 'estimate') %>%
  unite(col = 'parameter', c(number_measurements,name))

#2) Replace parameter values with tag labels. 
param_data$parameter <- factor(param_data$parameter, 
                               levels = c("5_gamma_rand", "7_gamma_rand"), 
                               labels = parameter_names)

base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
density_data <- ggplot_build(plot = base_density_plot)$data[[1]]

param_search_names <- c("A\\:", "B\\:")

param_error_bar_ranges <- lapply(X = param_search_names, compute_ind_param_error_bar_range, param_data = param_data)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


example_plot <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = example_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_time_inc_exp1.pdf')

```

```{r exp1-density-plot-time-inc-fixed, include=F, eval=F}
param_error_bar_ranges <- lapply(X = param_search_names, compute_80_ind_param_error_bar_range, param_data = param_data)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


time_inc_fixed_density <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = time_inc_fixed_density, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_time_inc_exp1_fixed.pdf')

```

```{r text-values-time-increasing-exp1, echoF}
beta_time_inc_5_80 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval increasing', number_measurements == 5, midpoint == 80, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_time_inc_5_180 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval increasing', number_measurements == 5, midpoint == 180, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_time_inc_5_280 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval increasing', number_measurements == 5, midpoint == 280, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_time_inc_7_280 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval increasing', number_measurements == 7, midpoint == 180, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))
```


Figure \ref{fig:exp1_plot_time_increasing} shows the parameter
estimation plots for the day-unit parameters when equal spacing was used
(error bars represent the middle 95% of estimated values and shaded
horizontal lines indicate the population values). Panels A--B show the
parameter estimation plots for the fixed-effect days-to-halfway
elevation and triquarter-halfway delta parameters ($\upbeta_{fixed}$ and
$\upgamma_{fixed}$), respectively. Panels C--D show the parameter
estimation plots for the random-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{random}$ and
$\upgamma_{random}$), respectively. Note that, in Panel A, estimates for
$\upbeta_{fixed}$ are centered around their corresponding population
values (80, 180, and 280 days), and so the y-axis represents error (in
number of days) from the population value. Note that Table \ref{tab:omega-exp1-time-inc} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under time-interval increasing spacing. 

For all simulations presented in Figure
\ref{fig:exp1_plot_time_increasing}, no instance of bias occurred, as
the average estimated values for all day-unit parameters (as indicated
by the black dots) were close to their respective population values
(indicated by the gray lines).

With respect to variability, two general patterns of results emerged in
the estimation of day-unit parameters with time-interval increasing
spacing. First, for all day-unit parameters except the random-effect
halfway-triquarter delta parameter ($\upgamma_{random}$; Figure
\ref{fig:exp1_plot_time_increasing}D), variability increased
considerably with five measurements as the population value set for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$)
increased from 80 to 280. As an example, the error bar length for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$;
Figure \ref{fig:exp1_plot_time_increasing}A) spanned approximately
`r beta_time_inc_5_80$upper_ci - beta_time_inc_5_80$lower_ci` (upper
bound of `r beta_time_inc_5_80$upper_ci` days to a lower bound of
`r beta_time_inc_5_80$lower_ci` days) and
`r beta_time_inc_5_180$upper_ci - beta_time_inc_5_180$lower_ci` days
(upper bound of `r beta_time_inc_5_180$lower_ci` days to a lower bound
of `r beta_time_inc_5_180$upper_ci` days) when the $\upbeta_{fixed}$ had
a population value of 80 and 180 days, respectively, but the length
increased to
`r beta_time_inc_5_280$upper_ci - beta_time_inc_5_280$lower_ci` days
when the population value for $\upbeta_{fixed}$ was set to 280 (upper
bound of `r beta_time_inc_5_280$upper_ci` days to a lower bound of
`r beta_time_inc_5_280$lower_ci` days). Second, the large amounts of
variability observed for the parameters with five measurements largely
disappeared with seven or more measurements. As an example, when the
population value for the days-to-halfway elevation parameter
($\upbeta_{fixed}$) was set to 280, the long error bar range of
`r beta_time_inc_5_280$upper_ci - beta_time_inc_5_280$lower_ci` days for
the estimation of $\upbeta_{fixed}$ (Figure
\ref{fig:exp1_plot_time_increasing}A) with five measurements decreased
to a shorter length of
`r beta_time_inc_7_280$upper_ci - beta_time_inc_7_280$lower_ci` days
with seven measurements.

```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Time-Interval Increasing Spacing in Experiment 1}
  \label{fig:exp1_plot_time_increasing}
  \includegraphics{Figures/exp1_plot_days_time-interval increasing.png} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that, in Panel A, estimates for $\upbeta_{fixed}$ are centered around their corresponding population values (80, 180, and 280 days), and so the y-axis represents error (in number of days) from the population value. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-inc} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp1-time-inc, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'time_inc', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'M', 'NM x M'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Increasing Spacing in Experiment 1',
footnote = 'NM = number of measurements (5, 7, 9, 11), M = population value set for $\\\\upbeta_{fixed}$ (80, 180, 280), NM x M = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. \\\\phantom{ indicate conditions where}', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_increasing}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_increasing}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_increasing}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_increasing}D)'))
```

One additional minor point should be mentioned. In Figure
\ref{fig:exp1_plot_time_increasing}D, the variability of values
estimated for the random-effect triquarter-halfway delta
($\upgamma_{fixed}$) parameter counterintuitively increased as the
number of measurements increased from five to seven. Inspection of the
underlying density plots for the random-effect triquarter-halfway delta
parameter ($\upgamma_{fixed}$) in Figure
\ref{fig:exp1_density_time_increasing} showed that the increase was not
due to outliers and, rather, occurred because of a slight increase in
the variability of the parameter estimates (see the estimates located
within the dashed rectangle). When the fixed-effect days-to-halfway
elevation parameter ($\upbeta_{fixed}$) was set to 80, the density
distribution for the random-effect triquarter-halfway delta parameter
($\upgamma_{fixed}$) became slightly flatter as the number of
measurements increased from five (Figure
\ref{fig:exp1_density_time_increasing}A) to seven (Figure
\ref{fig:exp1_density_time_increasing}B).

```{=tex}
\begin{figure} [H]
  \caption{Density Plots of the Random-Effect Halfway-Triquarter Delta ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_increasing}D) With Time-Interval Increasing Spacing in Experiment 1 (95\% Error Bars)}
  \label{fig:exp1_density_time_increasing}
  \includegraphics[height = 15cm, width = 25cm]{Figures/density_plots_time_inc_exp1} \hfill{}
  \caption*{Note. \textup{Regions shaded in in gray represent the the middle 95\% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. The error bar length increases as the number of measurements increases from five to seven.}}
\end{figure}
```


### Time-Interval Decreasing Spacing

```{r plots-time-decreasing-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Time-interval decreasing',
                                x_axis_name = expression("Population value set for"~beta[fixed]),
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -60, beta_upper = 70, ticks = 10)
```

```{r exp1-density-plot-time-dec, include=F, eval=F}
##generate figure showing density distributions if gamma_fizxd at N = 500 and N = 1000 with middle 95% area shaded. Emphasize
##that longer error bars in  N = 1000 are likely a statistical artifact of the random number generating procedure. 
exp_1 <- read_csv('data/exp_1_zero.csv') %>% filter(code == 0) #load data 
exp_1 <- convert_raw_var_to_sd(raw_data = exp_1) #var to sd conversion 

parameter_names <- c(bquote(expr = bold(A:~gamma[random]~(beta[fixed]~" = 80, 5 measurements"))),
                     bquote(expr =bold(B:~gamma[random]~(beta[fixed]~" = 80, 7 measurements"))))
                     
#1) Extract estimates for four parameter gamma_fixed and beta_rand when N =500 or 1000, num_measurements == 5, spacing == equal. 
##Convert to long format, with parameter name going into unique column and estimate becoming new column 
param_data <- exp_1 %>%
  filter(number_measurements <= 7, measurement_spacing == 'time_dec', midpoint == 80) %>%
  select(locate_ivs(exp_1),'gamma_rand') %>%
  pivot_longer(cols = c(gamma_rand), values_to = 'estimate') %>%
  unite(col = 'parameter', c(number_measurements,name))

#2) Replace parameter values with tag labels. 
param_data$parameter <- factor(param_data$parameter, 
                               levels = c("5_gamma_rand", "7_gamma_rand"), 
                               labels = parameter_names)

base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3, alpha = 0) 

##create density data for each parameter 
density_data <- ggplot_build(plot = base_density_plot)$data[[1]]

param_search_names <- c("A\\:", "B\\:")

param_error_bar_ranges <- lapply(X = param_search_names, compute_ind_param_error_bar_range, param_data = param_data)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


density_time_dec_exp_1 <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = density_time_dec_exp_1, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_time_dec_exp1.pdf')

```

```{r exp1-density-plot-time-dec-fixed, include=F, eval=F}
param_error_bar_ranges <- lapply(X = param_search_names, compute_80_ind_param_error_bar_range, param_data = param_data)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


time_dec_fixed_density <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = time_dec_fixed_density, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_time_dec_exp1_fixed.pdf')

```

```{r text-values-time-decreasing-exp1, echoF}
beta_time_dec_5_80 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval decreasing', number_measurements == 5, midpoint == 80, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_time_dec_5_180 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval decreasing', number_measurements == 5, midpoint == 180, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_time_dec_5_280 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval decreasing', number_measurements == 5, midpoint == 280, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_time_dec_7_80 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval decreasing', number_measurements == 7, midpoint == 80, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))
```

Figure \ref{fig:exp1_plot_time_decreasing} shows the parameter
estimation plots for the day-unit parameters when equal spacing was used
(error bars represent the middle 95% of estimated values and shaded
horizontal lines indicate the population values). Panels A--B show the
parameter estimation plots for the fixed-effect days-to-halfway
elevation and triquarter-halfway delta parameters ($\upbeta_{fixed}$ and
$\upgamma_{fixed}$), respectively. Panels C--D show the parameter
estimation plots for the random-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{random}$ and
$\upgamma_{random}$), respectively. Note that, in Panel A, estimates for
$\upbeta_{fixed}$ are centered around their corresponding population
values (80, 180, and 280 days), and so the y-axis represents error (in
number of days) from the population value. Note that Table \ref{tab:omega-exp1-time-dec} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under time-interval decreasing spacing. 

For all simulations presented in Figure
\ref{fig:exp1_plot_time_decreasing}, no instance of bias occurred, as
the average estimated values for all day-unit parameters (as indicated
by the black dots) were close to their respective population values
(indicated by the gray lines).

With respect to variability, two general patterns of results emerged in
the estimation of day-unit parameters with time-interval decreasing
spacing. First, for all day-unit parameters except the random-effect
halfway-triquarter delta ($\upgamma_{random}$; Figure
\ref{fig:exp1_plot_time_decreasing}D), variability increased
considerably with five measurements and the population value set for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$)
decreased from 280 to 80 days. As an example, the error bar length for
the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$;
Figure \ref{fig:exp1_plot_time_decreasing}A) spanned approximately
`r beta_time_dec_5_280$upper_ci - beta_time_dec_5_280$lower_ci`(upper
bound of `r beta_time_dec_5_280$upper_ci` days to a lower bound of
`r beta_time_dec_5_280$lower_ci` days) and
`r beta_time_dec_5_180$upper_ci - beta_time_dec_5_180$lower_ci` days
(upper bound of `r beta_time_dec_5_180$upper_ci` days to a lower bound
of `r beta_time_inc_5_180$lower_ci` days) when $\upbeta_{fixed}$ had a
population value of 280 and 180 days, respectively, but the error bar
length increased to
`r beta_time_dec_5_80$upper_ci - beta_time_dec_5_80$lower_ci` days
(upper bound of `r beta_time_dec_5_80$upper_ci` days to a lower bound of
`r beta_time_dec_5_80$lower_ci` days) $\upbeta_{fixed}$ had a population
value of 80. Second, the large amounts of variability observed for the
parameters with five measurements largely disappeared with seven or more
measurements. As an example, when the population value for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$;
Figure \ref{fig:exp1_plot_time_decreasing}A) was set to 80, the long
error bar range of
`r beta_time_dec_5_80$upper_ci - beta_time_dec_5_80$lower_ci` days with
five measurements decreased to a shorter length of
`r beta_time_dec_7_80$upper_ci - beta_time_dec_7_80$lower_ci` days with
seven measurements.

```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 1}
  \label{fig:exp1_plot_time_decreasing}
  \includegraphics{Figures/exp1_plot_days_time-interval decreasing.png} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that, in Panel A, estimates for $\upbeta_{fixed}$ are centered around their corresponding population values (80, 180, and 280 days), and so the y-axis represents error (in number of days) from the population value. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-dec} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp1-time-dec, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'time_dec', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'M', 'NM x M'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 1',
footnote = 'NM = number of measurements (5, 7, 9, 11), M = population value set for $\\\\upbeta_{fixed}$ (80, 180, 280), NM x M = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. \\\\phantom{ indicate conditions where}', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_decreasing}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_decreasing}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_decreasing}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_decreasing}D)'))
```

```{=tex}
\begin{figure} [H]
  \caption{Density Plots of the Random-Effect Halfway-Triquarter Delta ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_decreasing}D) With Time-Interval Decreasing Spacing in Experiment 1 (95\% Error Bars)}
  \label{fig:exp1_density_time_decreasing}
  \includegraphics[height = 15cm, width = 30cm]{Figures/density_plots_time_dec_exp1} \hfill{}
  \caption*{Note. \textup{Regions shaded in in gray represent the the middle 95\% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. The error bar length increases as the number of measurements increases from five to seven.}}
\end{figure}
```
One additional minor point should be mentioned. In Figure
\ref{fig:exp1_density_time_decreasing}D, the variability of values
estimated for the random-effect triquarter-halfway delta
($\upgamma_{fixed}$) parameter counterintuitively increased as the
number of measurements increased from five to seven (see the estimates
located within the dashed rectangle). Inspection of the underlying
density plots for the random-effect triquarter-halfway delta parameter
($\upgamma_{fixed}$) in Figure \ref{fig:exp1_density_time_decreasing}
showed that the increase was not due to outliers and, rather, occurred
because of a slight increase in the variability of the parameter
stimates. When the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$) was set to 280, the density distribution for the
random-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$)
became slightly flatter as the number of measurements increased from
five (Figure \ref{fig:exp1_density_time_decreasing}A) to seven (Figure
\ref{fig:exp1_density_time_decreasing}B).

### Middle-and-Extreme Spacing

```{r plots-mid-ext-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Middle-and-extreme spacing',
                                x_axis_name = expression("Population value set for"~beta[fixed]), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -80, beta_upper = 80, ticks = 10)
```

```{r text-values-mid-ext-exp1, echoF}
beta_mid_ext_5_80 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 5, midpoint == 80, grepl('beta\\[fixed\\]', parameter)) %>%
  select(midpoint, lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci), 
         estimate = as.integer(estimate))

beta_mid_ext_5_180 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 5, midpoint == 180, grepl('beta\\[fixed\\]', parameter)) %>%
  select(midpoint, lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_mid_ext_5_280 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 5, midpoint == 280, grepl('beta\\[fixed\\]', parameter)) %>%
  select(midpoint, lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci), 
         estimate = as.integer(estimate))


beta_mid_ext_7_280 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 7, midpoint == 280, grepl('beta\\[fixed\\]', parameter)) %>%
  select(midpoint, lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))


beta__rand_mid_ext_7_280 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 7, midpoint == 280, grepl('beta\\[random\\]', parameter)) %>%
  select(midpoint, lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta__rand_mid_ext_7_80 <- exp_1_analytical$days %>% 
  filter(measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 7, midpoint == 80, grepl('beta\\[random\\]', parameter)) %>%
  select(midpoint, lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))
```

Figure \ref{fig:exp1_plot_time_mid_ext} shows the parameter estimation
plots for the day-unit parameters when equal spacing was used (error
bars represent the middle 95% of estimated values and shaded horizontal
lines indicate the population values). Panels A--B show the parameter
estimation plots for the fixed-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{fixed}$ and
$\upgamma_{fixed}$), respectively. Panels C--D show the parameter
estimation plots for the random-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{random}$ and
$\upgamma_{random}$), respectively. Note that, in Panel A, estimates for
$\upbeta_{fixed}$ are centered around their corresponding population
values (80, 180, and 280 days), and so the y-axis represents error (in
number of days) from the population value. Note that Table \ref{tab:omega-exp1-time-inc} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under middle-and-extreme spacing. 

For all simulations presented in Figure
\ref{fig:exp1_plot_time_mid_ext}, one instance of bias occurred. With
five measurements and a population value for the fixed-effect
days-to-halfway elevation parameter ($\upbeta_{fixed}$) set to either 80
or 280, the random-effect days-to-halfway elevation parameter
($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}C) was
slightly overestimated, with respective average estimated values of
`r beta_mid_ext_5_80` and `r beta_mid_ext_5_280` days (relative to a
population value of 10.00 days). For all other conditions across all
day-unit parameters in Figure \ref{fig:exp1_plot_time_mid_ext}, no
instance of bias occurred, as the average estimated values for all
day-unit parameters (as indicated by the black dots) were close to their
respective population values (indicated by the gray lines).

With respect to variability, two general patterns of results emerged in
the estimation of day-unit parameters with middle-and-extreme spacing.
First, for all the day-unit parameters except the random effect of the
halfway-triquarter delta parameter ($\upgamma_{random}$), variability
increased considerably with five measurements and the fixed-effect
days-to-halfway elevation parameter ($\upbeta_{fixed}$) had population
values of 80 or 280. As an example, the error bar length for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$)
spanned approximately
`r beta_mid_ext_5_180$upper_ci - beta_mid_ext_5_180$lower_ci` days when
the $\upbeta_{fixed}$ had a population value of 180 (upper bound of
`r beta_mid_ext_5_180$upper_ci` days and a lower bound of
`r beta_mid_ext_5_180$lower_ci` days), but the length increased to
`r beta_mid_ext_5_80$upper_ci - beta_mid_ext_5_80$lower_ci` days (upper
bound of `r beta_mid_ext_5_80$upper_ci` days and a lower bound of
`r beta_mid_ext_5_80$lower_ci` days) when $\upbeta_{fixed}$ had a
population value of 80 and
`r beta_mid_ext_5_280$upper_ci - beta_mid_ext_5_280$lower_ci` days
(upper bound of `r beta_mid_ext_5_280$upper_ci` days and a lower bound
of `r beta_mid_ext_5_280$lower_ci` days) when $\upbeta_{fixed}$ had a
population value of 280. Second, the large amounts of variability
observed for the parameters with five measurements largely disappeared
when seven or more measurements were taken. As an example, when the
fixed-effect days-to-halfway elevation parameter($\upbeta_{fixed}$) had
a population value of 280, the error bar range for the
estimation$\upbeta_{fixed}$ spanned approximately
`r beta_mid_ext_5_280$upper_ci - beta_mid_ext_5_280$lower_ci` days with
five measurements, but the error bar length to approximately
`r beta_mid_ext_7_280$upper_ci - beta_mid_ext_7_280$lower_ci` days with
seven measurements. Note that variability remained considerably high for
the random-effect days-to-halfway elevation parameter
($\upbeta_{random}$) with seven measurements the fixed-effect
days-to-halfway elevation parameter ($\upbeta_{fixed}$) had population
values of 80 and 280, with respective ranges of
`r beta__rand_mid_ext_7_80$upper_ci - beta__rand_mid_ext_7_80$lower_ci`
and
`r beta__rand_mid_ext_7_280$upper_ci - beta__rand_mid_ext_7_280$lower_ci`
days.

```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Middle-and-Extreme Spacing in Experiment 1}
  \label{fig:exp1_plot_time_mid_ext}
  \includegraphics{Figures/exp1_plot_days_middle-and-extreme spacing} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that, in Panel A, estimates for $\upbeta_{fixed}$ are centered around their corresponding population values (80, 180, and 280 days), and so the y-axis represents error (in number of days) from the population value. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-mid-ext} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp1-mid-ext, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'mid_ext', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'M', 'NM x M'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Middle-and-Extreme Spacing in Experiment 1',
footnote = 'NM = number of measurements (5, 7, 9, 11), M = population value set for $\\\\upbeta_{fixed}$ (80, 180, 280), NM x M = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. \\\\phantom{ indicate conditions where}', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}D)'))
```
## Discussion

In summary, bias was negligible in across in all measurement spacing
conditions for all parameters and variability was considerably high in
each measurement spacing condition with five measurements and different
population values set for the dfixed-effect days-to-halfway elevation
parameter ($\upbeta_{fixed}$). Under equal spacing, variability was
moderately high for all day-unit parameters across all population values
of the days-to-halfway elevation parameter ($\upbeta_{fixed}$). Under
time-interval increasing spacing, variability was high for all day-unit
parameters (with the random-effect halfway-triquarter parameter
[$\upgamma_{random}$] being an exception) when the days-to-halfway
elevation parameter ($\upbeta_{fixed}$) was set at 280. Under
time-interval increasing spacing, variability was high for all day-unit
parameters (with the random-effect halfway-triquarter parameter
[$\upgamma_{random}$] being an exception) when the days-to-halfway
elevation parameter ($\upbeta_{fixed}$) was set at 80. Under
middle-and-extreme spacing, variability was high for all day-unit
parameters (with the random-effect halfway-triquarter parameter
[$\upgamma_{random}$] being an exception) when the days-to-halfway
elevation parameter ($\upbeta_{fixed}$) was set at either 80 or 280.

The interaction between measurement spacing and the population value set
for the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$) can be explained by the extent to which each
measurement spacing schedule samples measurements during periods of
change. Figure \ref{fig:spacing_example} shows where each measurement
schedule samples data when the curve has a population value for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) of
80. The region shaded in gray covers the time period where 80% of the
curve's change occurs. Only the equal and time-interval increasing
measurement schedules sampled data during the period of greatest change,
and the variability for the parameter estimates of these schedules was
considerably less than the variability observed when using time-interval
decreasing and middle-and-extreme spacing schedules (see Figure
\ref{fig:exp1_summary}).

```{=tex}
\begin{figure}[H]
  \caption{Depiction of Time Points Sampled by Four Measurement Spacing Schedules in Experiment 1}
  \label{fig:spacing_example}
  \includegraphics{Figures/spacing_example} \hfill{}
  \caption*{Note. \textup{Region shaded in gray covers the time period where 80\% of the curve's change occurs. Only the equal and time-interval increasing measurement schedules sample data during the period of greatest change.}}
\end{figure}
```
Figure \ref{fig:exp1_summary} comprehensively shows the interaction
between measurement spacing and the population value set for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$).
Stated succinctly, measurements schedules incur variability in parameter
estimation when they do not sample data during periods of change.
Importantly, variability for each condition was computing by using the
following procedure:

1)  Compute variance of estimates for each day-unit parameter.
2)  Compute mean variance of estimates across all day-unit parameters
    for each experimental condition.
3)  Take the square root of the mean variance for each experimental
    condition.

\noindent Algebraically, Equation \ref{eq:mean-sd} below shows the
formula for computing the mean standard deviation across all day-unit
parameters:

```{=tex}
\begin{align}
\text{Standard deviation}_{Day-unit} = \sqrt{\Bigg(\frac{1}{P} \sum^{P = 4}_{i = 1} var(estimate_{Day-unit_i}) \Bigg)},   (\#eq:mean-sd)
\end{align}
```
\noindent where *P* is the number of day-unit parameters. Measurement
schedules incurred the most variability when the population value set
for the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$) led the schedules to sample data outside the region
of greatest change.

```{r spacing-figure-five, include=F, eval=F}
#generate logistic curve values for each day, set beta = 80 
beta <- 80
gamma <- 20
alpha <-  3.32
theta <- 3
days <- 0:360

curve_values <- theta + (alpha - theta)/(1 + exp((beta - days)/gamma))
logistic_data <- data.frame('day' = days, 
                            'curve_value' = curve_values)

#compute measurement days 
equal_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'equal')$measurement_days
time_inc_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'time_inc')$measurement_days
time_dec_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'time_dec')$measurement_days
mid_ext_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'mid_ext')$measurement_days

measurement_schedules <- c('A: Equal', 'B: Time-Interval Increasing', 'C: Time-Interval Decreasing', 'D: Middle-and-Extreme')
schedules_data <- data.frame('schedule' = factor(rep(c(measurement_schedules),each = 5)),  
                             'measurement_day' = c(equal_days, time_inc_days, time_dec_days, mid_ext_days))

#match measurement_day on day column from logistic_data and extract curve_value
schedules_data <- schedules_data %>% 
  left_join(y = logistic_data,by = c('measurement_day' = 'day')) 
schedules_data$schedule <- factor(schedules_data$schedule, levels = measurement_schedules)

#middle 80% of change
##find y_range 
y_lower <- 3.16 - 0.8*(alpha - theta)/2
y_upper <- 3.16 + 0.8*(alpha - theta)/2

##find corresponding x values
x_lower <- logistic_data$day[which(round(logistic_data$curve_value, digits = 3) == y_lower)]
x_upper <- logistic_data$day[which(round(logistic_data$curve_value, digits = 3) == 3.288)]

spacing_example <- ggplot(data = logistic_data, mapping = aes(x = day,  y = curve_value)) + 
  geom_line(size = 1) + 
  geom_point(data = schedules_data, mapping = aes(x = measurement_day, group = schedule), size = 3) + 
  scale_shape_manual(name = 'Measurement Schedule', values = c(15, 16, 17, 18)) + 
  guides(shape = guide_legend(override.aes = list(fill = "white"))) + 
  scale_x_continuous(name = 'Day', breaks = c(0, 60, 120, 180, 240, 300, 360)) + 
  scale_y_continuous(name = 'Curve value', breaks = c(3, 3.1, 3.2, 3.3)) + 
  facet_wrap(facets = ~schedule, scales = 'free') + 
  #shaded rectangle
  annotate("rect", xmin = x_lower, xmax = x_upper, ymin = y_lower, ymax = y_upper, alpha = .3,fill = "gray") +
  theme_classic(base_family = 'Helvetica')  + 
   theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      ##original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 16, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),
#
      ##axis details
      axis.text = element_text(size = 12, color = 'black'),
      axis.title = element_text(size = 16),
      #axis.title.x.bottom = element_markdown(),
      #axis.line = element_line(size = 1),
      ##axis.ticks.length.x = unit(x = 1, units = 'cm'),
      #axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      #axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      #axis.ticks = element_line(size = 2, colour = 'black'),
      #axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #legend.position = c(0.5, 0.5), 
      #legend.direction = 'horizontal', 
#
      #panel details
      panel.spacing.y = unit(x = 1, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
ggsave(filename = 'Figures/spacing_example.pdf', plot = spacing_example, width = 9, height = 6)
```

```{r plot-summary, include=F, eval=F}
generate_summary_facet_plot(condition_data = cond_summary_exp_1, lower_y_limit = 0, upper_y_limit = 20, ticks = 5, exp_num = 'Figures/exp1_', 
                            y_axis_var = 'mean_sd', y_axis_name = 'Average parameter standard deviation', 
                            x_axis_var = 'midpoint', x_axis_name = expression("Population value set for"~beta[fixed]))

cond_summary_exp_1 <- compute_condition_summary(param_summary_data = param_summary_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))

cond_summary_exp_1$number_measurements <- as.numeric(cond_summary_exp_1$number_measurements)
cond_summary_exp_1$midpoint <- as.numeric(cond_summary_exp_1$midpoint)
cond_summary_exp_1$measurement_spacing <- factor(cond_summary_exp_1$measurement_spacing, levels = c(1, 2, 3, 4))

lm_model <- lm(data = cond_summary_exp_1, formula = mean_sd ~ number_measurements*measurement_spacing*midpoint)

summary(lm_model)
apaTables::apa.reg.table(lm_model)

generate_summary_facet_plot(condition_data = cond_summary_exp_2, lower_y_limit = 0, upper_y_limit = 30, ticks = 5, exp_num = 'Figures/exp2_', 
                            y_axis_var = 'mean_sd', y_axis_name = 'Average parameter standard deviation', 
                            x_axis_var = 'sample_size', x_axis_name = 'Sample size (*N*)')


generate_summary_facet_plot(condition_data = cond_summary_exp_3, lower_y_limit = 0, upper_y_limit = 30, ticks = 2, exp_num = 'Figures/exp3_',
                            y_axis_var = 'mean_sd', y_axis_name = 'Average parameter standard deviation', 
                            x_axis_var = 'sample_size', x_axis_name = 'Sample size (*N*)', 
                            facet_var = 'time_structuredness')
```

```{=tex}
\begin{figure} [H]
  \caption{Average Parameter Standard Deviations Across Measurement Spacing Conditions}
  \label{fig:exp1_summary}
  \includegraphics{Figures/exp1_summary_plot} \hfill{}
  \caption*{Note. \textup{Average parameter standard deviations were obtained by computing the square root of the mean of the variance of estimates across all parameters (see Equation \ref{eq:mean-sd}).}}
\end{figure}
```
Although considerable variability occurs with five measurements,
variability in the estimation of day-unit parameters becomes nearly
nontrivial with seven or more measurements. Therefore, with a sample
size typically observed in organizational research (i.e., *N* = 225),
seven measurements may be the minimum number of measurements that should
be used so avoid incurring high levels of variability in parameter
estimation.

One limitation of the simulations conducted in Experiment 1 is that
sample size was not manipulated and was set as a constant value (*N* =
225). Given that sample size is a focal variable when designing a study,
understanding how sample size affects the estimation of logistic
function parameters is important. Therefore, sample size will be
manipulated in Experiment 2.

```{r spacing-figure-seven, include=F, eval=F}
#generate logistic curve values for each day, set beta = 80 
beta <- 80
gamma <- 20
alpha <-  3.32
theta <- 3
days <- 0:360

curve_values <- theta + (alpha - theta)/(1 + exp((beta - days)/gamma))
logistic_data <- data.frame('day' = days, 
                            'curve_value' = curve_values)

#compute measurement days 
num_measurements <- 7
equal_days <- compute_measurement_schedule(time_period = 360, num_measurements = num_measurements, smallest_int_length = 30, measurement_spacing = 'equal')$measurement_days
time_inc_days <- compute_measurement_schedule(time_period = 360, num_measurements = num_measurements, smallest_int_length = 30, measurement_spacing = 'time_inc')$measurement_days
time_dec_days <- compute_measurement_schedule(time_period = 360, num_measurements = num_measurements, smallest_int_length = 30, measurement_spacing = 'time_dec')$measurement_days
mid_ext_days <- compute_measurement_schedule(time_period = 360, num_measurements = num_measurements, smallest_int_length = 30, measurement_spacing = 'mid_ext')$measurement_days

measurement_schedules <- c('Equal', 'Time-interval increasing', 'Time-interval decreasing', 'Middle-and-extreme')
schedules_data <- data.frame('schedule' = factor(rep(c(measurement_schedules),each = num_measurements)),  
                             'measurement_day' = c(equal_days, time_inc_days, time_dec_days, mid_ext_days))

#match measurement_day on day column from logistic_data and extract curve_value
schedules_data <- schedules_data %>% 
  left_join(y = logistic_data,by = c('measurement_day' = 'day')) 
schedules_data$schedule <- factor(schedules_data$schedule, levels = measurement_schedules)

#middle 80% of change
##find y_range 
y_lower <- 3.16 - 0.8*(alpha - theta)/2
y_upper <- 3.16 + 0.8*(alpha - theta)/2

##find corresponding x values
x_lower <- logistic_data$day[which(round(logistic_data$curve_value, digits = 3) == y_lower)]
x_upper <- logistic_data$day[which(round(logistic_data$curve_value, digits = 3) == 3.288)]

ggplot(data = logistic_data, mapping = aes(x = day,  y = curve_value)) + 
  geom_line(size = 1)  + 
  geom_point(data = schedules_data, mapping = aes(x = measurement_day, group = schedule, shape = schedule), size = 5, alpha = 0.3) +
  scale_shape_manual(name = 'Measurement Schedule', values = c(15, 16, 17, 18)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, 60, 80, 120, 180, 240, 300, 360)) +
  scale_y_continuous(name = 'Curve value', breaks = c(3, 3.1, 3.2, 3.3, 3.32))  +
  #shaded rectangle
  annotate("rect", xmin = x_lower, xmax = x_upper, ymin = y_lower, ymax = y_upper, alpha = .3,fill = "gray")+
  theme_classic(base_family = 'Helvetica') + 
  theme(axis.text = element_text(colour = 'black', size = 12), 
        axis.title = element_text(colour = 'black', size = 16), 
        legend.title = element_text(colour = 'black', size = 16), 
        legend.text = element_text(colour = 'black', size = 12))

ggsave(filename = 'Figures/spacing_example.pdf', plot = spacing_example, width = 9, height = 6)

```

```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```
# Experiment 2

```{=tex}
\nointerlineskip
\vfill
\newpage
```
Experiment 2 investigated the extent to which measurement spacing
schedules could accurately model logistic function parameters under
various measurement number-sample size conditions. Three variables were
manipulated: measurement spacing, number of measurements, and sample
size. Measurement spacing was manipulated by creating schedules defined
by either equal, time-interval increasing, time-interval decreasing, or
middle-and-extreme spacing.middle-and-extreme spacing. Number of
measurements was manipulated to take on a value of either 5, 7, 9, or 11
measurements. Sample size was manipulated to take on a value of either
30, 50, 100, 200, 500, or 1000. Note that the population value for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$)
previously manipulated in Experiment 1 is set to a value of 180 across
all conditions in Experiment 2.

## Results

### Equal Spacing

```{r plots-equal-exp2, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_2_analytical, 
                               target_col = 'measurement_spacing', target_value = 'Equal spacing',
                               x_axis_name = expression("Sample size ("*italic(N)*")"), 
                               x_axis_var = 'sample_size', exp_num = 'exp2_', beta_lower = 165, beta_upper = 205,
                               ticks = 5)
```

```{r exp2-density-plot-equal, include=F, eval=F}
##generate figure showing density distributions if gamma_fizxd at N = 500 and N = 1000 with middle 95% area shaded. Emphasize
##that longer error bars in  N = 1000 are likely a statistical artifact of the random number generating procedure. 
exp_2 <- read_csv('data/exp_2.csv') %>% filter(code == 0) #load data 
exp_2 <- convert_raw_var_to_sd(raw_data = exp_2) #var to sd conversion 

parameter_names <- c(bquote(expr = bold(A:~gamma[fixed]~"(N=500, 5 measurements)")),
                     bquote(expr = bold(B:~beta[random]~"(N=500, 5 measurements)")),
                     bquote(expr = bold(C:~gamma[fixed]~"(N=1000, 5 measurements)")),
                     bquote(expr = bold(D:~beta[random]~"(N=1000, 5 measurements)")))
                     
#1) Extract estimates for four parameter gamma_fixed and beta_rand when N =500 or 1000, num_measurements == 5, spacing == equal. 
##Convert to long format, with parameter name going into unique column and estimate becoming new column 
param_data_equal_exp_2 <- exp_2 %>%
  filter(number_measurements == 5, measurement_spacing == 'equal', sample_size %in% c(500, 1000)) %>%
  select(locate_ivs(exp_2),'gamma_fixed', 'beta_rand') %>%
  pivot_longer(cols = c(gamma_fixed, beta_rand), values_to = 'estimate') %>%
  unite(col = 'parameter', sample_size:name) 

#2) Replace parameter values with tag labels. 
param_data_equal_exp_2$parameter <- factor(param_data_equal_exp_2$parameter, 
                               levels = c("500_gamma_fixed", "500_beta_rand",
                                          "1000_gamma_fixed", "1000_beta_rand"), 
                               labels = parameter_names)

base_density_plot <- ggplot(data = param_data_equal_exp_2, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
density_data <- ggplot_build(plot = base_density_plot)$data[[1]]

param_search_names <- c("A\\:", "B\\:", "C\\:", "D\\:")

param_error_bar_ranges <- lapply(X = param_search_names, compute_ind_param_error_bar_range, param_data = param_data_equal_exp_2)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data_equal_exp_2, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
density_data <- ggplot_build(plot = base_density_plot)$data[[1]]

plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


density_plot_equal_exp2 <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 2, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(2, scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(3,scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(4, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.90, by = 0.10),
                                                                                                   limits = c(0, .90))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = density_plot_equal_exp2, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plot_fixed_equal_exp2.pdf')

```

```{r exp2-density-plot-equal-fixed, include=F, eval=F}
param_error_bar_ranges <- lapply(X = param_search_names, compute_90_ind_param_error_bar_range, param_data = param_data_equal_exp_2)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data_equal_exp_2, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


density_equal_fixed_exp2 <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
     facet_wrap_custom( ~ parameter, scales = "free", ncol = 2, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(2, scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(3,scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(4, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.90, by = 0.10),
                                                                                                   limits = c(0, .90))))) + 
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = density_equal_fixed_exp2, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_equal_fixed_exp2.pdf')

```

```{r plots-equal-exp2-fixed, include=F, eval=F}
exp_2_analytical$days$upper_ci <- exp_2_analytical$days$upper_ci_90
exp_2_analytical$days$lower_ci <- exp_2_analytical$days$lower_ci_90

generate_day_likert_facet_plot(analytical_data = exp_2_analytical, 
                               target_col = 'measurement_spacing', target_value = 'Equal spacing',
                               x_axis_name = 'Sample size (*N*)', 
                               x_axis_var = 'sample_size', exp_num = 'exp2_fixed_', beta_lower = 165, beta_upper = 205,
                               ticks = 5)
```

```{r text-values-equal-exp2, echoF}
#fixed-effect halfway-triquarter delta (5, 100)
gamma_fixed_equal_5_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, sample_size == 200, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter (5, 100)
beta_fixed_equal_5_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, sample_size == 200, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter(7, 100)
gamma_fixed_equal_7_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 7, sample_size == 200, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 

#random-effect halfway-triquarter delta (5, 200)
gamma_rand_equal_5_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci), 
         estimate = as.integer(estimate))
```


Figure \ref{fig:exp2_plot_equal} shows the parameter estimation plots
for the day-unit parameters when equal spacing was used (error bars
represent the middle 95% of estimated values and shaded horizontal lines
indicate the population values). Panels A--B show the parameter
estimation plots for the fixed-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{fixed}$ and
$\upgamma_{fixed}$), respectively.Panels C--D show the parameter
estimation plots for the random-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{random}$ and
$\upgamma_{random}$), respectively. Note that Table \ref{tab:omega-exp2-equal} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under equal spacing. 

For all simulations presented in Figure \ref{fig:exp2_plot_equal}, one
instance of bias occurred. With five measurements and a sample size no
larger than 200, estimation of the random-effect halfway-triquarter
delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp2_plot_equal}D)
was considerably overestimated. For example, the average population
value estimated for the random-effect halfway-triquarter delta parameter
($\upgamma_{random}$) parameter was `r gamma_rand_equal_5_200$estimate`
days with five measurements and a sample size of 200 (relative to a
population value of 4.00 days). Across all other conditions in Figure
\ref{fig:exp1_plot_time_mid_ext}, no instance of bias occurred, as the
average estimated values for all day-unit parameters (as indicated by
the black dots) were close to their respective population values
(indicated by the gray lines).

With respect to variability, two general patterns of results emerged in
the estimation of day-unit parameters with equal spacing.First, for the
fixed- and random-effects of the halfway-triquarter delta parameters
($\upgamma_{fixed}$ and $\upgamma_{random}$), variability was
considerably high with five measurements and a sample size no larger
than 200. For example, the error bar length for the fixed-effect
halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure
\ref{fig:exp2_plot_equal}B) spanned approximately
`r gamma_fixed_equal_5_200$upper_ci -gamma_fixed_equal_5_200$lower_ci`
days (upper bound of `r gamma_fixed_equal_5_200$upper_ci` days to a
lower bound of `r gamma_fixed_equal_5_200$lower_ci` days) with five
measurements and a sample size of 200. Note that, similarly, variability
for the fixed- and random-effects of the days-to-halfway elevation
parameters ($\beta_{fixed}$ and $\beta_{random}$) was lower than the
variability for the halfway-triquarter delta parameters, but still
moderately high at sample sizes below 200 with five measurements. As an
example, the error bar length for the fixed-effect days-to-halfway
elevation parameter($\beta_{fixed}$; Figure \ref{fig:exp2_plot_equal}A)
spanned approximately
`r beta_fixed_equal_5_200$upper_ci - beta_fixed_equal_5_200$lower_ci`
days (upper bound of `r beta_fixed_equal_5_200$upper_ci` days to a lower
bound of `r beta_fixed_equal_5_200$lower_ci` days) with five
measurements and a sample size of 200. Second, variability across all
day-unit parameters was nearly trivial across all sample size levels
with seven or more measurements. For example, the error bar length for
the the fixed-effect halfway-triquarter delta parameter
($\upgamma_{fixed}$; Figure \ref{fig:exp2_plot_equal}B) spanned
approximately
`r gamma_fixed_equal_7_200$upper_ci - gamma_fixed_equal_7_200$lower_ci`
(upper bound of `r gamma_fixed_equal_7_200$upper_ci` days to a lower
bound of `r gamma_fixed_equal_7_200$lower_ci` days) days with seven
measurements and a sample size of 100.

```{r density-ranges, echo=F}
#fixed-effect days-to-halfway elevation parameter (5, 500)
beta_fixed_equal_5_500 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, sample_size == 500, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter (5, 500)
beta_fixed_equal_5_1000 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Equal spacing', number_measurements == 5, sample_size == 1000, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))
```

```{=tex}
\begin{figure}[H]
  \caption{Summary of Day-Unit Parameter Estimates for Equal Spacing in Experiment 2}
  \label{fig:exp2_plot_equal}
  \includegraphics{Figures/exp2_plot_days_equal spacing} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Population values for each parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\upepsilon$ = 0.03. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that random-effect units are in standard deviation units. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-equal} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp2-equal, echo=F}
print_bias_var_omega_table(exp_data = exp_2_raw, target_col = 'measurement_spacing', target_value = 'equal', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Equal Spacing in Experiment 2',
footnote = 'NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp2_plot_equal}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp2_plot_equal}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp2_plot_equal}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp2_plot_equal}D)'))
```

### Time-Interval Increasing Spacing

```{r plots-time-increasing-exp2, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_2_analytical, 
                               target_col = 'measurement_spacing', target_value = 'Time-interval increasing',
                                                             x_axis_name = expression("Sample size ("*italic(N)*")"), 

                               x_axis_var = 'sample_size', exp_num = 'exp2_', beta_lower = 165, beta_upper = 205,
                               ticks = 5)
```

```{r text-values-time-increasing-exp2, echoF}
#fixed-effect days-to-halfway elevation parameter (5, 100)
beta_fixed_time_inc_5_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval increasing', number_measurements == 5, sample_size == 200, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter (7, 100)
beta_fixed_time_inc_7_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval increasing', number_measurements == 7, sample_size == 100, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 
```

Figure \ref{fig:exp2_plot_time_increasing} shows the parameter
estimation plots for the day-unit parameters when equal spacing was used
(error bars represent the middle 95% of estimated values and shaded
horizontal lines indicate the population values). Panels A--B show the
parameter estimation plots for the fixed-effect days-to-halfway
elevation and triquarter-halfway delta parameters ($\upbeta_{fixed}$ and
$\upgamma_{fixed}$), respectively. Panels C--D show the parameter
estimation plots for the random-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{random}$ and
$\upgamma_{random}$), respectively. Note that Table \ref{tab:omega-exp2-time-inc} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under time-interval increasing spacing. 


For all simulations presented in Figure
\ref{fig:exp2_plot_time_increasing}, no instance of bias occurred, as
the average estimated values for all day-unit parameters (as indicated
by the black dots) were close to their respective population values
(indicated by the gray lines).

With respect to variability, two general patterns of results emerged in
the estimation of day-unit parameters with time-interval increasing
spacing. First, for the fixed- and random-effect days-to-halfway
elevation parameter ($\upbeta_{fixed}$, $\upbeta_{random}$), variability
was considerably high with five measurements and a sample size no larger
than 200. For example, the error bar length for the fixed-effect
days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure
\ref{fig:exp2_plot_time_increasing}A) spanned approximately
`r beta_fixed_time_inc_5_200$upper_ci - beta_fixed_time_inc_5_200$lower_ci`
days (upper bound of `r beta_fixed_time_inc_5_200$upper_ci` days to
lower bound of `r beta_fixed_time_inc_5_200$lower_ci` days) with five
measurements and a sample size of 200. Note that variability for the
fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$;
Figure \ref{fig:exp2_plot_time_increasing}B) was considerably high with
five measurements and a sample size no larger than 100. Second,
variability across all day-unit parameters was nearly trivial with seven
measurements across all sample size levels. For example, the error bar
length for the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$; Figure \ref{fig:exp2_plot_time_increasing}A) spanned
approximately
`r beta_fixed_time_inc_7_200$upper_ci - beta_fixed_time_inc_7_200$lower_ci`
days (upper bound of `r beta_fixed_time_inc_7_200$upper_ci` days to a
lower bound of `r beta_fixed_time_inc_7_200$lower_ci` days) with seven
measurements and a sample size of 200.

```{=tex}
\begin{figure}[H]
  \caption{Summary of Day-Unit Parameter Estimates for Time-Interval Increasing Spacing in Experiment 2}
  \label{fig:exp2_plot_time_increasing}
  \includegraphics{Figures/exp2_plot_days_time-interval increasing} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Population values for each parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\upepsilon$ = 0.03. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that random-effect units are in standard deviation units. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-time-inc} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp2-time-inc, echo=F}
print_bias_var_omega_table(exp_data = exp_2_raw, target_col = 'measurement_spacing', target_value = 'time_inc', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Increasing Spacing in Experiment 2',
footnote = 'NM = number of measurements, S = sample size, NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp2_plot_time_increasing}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp2_plot_time_increasing}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp2_plot_time_increasing}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp2_plot_time_increasing}D)'))
```
### Time-Interval Decreasing Spacing

```{r plots-time-decreasing-exp2, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_2_analytical, 
                               target_col = 'measurement_spacing', target_value = 'Time-interval decreasing',
                                                                                             x_axis_name = expression("Sample size ("*italic(N)*")"), 


                               x_axis_var = 'sample_size', exp_num = 'exp2_', beta_lower = 155, beta_upper = 195,
                               ticks = 5)
```

```{r text-values-time-decreasing-exp2, echoF}
#fixed-effect days-to-halfway elevation parameter (5, 100)
beta_fixed_time_dec_5_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval decreasing', number_measurements == 5, sample_size == 200, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter (7, 100)
beta_fixed_time_dec_7_200 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Time-interval decreasing', number_measurements == 7, sample_size == 200, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 
```

Figure \ref{fig:exp2_plot_time_decreasing} shows the parameter
estimation plots for the day-unit parameters when equal spacing was used
(error bars represent the middle 95% of estimated values and shaded
horizontal lines indicate the population values). Panels A--B show the
parameter estimation plots for the fixed-effect days-to-halfway
elevation and triquarter-halfway delta parameters ($\upbeta_{fixed}$ and
$\upgamma_{fixed}$), respectively. Panels C--D show the parameter
estimation plots for the random-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{random}$ and
$\upgamma_{random}$), respectively. Note that Table \ref{tab:omega-exp2-time-dec} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under time-interval decreasing spacing.  

For all simulations presented in Figure
\ref{fig:exp2_plot_time_decreasing}, no instance of bias occurred, as
the average estimated values for all day-unit parameters (as indicated
by the black dots) were close to their respective population values
(indicated by the gray lines).

Two general patterns of results emerged in the estimation of day-unit
parameters with time-interval decreasing spacing. First, for the fixed-
and random-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$, ($\upbeta_{random}$), variability was considerably
high with five measurements and a sample size no larger than 200. For
example, the error bar length for the fixed-effect days-to-halfway
elevation parameter ($\upbeta_{fixed}$; Figure
\ref{fig:exp2_plot_time_decreasing}A) spanned approximately
`r beta_fixed_time_dec_5_200$upper_ci - beta_fixed_time_dec_5_200$lower_ci`
days (upper bound of `r beta_fixed_time_dec_5_200$upper_ci` days to
lower bound of `r beta_fixed_time_dec_5_200$lower_ci` days) with five
measurements and a sample size of 200. Note that variability for the
fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$) was
considerably high with five measurements and a sample size no larger
than 100. Second, variability across all day-unit parameters was nearly
trivial with seven measurements across all sample size levels. For
example, the error bar length for the fixed-effect days-to-halfway
elevation parameter ($\beta_{fixed}$; Figure
\ref{fig:exp2_plot_time_decreasing}A) spanned approximately
`r beta_fixed_time_dec_7_200$upper_ci - beta_fixed_time_dec_7_200$lower_ci`
days (upper bound of `r beta_fixed_time_dec_7_200$upper_ci` days to a
lower bound of `r beta_fixed_time_dec_7_200$lower_ci` days) with seven
measurements and a sample size of 100.

```{=tex}
\begin{figure}[H]
  \caption{Summary of Day-Unit Parameter Estimates for Time-Interval Decreasing Spacing in Experiment 2}
  \label{fig:exp2_plot_time_decreasing}
  \includegraphics{Figures/exp2_plot_days_time-interval decreasing} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Population values for each parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\upepsilon$ = 0.03. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that random-effect units are in standard deviation units. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-time-dec} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp2-time-dec, echo=F}
print_bias_var_omega_table(exp_data = exp_2_raw, target_col = 'measurement_spacing', target_value = 'time_dec', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 2',
footnote = 'NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp2_plot_time_decreasing}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp2_plot_time_decreasing}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp2_plot_time_decreasing}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp2_plot_time_decreasing}D)'))
```

### Middle-and-Extreme Spacing

```{r plots-mid-ext-exp2, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_2_analytical, 
                               target_col = 'measurement_spacing', target_value = 'Middle-and-extreme spacing',
                                                             x_axis_name = expression("Sample size ("*italic(N)*")"), 

                               x_axis_var = 'sample_size', exp_num = 'exp2_', beta_lower = 165, beta_upper = 205,
                               ticks = 5)
```

```{r text-values-mid-ext-exp2, echoF}
#fixed-effect days-to-halfway elevation parameter (5, 30)
beta_fixed_mid_ext_5_30 <- exp_2_analytical$days %>% 
  filter(measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 5, sample_size == 30, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 
```


Figure \ref{fig:exp2_plot_time_mid_ext} shows the parameter estimation
plots for the day-unit parameters when equal spacing was used (error
bars represent the middle 95% of estimated values and shaded horizontal
lines indicate the population values). Panels A--B show the parameter
estimation plots for the fixed-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{fixed}$ and
$\upgamma_{fixed}$), respectively. Panels C--D show the parameter
estimation plots for the random-effect days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta_{random}$ and
$\upgamma_{random}$), respectively. Note that Table \ref{tab:omega-exp2-mid-ext} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters under middle-and-extreme spacing. 

For all simulations presented in Figure
\ref{fig:exp2_plot_time_mid_ext}, no instance of bias occurred, as the
average estimated values for all day-unit parameters (as indicated by
the black dots) were close to their respective population values
(indicated by the gray lines).

In addition to showing little to no systematic bias, parameter estimates
also showed little to no variability with middle-and-extreme measurement
spacing. The longest error bar length across all day-unit parameters
across all sample size-measurement-number conditions occurred for the
fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$;
Figure \ref{fig:exp2_plot_time_mid_ext}A), with an error bar length of
`r beta_fixed_mid_ext_5_30$upper_ci - beta_fixed_mid_ext_5_30$lower_ci`
days (upper bound of `r beta_fixed_mid_ext_5_30$upper_ci` days to a
lower bound of `r beta_fixed_mid_ext_5_30$lower_ci` days) with five
measurements and a sample size of 30.

```{=tex}
\begin{figure}[H]
  \caption{Summary of Day-Unit Parameter Estimates for Middle-and-Extreme Spacing in Experiment 2}
  \label{fig:exp2_plot_time_mid_ext}
  \includegraphics{Figures/exp2_plot_days_middle-and-extreme spacing} \hfill{}
  \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Population values for each parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\upepsilon$ = 0.03. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that random-effect units are in standard deviation units. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp2-mid-ext} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp2-mid-ext, echo=F}
print_bias_var_omega_table(exp_data = exp_2_raw, target_col = 'measurement_spacing', target_value = 'mid_ext', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Middle-and-Extreme Spacing in Experiment 2',
footnote = 'NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp2_plot_time_mid_ext}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp2_plot_time_mid_ext}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp2_plot_time_mid_ext}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp2_plot_time_mid_ext}D)'))
```

```{r plot-summary-exp2, include=F, eval=F}

generate_summary_facet_plot(condition_data = cond_summary_exp_2, lower_y_limit = -6, upper_y_limit = 20, ticks = 2, exp_num = 'Figures/exp2_', 
                            y_axis_var = 'mean_perc_error', y_axis_name = 'Parameter bias (percentage error)', 
                            x_axis_var = 'sample_size', x_axis_name = 'Sample size (*N*)')

```

## Discussion of Experiment 2

In summary, two patterns of results occurred across each measurement
spacing condition. First, variability for at least two day-unit
parameters was considerably high across all measurement spacing
conditions (excluding middle-and-extreme spacing) with five measurements
and a sample size no larger than 200. Variability was high for the
following day-unit parameters in the following measurement spacing
conditions:

1.  Equal spacing: fixed- and random-effect triquarter-halfway delta
    parameters ($\upgamma_{fixed}$, $\upgamma_{random}$).
2.  Time-interval increasing spacing: fixed- and random-effect
    days-to-halfway elevation parameters ($\upbeta_{fixed}$,
    $\upbeta_{random}$) and the fixed-effect triquarter-halfway delta
    parameter ($\upgamma_{fixed}$) with a sample size no larger
    than 100.
3.  Time-interval decreasing spacing: fixed- and random-effect
    days-to-halfway elevation parameters ($\upbeta_{fixed}$,
    $\upbeta_{random}$) and the fixed-effect triquarter-halfway delta
    parameter ($\upgamma_{fixed}$) with a sample size no larger
    than 100.

\noindent Second, variability became nearly non-trivial with seven or
more measurements for all day-unit parameters across all measurement
spacing-sample size conditions. Therefore, to have a high degree of
certainty of accurately modelling a logistic pattern of change, either
five measurements should be taken with a sample size of 500 or,
alternatively, seven measurements can be taken with any sample size.

One limitation of Experiment 2 is the assumption of time-structured
data. Data in Experiment 2 were manipulated to resemble conditions where
data at each collection point are all collected at the same time point.
Given that, at any given collection point, respondents are likely to
provide their data at different time points---such that all data are
obtained over a window of time---the assumption of time-structured data
is unrealistic. Therefore, Experiment 3 will manipulate the time
structure of data to more closely resemble data collection conditions
encountered in longitudinal studies.

```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```
# Experiment 3

```{=tex}
\nointerlineskip
\vfill
\newpage
```
Experiment 3 investigated the extent to which time structuredness, when
not accounted for, affected the ability to accurately model logistic
function parameters under various measurement number-sample size
conditions. Three variables were manipulated: time structuredness,
number of measurements, and sample size. Time structuredness was
manipulated by defining response rates such that 80% of participants
responded within a period of 0 (time-structured data), 4.32 (fast
response), or 10.80 days (slow response).
\footnote{The response rate values used in defining the three time structuredness conditions were chosen to resemble values used in previous research (ref:coulombe2016f).}
Number of measurements was manipulated to take on a value of either 5,
7, 9, or 11 measurements. Sample size was manipulated to take on a value
of either 30, 50, 100, 200, 500, or 1000. Note that measurement spacing
was fixed to equal spacing across and a value of 180 was set for the
population value of the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$) across all conditions.

## Results of Experiment 3

### Time-Structured Data

```{r plots-time-structured-exp3, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_3_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time structured',
                                                              x_axis_name = expression("Sample size ("*italic(N)*")"), 

                               x_axis_var = 'sample_size', exp_num = 'exp3_', beta_lower = 165, beta_upper = 205,
                               ticks = 5)
```

```{r text-values-time-structured-exp3, echoF}
#fixed-effect halfway-triquarter delta (5, 100)
gamma_fixed_equal_5_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time structured', number_measurements == 5, sample_size == 200, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter (5, 100)
beta_fixed_equal_5_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time structured', number_measurements == 5, sample_size == 200, grepl('beta\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter(7, 100)
gamma_fixed_equal_7_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time structured', number_measurements == 7, sample_size == 200, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))  

#fixed-effect halfway-triquarter delta (5, 200)
gamma_rand_equal_5_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time structured', number_measurements == 5, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci),
         estimate = as.integer(estimate))

```

Figure \ref{fig:exp3_plot_days_time_structured} shows the parameter
estimation plots with time-structured data (error bars represent the
middle 95% of estimated values and shaded horizontal lines indicate the
population values). Panels A--B show the parameter estimation plots for
the fixed-effect days-to-halfway elevation and triquarter-halfway delta
parameters ($\upbeta_{fixed}$ and $\upgamma_{fixed}$),
respectively.Panels C--D show the parameter estimation plots for the
random-effect days-to-halfway elevation and triquarter-halfway delta
parameters ($\upbeta_{random}$ and $\upgamma_{random}$), respectively. Note that Table \ref{tab:omega-exp3-time-structured} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters with time-structured data.

For all simulations presented in Figure
\ref{fig:exp3_plot_days_time_structured}, one instance of bias occurred.
With five measurements and a sample size no larger than 200, estimation
of the random-effect halfway-triquarter delta parameter
($\upgamma_{random}$) was considerably overestimated. For example, the
average population value estimated for the random-effect
halfway-triquarter delta parameter ($\upgamma_{random}$; Figure
\ref{fig:exp3_plot_days_time_structured}D) parameter was
`r gamma_rand_equal_5_200$estimate` days with five measurements and a
sample size of 200 (relative to a population value of 4.00 days). Across
all other conditions in Figure \ref{fig:exp3_plot_days_time_structured},
no instance of bias occurred, as the average estimated values for all
day-unit parameters (as indicated by the black dots) were close to their
respective population values (indicated by the gray lines).

With respect to variability, two general patterns of results emerged in
the estimation of day-unit parameters with equal spacing. First, for the
halfway-triquarter delta parameters ($\upgamma_{fixed}$ and
$\upgamma_{random}$), variability was considerably high with five
measurements and a sample size no larger than 200. For example, the
error bar length for the fixed-effect halfway-triquarter delta parameter
($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_time_structured}B)
spanned approximately
`r gamma_fixed_equal_5_200$upper_ci -gamma_fixed_equal_5_200$lower_ci`
days (upper bound of `r gamma_fixed_equal_5_200$upper_ci` days to a
lower bound of `r gamma_fixed_equal_5_200$lower_ci` days) with five
measurements and a sample size of 200. Note that, in contrast,
variability for the fixed- and random-effects of the days-to-halfway
elevation parameters ($\beta_{fixed}$ and $\beta_{random}$) was
considerably lower than the variability for the halfway-triquarter delta
parameters. As an example, the error bar length for the fixed-effect
days-to-halfway elevation parameter($\beta_{fixed}$; Figure
\ref{fig:exp3_plot_days_time_structured}A) spanned approximately
`r beta_fixed_equal_5_200$upper_ci - beta_fixed_equal_5_200$lower_ci`
days (upper bound of `r beta_fixed_equal_5_200$upper_ci` days to a lower
bound of `r beta_fixed_equal_5_200$lower_ci` days) with five
measurements and a sample size of 200. Second, variability across all
day-unit parameters was nearly trivial across all sample size levels
with seven or more measurements. For example, the error bar length for
the the fixed-effect halfway-triquarter delta parameter
($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_time_structured}B)
spanned approximately
`r gamma_fixed_equal_7_200$upper_ci - gamma_fixed_equal_7_200$lower_ci`
(upper bound of `r gamma_fixed_equal_7_200$upper_ci` days to a lower
bound of `r gamma_fixed_equal_7_200$lower_ci` days) days with seven
measurements and a sample size of 200.

```{=tex}
\begin{figure}[H]
  \caption{Summary of Day-Unit Parameter Estimates for Time-Structured Data in Experiment 3}
  \label{fig:exp3_plot_days_time_structured}
  \includegraphics{Figures/exp3_plot_days_time structured} \hfill{}
    \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Population values for each parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\upepsilon$ = 0.03. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that random-effect units are in standard deviation units. See Table \ref{tab:exp3-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-time-structured} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp3-time-structured, echo=F}
print_bias_var_omega_table(exp_data = exp_3_raw, target_col = 'time_structuredness', target_value = 'time_structured', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Structured Data in Experiment 3',
footnote = 'NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 100), NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp3_plot_days_time_structured}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp3_plot_days_time_structured}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp3_plot_days_time_structured}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp3_plot_days_time_structured}D)'))

```

One additional point to mention concerns how the pattern of results
observed here mirror the results observed in Experiment 2 when equal
spacing was used. In both Experiment 2 (equal spacing) and Experiment 3
(time-structured data), the same conditions were simulated: Measurement
spacing was equal, data were time structured, sample size levels were
30, 50, 100, 200, 500, and 1000, and levels for the number of
measurements were 5, 7, 9, and 11. Thus, it is unsurprising that the
results across Experiment 2 (equal spacing) and Experiment 3
(time-structured data) are identical.

### Time-Unstructured Data (Fast Response)

```{r plots-fast-response-exp3, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_3_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time unstructured (fast response)',
                              x_axis_name = expression("Sample size ("*italic(N)*")"), 
                               x_axis_var = 'sample_size', exp_num = 'exp3_', beta_lower = 165, beta_upper = 205,
                               ticks = 5)
```

```{r text-values-fast-response-exp3, echoF}
#fixed-effect triquarter-halfway delta parameter (5, 1000)
gamma_fixed_fast_5_1000 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (fast response)', number_measurements == 5, sample_size == 1000, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect triquarter-halfway delta parameter (5, 200)
gamma_random_fast_5_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (fast response)', number_measurements == 5, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci), 
         estimate = as.integer(estimate))

#random-effect triquarter-halfway delta parameter (5, 200)
gamma_random_fast_5_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (fast response)', number_measurements == 5, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 

#random-effect triquarter-halfway delta parameter (7, 200)
gamma_random_fast_7_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (fast response)', number_measurements == 7, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 
```

Figure \ref{fig:exp3_plot_days_fast_response} shows the parameter
estimation plots with time-structured data (error bars represent the
middle 95% of estimated values and shaded horizontal lines indicate the
population values). Panels A--B show the parameter estimation plots for
the fixed-effect days-to-halfway elevation and triquarter-halfway delta
parameters ($\upbeta_{fixed}$ and $\upgamma_{fixed}$),
respectively.Panels C--D show the parameter estimation plots for the
random-effect days-to-halfway elevation and triquarter-halfway delta
parameters ($\upbeta_{random}$ and $\upgamma_{random}$), respectively. Note that Table \ref{tab:omega-exp3-fast-response} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters with time-unstructured data defined by fast response rates.  

For all simulations presented in Figure
\ref{fig:exp3_plot_days_time_structured}, two instances of bias
occurred. First, estimation of the fixed-effect days-to-halfway
elevation parameter ($\upbeta_{fixed}$; Figure
\ref{fig:exp3_plot_days_time_structured}A) was slightly underestimated
across all conditions (all black dots lied slightly below the gray
line). Second, the random-effect halfway-triquarter delta parameter
($\upgamma_{random}$) was considerably overestimated with five
measurements and a sample size no larger than 200. For example, the
average population value estimated for the random-effect
halfway-triquarter delta parameter ($\upgamma_{random}$; Figure
\ref{fig:exp3_plot_days_fast_response}D) parameter was approximately
`r gamma_random_fast_5_200$estimate` days with five measurements and a
sample size of 200 (relative to a population value of 4.00 days). Across
all other conditions in Figure \ref{fig:exp3_plot_days_fast_response},
no instance of bias occurred, as the average estimated values for all
day-unit parameters (as indicated by the black dots) were close to their
respective population values (indicated by the gray lines).

With respect to variability, three general patterns of results emerged
in the estimation of day-unit parameters with time-unstructured data
defined by fast response rates. First, variability across all sample
sizes for the fixed-effect triquarter-halfway delta parameter
($\upgamma_{fixed}$) remained high with five measurements. For example,
the error bar length for the fixed-effect triquarter-halfway delta
parameter ($\upgamma_{fixed}$; Figure
\ref{fig:exp3_plot_days_time_structured}B) had a length of
`r gamma_fixed_fast_5_1000$upper_ci - gamma_fixed_fast_5_1000$lower_ci`
days (upper bound of `r gamma_fixed_fast_5_1000$upper_ci` days to lower
bound of `r gamma_fixed_fast_5_1000$upper_ci` days) with a sample size
of 1000 with 5 measurements. Note that the same pattern of variability
existed to a lesser extent for the random-effect days-to-halfway
elevation parameter ($\upbeta_{random}$; Figure
\ref{fig:exp3_plot_days_time_structured}C). Second, variability for the
random-effect triquarter-halfway delta parameter ($\upgamma_{random}$)
remained high with five measurements and a sample size no larger than
200. For example, the error bar length for the random-effect
triquarter-halfway delta parameter ($\upgamma_{random}$; Figure
\ref{fig:exp3_plot_days_time_structured}D) had a length of
`r gamma_random_fast_5_200$upper_ci - gamma_random_fast_5_200$lower_ci`
days (upper bound of `r gamma_random_fast_5_200$upper_ci` days to lower
bound of `r gamma_random_fast_5_200$lower_ci` days) with a sample size
of 200 and five measurements. Third, variability across all day-unit
parameters was nearly trivial across all sample size levels with seven
measurements. For example, the error bar length for the the
random-effect halfway-triquarter delta parameter ($\upgamma_{random}$;
Figure \ref{fig:exp3_plot_days_time_structured}D) spanned approximately
`r gamma_random_fast_7_200$upper_ci - gamma_random_fast_7_200$lower_ci`
(upper bound of `r gamma_random_fast_7_200$upper_ci` days to a lower
bound of `r gamma_random_fast_7_200$lower_ci` days) days with seven
measurements and a sample size of 200 and had an average estimated value
of `r gamma_random_fast_7_200$estimate` days (relative to a population
value of 4.00).

```{=tex}
\begin{figure}[H]
  \caption{Summary of Day-Unit Parameter Estimates for Time-Unstructured Data (Fast Response Rate) in Experiment 3}
  \label{fig:exp3_plot_days_fast_response}
  \includegraphics{Figures/exp3_plot_days_time unstructured (fast response)} \hfill{}
    \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Population values for each parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\upepsilon$ = 0.03. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that random-effect units are in standard deviation units. See Table \ref{tab:exp3-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-fast-response} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp3-fast-response, echo=F}
print_bias_var_omega_table(exp_data = exp_3_raw, target_col = 'time_structuredness', target_value = 'fast_response', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Unstructured Data (Fast Response Rate) in Experiment 3',
footnote = 'NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp3_plot_days_fast_response}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp3_plot_days_fast_response}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp3_plot_days_fast_response}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp3_plot_days_fast_response}D)'))

```

### Time-Unstructured Data (Slow Response)

```{r plots-slow-response-exp3, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_3_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time unstructured (slow response)',
                               x_axis_name = expression("Sample size ("*italic(N)*")"), 
                               x_axis_var = 'sample_size', exp_num = 'exp3_', beta_lower = 165, beta_upper = 205,
                               ticks = 5)
```

```{r text-values-slow-response-exp3, echoF}
#fixed-effect triquarter-halfway delta parameter (5, 1000)
gamma_fixed_slow_5_1000 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (slow response)', number_measurements == 5, sample_size == 1000, grepl('gamma\\[fixed\\]', parameter)) %>%
  select(lower_ci, upper_ci) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect triquarter-halfway delta parameter (5, 200)
gamma_random_slow_5_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (slow response)', number_measurements == 5, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

#fixed-effect days-to-halfway elevation parameter (5, 100)
beta_fixed_slow_5_100 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (slow response)', number_measurements == 5, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci))

beta_fixed_slow_5_30 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (slow response)', number_measurements == 5, sample_size == 30, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 

beta_fixed_slow_11_1000 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (slow response)', number_measurements == 11, sample_size == 1000, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 

#random-effect triquarter-halfway delta parameter (5, 100)
gamma_random_slow_5_100 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (slow response)', number_measurements == 5, sample_size == 100, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 

#random-effect triquarter-halfway delta parameter (7, 100)
gamma_random_slow_7_200 <- exp_3_analytical$days %>% 
  filter(time_structuredness == 'Time unstructured (slow response)', number_measurements == 7, sample_size == 200, grepl('gamma\\[random\\]', parameter)) %>%
  select(lower_ci, upper_ci, estimate) %>%
  mutate(lower_ci = as.integer(lower_ci), 
         upper_ci = as.integer(upper_ci)) 
```

Figure \ref{fig:exp3_plot_days_slow_response} shows the parameter
estimation plots with time-structured data (error bars represent the
middle 95% of estimated values and shaded horizontal lines indicate the
population values). Panels A--B show the parameter estimation plots for
the fixed-effect days-to-halfway elevation and triquarter-halfway delta
parameters ($\upbeta_{fixed}$ and $\upgamma_{fixed}$),
respectively.Panels C--D show the parameter estimation plots for the
random-effect days-to-halfway elevation and triquarter-halfway delta
parameters ($\upbeta_{random}$ and $\upgamma_{random}$), respectively. Note that Table \ref{tab:omega-exp3-slow-response} provides the partial $\upomega^2$ values for the experimental variables for the day-unit parameters with time-unstructured data defined by fast response rates. 

For all simulations presented in Figure
\ref{fig:exp3_plot_days_slow_response}, two instances of bias occurred
in the estimation of day-unit parameters. First, estimation of the
random-effect halfway-triquarter delta parameter ($\upgamma_{random}$)
incurred bias with five measurements and a sample size no larger than
100. For example, the random-effect halfway-triquarter delta parameter
($\upgamma_{random}$; Figure \ref{fig:exp3_plot_days_slow_response}D)
had an average estimated value of `r gamma_random_slow_5_100$estimate`
days with a sample size of 100 with five measurements. Second,
estimation of the fixed-effect days-to halfway elevation parameter
($\upbeta_{fixed}$) incurred bias under all sample size-measurement
number conditions. For example, the fixed-effect days-to halfway
elevation parameter ($\upbeta_{fixed}$; Figure
\ref{fig:exp3_plot_days_slow_response}A) had an average estimated value
of `r beta_fixed_slow_5_30$estimate` days with a sample size of 30 and
five measurements and an average estimated value of
`r beta_fixed_slow_11_1000$estimate` days with a sample size of 1000 and
11 measurements (relative to a population value of 180.00). Across all
other conditions in Figure \ref{fig:exp3_plot_days_slow_response}, no
instance of bias occurred, as the average estimated values for all
day-unit parameters (as indicated by the black dots) were close to their
respective population values (indicated by the gray lines).

First, variability across all sample sizes for the fixed-effect
triquarter-halfway delta parameter ($\upgamma_{fixed}$) remained high
with five measurements. For example, the error bar length for the
fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$;
Figure \ref{fig:exp3_plot_days_slow_response}B) had a length of
`r gamma_fixed_fast_5_1000$upper_ci - gamma_fixed_fast_5_1000$lower_ci`
days (upper bound of `r gamma_fixed_fast_5_1000$upper_ci` days to lower
bound of `r gamma_fixed_fast_5_1000$upper_ci` days) with a sample size
of 1000 with 5 measurements. Note that the same pattern of variability
existed to a lesser extent for the random-effect days-to-halfway
elevation parameter ($\upbeta_{random}$). Second, variability for the
random-effect triquarter-halfway delta parameter ($\upgamma_{random}$)
remained high with five measurements and a sample size no larger than
200. For example, the error bar length for the random-effect
triquarter-halfway delta parameter ($\upgamma_{random}$; Figure
\ref{fig:exp3_plot_days_slow_response}D) had a length of
`r gamma_random_fast_5_200$upper_ci - gamma_random_fast_5_200$lower_ci`
days (upper bound of `r gamma_random_fast_5_200$upper_ci` days to lower
bound of `r gamma_random_fast_5_200$lower_ci` days) with a sample size
of 200 and five measurements. Third, variability across all day-unit
parameters was nearly trivial across all sample size levels with seven
measurements. For example, the error bar length for the the
random-effect halfway-triquarter delta parameter ($\upgamma_{random}$;
Figure \ref{fig:exp3_plot_days_slow_response}D) spanned approximately
`r gamma_random_fast_7_200$upper_ci - gamma_random_fast_7_200$lower_ci`
(upper bound of `r gamma_random_fast_7_200$upper_ci` days to a lower
bound of `r gamma_random_fast_7_200$lower_ci` days) days with seven
measurements and a sample size of 200 and had an average estimated value
of `r gamma_random_fast_7_200$estimate` days (relative to a population
value of 4.00).

With respect to variability, three general patterns of results emerged
in the estimation of day-unit parameters with time-unstructured data
defined by slow response rates. First, variability across all sample
sizes for the fixed-effect triquarter-halfway delta parameter
($\upgamma_{fixed}$) remained high with five measurements. For example,
the error bar length for the the fixed-effect triquarter-halfway delta
parameter ($\upgamma_{fixed}$; Figure
\ref{fig:exp3_plot_days_slow_response}B) spanned approximately
`r gamma_fixed_slow_5_1000$upper_ci - gamma_fixed_slow_5_1000$lower_ci`
days (upper bound of `r gamma_fixed_slow_5_1000$upper_ci` days to lower
bound of `r gamma_fixed_slow_5_1000$upper_ci` days) with a sample size
of 1000 and five measurements. Note that the same pattern of variability
existed to a lesser extent for the random-effect days-to-halfway
elevation parameter ($\upbeta_{random}$). Second, variability for the
random-effect triquarter-halfway delta parameter ($\upgamma_{random}$)
remained high with five measurements and a sample size no larger than
200. For example, the error bar length for the random-effect
triquarter-halfway delta parameter ($\upgamma_{random}$; Figure
\ref{fig:exp3_plot_days_slow_response}D) had a length of
`r gamma_random_slow_5_200$upper_ci - gamma_random_slow_5_200$lower_ci`
days (upper bound of `r gamma_random_slow_5_200$upper_ci` days to lower
bound of `r gamma_random_slow_5_200$lower_ci` days) with a sample size
of 200 and five measurements. Third, variability and bias across all
day-unit parameters (except the fixed-effect days-to-halfway elevation
parameter [$\upbeta_{fixed}$]) was nearly trivial across all sample
size levels with seven measurements. For example, the error bar length
for the the random-effect halfway-triquarter delta parameter
($\upgamma_{random}$; Figure \ref{fig:exp3_plot_days_slow_response}D)
spanned approximately
`r gamma_random_slow_7_200$upper_ci - gamma_random_slow_7_200$lower_ci`
(upper bound of `r gamma_random_slow_7_200$upper_ci` days to a lower
bound of `r gamma_random_slow_7_200$lower_ci` days) days with seven
measurements and a sample size of 200 and had an average estimated value
of `r gamma_random_slow_7_200$estimate` days (relative to a population
value of 4 days).

```{=tex}
\begin{figure}[H]
  \caption{Summary of Day-Unit Parameter Estimates for Time-Unstructured Data (Slow Response Rate) in Experiment 3}
  \label{fig:exp3_plot_days_slow_response}
  \includegraphics{Figures/exp3_plot_days_time unstructured (slow response)} \hfill{}
    \caption*{Note. \textup{Errors bars represent the middle 95\% of estimated values. Gray horizontal lines in each panel represent the population value for each parameter. Population values for each parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00, $\upepsilon$ = 0.03. Panels A--B show the parameter estimation plots for
the fixed- and random-effect days-to-halfway elevation  parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively. Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway elevation parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively. Note that random-effect units are in standard deviation units. See Table \ref{tab:exp3-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-slow-response} for $\upomega^2$ effect size values.}}
\end{figure}
```

```{r omega-exp3-slow-response, echo=F}
print_bias_var_omega_table(exp_data = exp_3_raw, target_col = 'time_structuredness', target_value = 'slow_response', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Untructured Data (Slow Response Rate) in Experiment 3',
footnote = 'NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 1000), NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp3_plot_days_slow_response}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp3_plot_days_slow_response}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp3_plot_days_slow_response}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp3_plot_days_slow_response}D)'))

```

## Discussion of Experiment 3

Variability is considerably high for at least two day-unit parameters
and bias was incurred for at least one day-unit parameter in all time
structuredness under different conditions. Provided below is a list
describing the general pattern of results for each time structuredness
condition:

1)  Time-structured data: high variability in the estimation of the
    fixed- and random-effect triquarter-halfway delta parameters
    ($\upgamma_{fixed}$, $\upgamma_{random}$) and bias in
    $\upgamma_{random}$ with five measurements and a sample size no
    larger than 200.
2)  Time-unstructured data (fast response): slight underestimation of
    the fixed-effect days-to-halfway elevation parameter
    ($\upbeta_{fixed}$) across all conditions and moderately high
    variability in the estimation of the random-effect days-to-halfway
    elevation parameter ($\upbeta_{random}$) across all sample sizes
    with five measurements. Variability is high in the estimation of the
    fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$)
    across all sample sizes with with five measurements and high in the
    estimation of the random-effect triquarter-halfway delta parameter
    ($\upgamma_{fixed}$) with five measurements and a sample size no
    larger than 200. The random-effect triquarter-halfway delta
    parameter ($\upgamma_{fixed}$) was systematically overestimated with
    five measurements and sample size values no larger than 100.
3)  Time-unstructured data (fast response): same pattern of results as
    with time-unstructured data define by fast responses. Only new
    result occurs in the estimation of the fixed-effect days-to-halfway
    elevation parameter ($\upbeta_{fixed}$), with the parameter being
    systematically underestimated in all conditions.

\noindent In summary, using seven measurements nearly eliminates
variability in the estimation of all day-unit parameters, but it does
not eliminate the bias incurred in estimating the fixed-effect
days-to-halfway elevation parameter ($\upbeta_{fixed}$) parameter.

```{r time-structure-plot, echo=F}
#generate logistic curve values for each day, set beta = 80 
beta <- 180
beta_slow <- 180 - 30
gamma <- 20
alpha <-  3.32
theta <- 3
days <- seq(from = 0, to = 360, by = 1)

##1) Generate curve values for each time structure condition 
curve_values_ts <- theta + (alpha - theta)/(1 + exp((beta - days)/gamma))
curve_values_slow <- theta + (alpha - theta)/(1 + exp((beta_slow - days)/gamma))

logistic_data <- data.frame('day' = days, 
                            'Population' = curve_values_ts, 
                            'Time unstructured' = curve_values_slow, check.names = F)

first_value_approx <- round(logistic_data$`Population`[logistic_data$day == 150], 2)

first_value <- logistic_data$`Population`[logistic_data$day == 150]
point_data <- data.frame('curve_value' = c(first_value, 3.16, 3.16), 
                         'day' = c(150, 180, 150), 
                         'ts' = factor(x = c('Time structured', 'Time structured', 'Time unstructured')))

#point_data <- data.frame('curve_value' = c(3.16, 3.16), 
#                         'day' = c(180, 150), 
#                         'ts' = factor(x = c('Time structured', 'Time unstructured')))
#
```

```{r time-structuredness-plot, include=F, eval= F}
logistic_data_long <- logistic_data %>% 
  pivot_longer(cols = c('Population','Time unstructured'), values_to = 'curve_value', names_to = 'time_structure', 
               names_ptypes = factor())

time_structure_curve <- ggplot(data = logistic_data_long, mapping = aes(x = day, y = curve_value, 
                                                group = time_structure, linetype = time_structure)) + 
  geom_line(size = 1) +
  geom_point(inherit.aes = F, data =  point_data, mapping = aes(x = day, y = curve_value, shape = ts), fill = 'black', size = 3) +
  scale_shape_manual(values = c(16, 1)) +
  scale_x_continuous(name = 'Day', breaks = c(0, 60, 120, 150, 180, 240, 300, 360)) + 
  scale_y_continuous(name = 'Curve value', breaks = c(3, 3.1, 3.16, 3.2, 3.3, 3.32)) + 
  annotate("rect", xmin = 150, xmax = 150 + 30, ymin = 3, ymax = 3.32, alpha = .3,fill = "gray") +
  theme_classic(base_family = 'Helvetica') + 
  labs(shape = 'Sampling method', linetype = 'Curve type') +  
  geom_segment(inherit.aes = F,aes(x = 175, y = 3.16, xend = 155, yend = 3.16), arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(inherit.aes = F,aes(x = 150, y = first_value, xend = 180, yend = first_value), arrow = arrow(length = unit(0.02, "cm"))) +
  geom_segment(inherit.aes = F,aes(x = 180, y = first_value, xend = 180, yend = 3.155), arrow = arrow(length = unit(0.3, "cm"))) +
  
  annotate(geom = 'text', parse = T, x = 60, y = 3.16, label = 'beta[fixed] == 150~days', size = 6) + 
  annotate(geom = 'text', parse = T, x = 280, y = 3.16, label = 'beta[fixed] == 180~days', size = 6) + 

  theme(axis.text = element_text(colour = 'black', size = 12), 
        axis.title = element_text(colour = 'black', size = 16), 
        legend.title = element_text(colour = 'black', size = 16), 
        legend.text = element_text(colour = 'black', size = 12))

ggsave(filename = 'Figures/time_structure_curve.pdf', plot = time_structure_curve, width = 9, height = 6)
```

Figure \ref{fig:time_structure_curve} illustrates why increasing the
number of measurements does not necessarily decrease the bias incurred
in estimating the fixed-effect days-to-halfway elevation parameter
($\upbeta_{fixed}$). Two curves are show in Figure
\ref{fig:time_structure_curve}: One curve results from having
time-structured data and another curve results from having
time-unstructured data and ignoring it. The shaded region indicates the
length of a collection period for collecting data at one time point.
Because respondents can provide data at any time during the response
window, a respondent that provides data near the end of the window may
have a higher curve value than if they respond at the beginning of the
response window. In the current example, a respondent would have a value
of `r first_value_approx` at the beginning of the response window and
3.16 at the end of the repsonse window. If a respondent provides data at
the end of the response window and time-structured data is assumed, then
the analysis will assume that the respondent provided data at day 150.
The resulting effect of incorrectly assumiing time-structured data in
the current example is that the fixed-effect days-to-halfway elevation
parameter ($\upbeta_{fixed}$) will be understimated with a value of 150
days.

```{=tex}
\begin{figure}[H]
  \caption{Depiction of Bias Caused by Time-Unstructured Data in Estimating the Fixed-Effect Days-to-Halfway Elevation Parameter ($\upbeta_{fixed}$)}
  \label{fig:time_structure_curve}
  \includegraphics{Figures/time_structure_curve} \hfill{}
  \caption*{Note. \textup{}}
\end{figure}
```
```{r plot-summary-exp3, include=F, eval=F}
generate_summary_facet_plot(condition_data = cond_summary_exp_3, lower_y_limit = -6, upper_y_limit = 20, ticks = 2, exp_num = 'Figures/exp3_', 
                            y_axis_var = 'mean_perc_error', y_axis_name = 'Parameter bias (percentage error)', 
                            x_axis_var = 'sample_size', x_axis_name = 'Sample size (*N*)', 
                            facet_var = 'time_structuredness')

```

```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```
# General discussion

```{=tex}
\nointerlineskip
\vfill
\newpage
```
# Appendix

## Appendix A: Procedure for generating measurement schedules in measurement spacing conditions {.unnumbered}

Given that no procedure existed (to my knowledge) for creating
measurement schedules, I devised a method for generating measurement
schedules for the four spacing conditions (equal, time-interval
increasing, time-interval decreasing, and middle-and-extreme spacing).
For each measurement spacing conditions across all measurement number
levels, a two-step procedure was employed to generate measurement
schedules in Experiments 2--3. At a broad level, the first step involved
computing setup variables and the second step computed the interval
lengths.

### Appendix A1: Procedure for calculating measurement schedules with equal spacing {.unnumbered}

Figure \@ref{fig:equal_spacing_diagram} shows how the two-step procedure
was implemented to construct a measurement schedule with equal spacing
and five measurements. In the first step, the number of intervals ($NI$)
was computed by subtracting one from the number of measurements ($NM$),
giving five measurements ($NM = 5$) and four intervals ($NI = 4$). In
the second step, interval lengths were calculated by dividing the length
of the measurement period ($MP$) by the number of intervals ($NI$),
yielding an interval length of 90 days
($\frac{MP}{NI} = \frac{360}{4} = 90$).

\blandscape

```{=tex}
\begin{figure}[H]
  \caption{Procedure for Generating Equal Measurement Spacing Schedules}
  \label{fig:equal_spacing_diagram}
  \includegraphics{Figures/equal_spacing_diagram} \hfill{}
  \caption*{Note. \textup{}}
\end{figure}
```
\elandscape

### Appendix A2: Procedure for calculating measurement schedules with time-interval increasing spacing

Figure \@ref{fig:time_inc_diagram} shows how the two-step procedure was
used to calculate the interval lengths for measurement schedules defined
by time-interval increasing spacing with five measurements. In the first
step, the number of intervals was determined by subtracting one from the
number of measurements, yielding a value of four for the number of
intervals ($NI = NM - 1 = 5 - 1 = 4$). Importantly, the length of each
interval increased by a constant value $c$ over time as shown below in
Equation \ref{eq:time-inc-length}:

```{=tex}
\begin{align}
\text{Interval length} = x + \#IN(c)
(\#eq:time-inc-length)
\end{align}
```
\noindent where $\#IN$ represents the interval number in increasing
order such that
$\#IN \in \{0, ..., \text{number of intervals (NI)} - 1\}$. In the
second step, the constant value by which interval lengths increased
($c$) was computed by first subtracting the smallest interval length
from each interval (i.e., $x = 36$ days) from the measurement period
($MP$), yielding 216 remaining days
($N_{remain} = MP - NIx = 360 - 4(36) = 216$). The number of remaining
days then had to be divided across the constant interval lengths.
Because each interval increased by some constant value ($c$ after each
measurement point, the total number of constant-value interval lengths
was obtained by computing the following sum in Equation
\ref{eq:time-sum-constants}:

```{=tex}
\begin{align}
\text{Number constant intervals} = \sum^{\#IN}_{i = 0} i.
(\#eq:time-sum-constants)
\end{align}
```
\noindent With $\#IN = 3$, the number of constant intervals was 6, and
so the constant value was obtained by using Equation
\ref{eq:constant-length} below:

```{=tex}
\begin{align}
\text{Number constant intervals} = \frac{N_{remain}}{\sum^{\#IN}_{i = 0} i},
(\#eq:constant-length)
\end{align}
```
\noindent giving a length of 36 days for the constant value
($c = \frac{216}{6} = 36$ days). Having computed the value for $c$, the
following interval lengths were obtained:

-   $i_{1} = x + \#IN(c) = 36 + 0(36)$ = 36 days
-   $i_{2} = x + \#IN(c) = 36 + 1(36)$ = 72 days
-   $i_{3} = x + \#IN(c) = 36 + 2(36)$ = 108 days
-   $i_{4} = x + \#IN(c) = 36 + 3(36)$ = 144 days

\blandscape

```{=tex}
\begin{figure}[H]
  \caption{Procedure for Generating Time-Interval Increasing Measurement Spacing Schedules}
  \label{fig:time_inc_diagram}
  \includegraphics{Figures/time_inc_diagram} \hfill{}
  \caption*{Note. \textup{}}
\end{figure}
```
\elandscape

### Appendix A3: Procedure for calculating measurement schedules with time-interval decreasing spacing {.unnumbered}

Figure \@ref{fig:time_dec_diagram} shows how the two-step procedure was
used to calculate the interval lengths for measurement schedules defined
by time-interval decreasing spacing with five measurements. In the first
step, the number of intervals was determined by subtracting one from the
number of measurements, yielding a value of four for the number of
intervals ($NI = NM - 1 = 5 - 1 = 4$). Importantly, the length of each
interval decreased by a constant value $c$ over time as shown below in
Equation \ref{eq:time-dec-length}:

```{=tex}
\begin{align}
\text{Interval length} = x + \#INT(c)
(\#eq:time-dec-length)
\end{align}
```
\noindent where $\#IN$ represents the interval number in decreasing
order such that
$\#IN \in \{\text{number of intervals (NI)} - 1, ... , 0\}$. In the
second step, the constant value by which interval lengths decreased
($c$) was computed by first subtracting the smallest interval length
from each interval (i.e., $x = 36$ days) from the measurement period
($MP$), yielding 216 remaining days
($N_{remain} = MP - NIx = 360 - 4(36) = 216$). The number of remaining
days then had to be divided across the constant interval lengths.
Because each interval decreased by some constant value ($c$ after each
measurement point, the total number of constant-value interval lengths
was obtained by computing the following sum in Equation
\ref{eq:dec-sum-constants}:

```{=tex}
\begin{align}
\text{Number constant intervals} = \sum_{\#IN}^{i = 0} i.
(\#eq:dec-sum-constants)
\end{align}
```
\noindent With $\#IN = 3$, the number of constant intervals was 6, and
so the constant value was obtained by using Equation
\ref{eq:constant-length-2} below:

```{=tex}
\begin{align}
\text{Number constant intervals} = \frac{N_{remain}}{\sum^{\#IN}_{i = 0} i},
(\#eq:constant-length-2)
\end{align}
```
\noindent giving a length of 36 days for the constant value
($c = \frac{216}{6} = 36$ days). Having computed the value for $c$, the
following interval lengths were obtained:

-   $i_{1} = x + \#IN(c) = 36 + 3(36)$ = 144 days
-   $i_{4} = x + \#IN(c) = 36 + 0(36)$ = 36 days
-   $i_{3} = x + \#IN(c) = 36 + 1(36)$ = 72 days
-   $i_{2} = x + \#IN(c) = 36 + 2(36)$ = 108 days

\blandscape

```{=tex}
\begin{figure}[H]
  \caption{Procedure for Generating Time-Interval Decreasing Measurement Spacing Schedules}
  \label{fig:time_dec_diagram}
  \includegraphics{Figures/time_dec_diagram} \hfill{}
  \caption*{Note. \textup{}}
\end{figure}
```
\elandscape

### Appendix A4: Procedure for calculating measurement schedules with middle-and-extreme spacing {.unnumbered}

Figure \@ref{fig:mid_ext_diagram} shows how the two-step procedure was
used to calculate the interval lengths for measurement schedules defined
by middle-and-extreme spacing with five measurements. In the first step,
the number of intervals was determined by subtracting one from the
number of measurements, yielding a value of four for the number of
intervals ($NI = NM - 1 = 5 - 1 = 4$)... 

\blandscape

```{=tex}
\begin{figure}[H]
  \caption{Procedure for Generating Time-Interval Decreasing Measurement Spacing Schedules}
  \label{fig:mid_ext_diagram}
  \includegraphics{Figures/mid_ext_diagram} \hfill{}
  \caption*{Note. \textup{}}
\end{figure}
```
\elandscape

## Appendix B: Convergence rates {#appendix-a-convergence-rates}

\newpage

```{r convergence-rates, echo=F, warning=F}
exp_1_conv <- generate_conv_success_data(condition_data = cond_summary_exp_1, first_col = 'measurement_spacing', second_col = 'number_measurements', wide_var = 'midpoint', exp_num = 1, recode_var = 'measurement_spacing')

exp_2_conv <- generate_conv_success_data(condition_data = cond_summary_exp_2, first_col = 'measurement_spacing', second_col = 'number_measurements', wide_var = 'sample_size', exp_num = 2, recode_var = 'measurement_spacing')

exp_3_conv <- generate_conv_success_data(condition_data = cond_summary_exp_3, first_col = 'time_structuredness', second_col = 'number_measurements', wide_var = 'sample_size', exp_num = 3, recode_var = 'time_structuredness')
```

\newpage

```{r conv-exp-1, echo=F}
print_conv_table(table_ready_data = exp_1_conv, 
                 caption_name = 'Convergence Success in Experiment 1', 
                 col_header_name = c('Days to halfway elevation'), 
                 IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
                 column_names = c('80', '180', '280'))
```

\newpage

```{r conv-exp-2, echo=F}
print_conv_table(table_ready_data = exp_2_conv, 
                 caption_name = 'Convergence Success in Experiment 2', 
                 col_header_name = c('Sample size (\\\\textit{N})'), 
                 IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
                 column_names = c('30', '50', '100', '200', '500', '1000'))
```

\newpage

```{r conv-exp-3, echo=F}
print_conv_table(table_ready_data = exp_3_conv, 
                 caption_name = 'Convergence Success in Experiment 3', 
                 col_header_name = c('Sample size (\\\\textit{N})'), 
                 IV_names =  c('Time Structuredness', 'Number of Measurements'), 
                 column_names = c('30', '50', '100', '200', '500', '1000'))
```

## Appendix C: Parameter estimation plots for Likert-unit parameters {#appendix-c-parameter-estimation-plots-for-likert-unit-parameters}

## Appendix D: Parameter estimate tables

### Experiment 1

```{r exp-table-generation, echo=F}
exp_1_tables <- create_table_data_sets(param_summary_data = param_summary_exp_1, 
                                       wide_var = 'midpoint', first_col = 'measurement_spacing', second_col = 'number_measurements')
  
exp_2_tables <- create_table_data_sets(param_summary_data = param_summary_exp_2, 
                                       wide_var = 'sample_size', first_col = 'measurement_spacing', second_col = 'number_measurements')

exp_3_tables <- create_table_data_sets(param_summary_data = param_summary_exp_3, 
                                       wide_var = 'sample_size', first_col = 'time_structuredness', second_col = 'number_measurements') 

#remove measurement spacing columns 
col_to_remove <- which(str_detect(string = names(exp_3_tables$estimate_table), pattern = 'measurement_spacing'))

exp_3_tables$estimate_table <- exp_3_tables$estimate_table[, -col_to_remove]
exp_3_tables$removed_value_table <- exp_3_tables$removed_value_table[ , -col_to_remove]
```

\renewcommand{\arraystretch}{0.8}{0.9}

```{r exp1-alpha-theta-param-est, echo=F}
usepackage_latex('makecell')

print_param_table(table_ready_data = exp_1_tables$estimate_table, parameter_name = 'theta|alpha', 
            caption_name = 'Parameter Values Estimated in Experiment 1', 
            col_header_name = c('\\\\thead{$\\\\uptheta_{fixed}$ (Baseline)  \\\\\\\\ Pop value = 3.00}', 
                                '\\\\thead{$\\\\uptheta_{random}$ (Baseline) \\\\\\\\ Pop value = 0.05}',
                                '\\\\thead{$\\\\upalpha_{fixed}$ (Maximal \\\\\\\\ elevation)  \\\\\\\\ Pop value = 3.32}', 
                                '\\\\thead{$\\\\upalpha_{random}$ (Maximal \\\\\\\\ elevation) \\\\\\\\ Pop value = 0.05}'), 
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c('80', '180', '280'))
```

\addtocounter{table}{-1}

```{r exp1-beta-gamma-param-est, echo=F}
print_param_table(table_ready_data = exp_1_tables$estimate_table, parameter_name = 'beta|gamma', 
            caption_name = 'Parameter Values Estimated in Experiment 1 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upbeta_{fixed}$ (Days to \\\\\\\\ halfway elevation)}', 
                                '\\\\thead{$\\\\upbeta_{random}$ (Days to \\\\\\\\ halfway elevation) \\\\\\\\ Pop value = 10.00}', 
                                '\\\\thead{$\\\\upgamma_{fixed}$ (Triquarter- \\\\\\\\ halfway delta) \\\\\\\\ Pop value = 20.00}', 
                                '\\\\thead{$\\\\upgamma_{random}$ (Triquarter- \\\\\\\\ halfway delta) \\\\\\\\ Pop value = 4.00}'),
             IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c(80, 180, 280))
```

\addtocounter{table}{-1}

```{r exp1-epsilon-param-est, echo=F}
print_param_table(table_ready_data = exp_1_tables$estimate_table, parameter_name = 'epsilon', 
            caption_name = 'Parameter Values Estimated in Experiment 1 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upepsilon$(error) \\\\\\\\ Pop value = 0.03}'),
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c(80, 180, 280))
```

### Experiment 2

```{r exp2-theta-param-est, echo=F}
print_param_table(table_ready_data = exp_2_tables$estimate_table, parameter_name = 'theta', 
            caption_name = 'Parameter Values Estimated in Experiment 2', 
           col_header_name = c('\\\\thead{$\\\\uptheta_{fixed}$ (Baseline) \\\\\\\\ Pop value = 3.00}', 
                               '\\\\thead{$\\\\uptheta_{random}$ (Baseline) \\\\\\\\ Pop value = 0.05}'),
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

\addtocounter{table}{-1}

```{r exp2-alpha-param-est, echo=F}
print_param_table(table_ready_data = exp_2_tables$estimate_table, parameter_name = 'alpha', 
            caption_name = 'Parameter Values Estimated in Experiment 2 (continued)', 
           col_header_name = c('\\\\thead{$\\\\upalpha_{fixed}$ (Maximal elevation) \\\\\\\\ Pop value = 3.32}', 
                               '\\\\thead{$\\\\upalpha_{random}$ (Maximal elevation) \\\\\\\\ Pop value = 0.05}'),
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

\addtocounter{table}{-1}

```{r exp2-beta-param-est, echo=F}
print_param_table(table_ready_data = exp_2_tables$estimate_table, parameter_name = 'beta', 
            caption_name = 'Parameter Values Estimated in Experiment 2 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upbeta_{fixed}$ (Days to halfway elevation) \\\\\\\\ Pop value = 180.00}', 
                               '\\\\thead{$\\\\upbeta_{random}$ (Days to halfway elevation) \\\\\\\\ Pop value = 10.00}'), 
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

\addtocounter{table}{-1}

```{r exp2-gamma-param-est, echo=F}
print_param_table(table_ready_data = exp_2_tables$estimate_table, parameter_name = 'gamma', 
            caption_name = 'Parameter Values Estimated in Experiment 2 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upgamma_{fixed}$ (Triquarter-halfway delta) \\\\\\\\ Pop value = 20.00}', 
                                '\\\\thead{$\\\\upgamma_{random}$ (Triquarter-halfway delta) \\\\\\\\ Pop value = 4.00}'),
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

\addtocounter{table}{-1}

```{r exp2-epsilon-param-est, echo=F}
print_param_table(table_ready_data = exp_2_tables$estimate_table, parameter_name = 'epsilon', 
            caption_name = 'Parameter Values Estimated in Experiment 2 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upepsilon$(error) \\\\\\\\ Pop value = 0.03}'), 
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

### Experiment 3

```{r exp3-theta-param-est, echo=F}
print_param_table(table_ready_data = exp_3_tables$estimate_table, parameter_name = 'theta', 
            caption_name = 'Parameter Values Estimated in Experiment 3', 
           col_header_name = c('\\\\thead{$\\\\uptheta_{fixed}$ (Baseline) \\\\\\\\ Pop value = 3.00}', 
                               '\\\\thead{$\\\\uptheta_{random}$ (Baseline) \\\\\\\\ Pop value = 0.05}'),
           IV_names =  c( 'Time Structuredness', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

```{r exp3-alpha-param-est, echo=F}
print_param_table(table_ready_data = exp_3_tables$estimate_table, parameter_name = 'alpha', 
            caption_name = 'Parameter Values Estimated in Experiment 3 (continued)', 
           col_header_name = c('\\\\thead{$\\\\upalpha_{fixed}$ (Maximal elevation) \\\\\\\\ Pop value = 3.32}', 
                               '\\\\thead{$\\\\upalpha_{random}$ (Maximal elevation) \\\\\\\\ Pop value = 0.05}'),
            IV_names =  c( 'Time Structuredness', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

```{r exp3-beta-param-est, echo=F}
print_param_table(table_ready_data = exp_3_tables$estimate_table, parameter_name = 'beta', 
            caption_name = 'Parameter Values Estimated in Experiment 3 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upbeta_{fixed}$ (Days to halfway elevation) \\\\\\\\ Pop value = 180.00}', 
                               '\\\\thead{$\\\\upbeta_{random}$ (Days to halfway elevation) \\\\\\\\ Pop value = 10.00}'), 
            IV_names =  c('Time Structuredness', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

```{r exp3-gamma-param-est, echo=F}
print_param_table(table_ready_data = exp_3_tables$estimate_table, parameter_name = 'gamma', 
            caption_name = 'Parameter Values Estimated in Experiment 3 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upbeta_{fixed}$ (Days to halfway elevation) \\\\\\\\ Pop value = 180.00}', 
                               '\\\\thead{$\\\\upbeta_{random}$ (Days to halfway elevation) \\\\\\\\ Pop value = 10.00}'), 
            IV_names =  c('Time Structuredness', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```

```{r exp3-epsilon-param-est, echo=F}
print_param_table(table_ready_data = exp_3_tables$estimate_table, parameter_name = 'epsilon', 
            caption_name = 'Parameter Values Estimated in Experiment 3 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upepsilon$(error) \\\\\\\\ Pop value = 0.03}'), 
            IV_names =  c('Time Structuredness', 'Number of Measurements'), 
            column_names = c("30", "50", "100", "200", "500", "1000"))
```


## Appendix D: Understanding ergodicity with code
# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```
