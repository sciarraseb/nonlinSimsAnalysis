---
shorttitle        : "Measurement timing"
format          : "pandoc"
header-includes:
  - \usepackage{nccmath}
  - \usepackage{caption}
  - \usepackage{textcomp} #for copyright symbol on title page
  - \usepackage{longtable}
  - \usepackage{makecell}
  - \usepackage[section]{placeins}
  - \usepackage{setspace}
  - \usepackage{biblatex}
  - \usepackage{booktabs}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{xcolor}
  - \usepackage{amsthm} 
  - \usepackage{amsmath} ##needed for argmax
  - \usepackage{bm}  #thicker bold in math 
  - \DeclareMathOperator*{\argmax}{arg\,max}
  - \usepackage{setspace} #needed to doublespace caption text (using \doublespacing)
  - \usepackage[labelfont = {bf, up}]{caption} 
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \usepackage{upgreek}  #required for non-italicized Greek letters
  - \usepackage{subcaption}
  - \captionsetup[figure]{labelfont={normalfont, bf}, singlelinecheck=false, labelsep=newline}
  - \DeclareCaptionFont{figCaptionFont}{\fontfamily{phv}\doublespacing} #sets caption font to sans serif font of Helvetica 
  - \DeclareCaptionFont{figCaptionSize}{\fontsize{11pt}{13.2pt}\selectfont} #set caption font size to footnote 
  - \DeclareCaptionFont{tabCaptionSize}{\small} #caption size for table title
  - \DeclareCaptionFont{figCaptionStyle}{\textup}  #set caption font to non-italicized font  
  - \DeclareCaptionLabelSeparator{captionSep}{\newline} #separates figure label and figure title with required white space
  - \captionsetup[figure]{labelfont={figCaptionStyle, bf}, font = {figCaptionFont,figCaptionSize, figCaptionStyle}, labelsep = captionSep, justification= raggedright}
  - \captionsetup[table]{labelfont={tabCaptionSize, bf}, font = {figCaptionFont, tabCaptionSize, figCaptionStyle}, labelsep = captionSep, justification= raggedright}
  - \newenvironment{helvenv}{\fontfamily{phv}\selectfont}{}
  - \raggedbottom #ensures text starts from top of page and any white space is at the botom

#both are needed to change font type of table footnotes
  - \usepackage{anyfontsize}
  - \AtBeginEnvironment{ThreePartTable}{\fontfamily{phv} \fontsize{10.5pt}{12pt}\selectfont} 
  - \AtBeginEnvironment{tablenotes}{\fontsize{9.5pt}{11.4pt}\selectfont} 

#environment numbering 
  - \setcounter{section}{0} 
  - \makeatletter \renewcommand\thesection{}\renewcommand\thesubsection{\@arabic\c@section.\@arabic\c@subsection} \makeatother

#set table line widths 
  - \setlength\cmidrulewidth{1pt} #line thickness of lines within table and in multi-row headers
  - \setlength\lightrulewidth{1pt} #line thickness of bottom line in header 

  - \newtheorem{theorem}{Theorem}
  - \newtheorem{example}[theorem]{Example}
  - \renewcommand\theadfont{} #sets cell font to be same as table font 
  
  #set figure title text
  - \newcommand{\figurefootnote}{\raggedright\linespread{2}\fontfamily{phv}\fontsize{9.5pt}{11.4pt}\selectfont \textit{Note. }}
  
  #table of contents settings 
  - \setcounter{tocdepth}{5} #
  - \setcounter{secnumdepth}{5} #set depth of header that will be numbered in the text and in the table of contents

  #modifies heading levels of 4-5 to follow apa7
  -  |
    \makeatletter
    
    \renewcommand\paragraph{% 
     \@startsection{paragraph}%
      {4}%
      {\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-0.5em}%
      {\normalfont\normalsize\bfseries\typesectitle}
    }
    
      
     \renewcommand\subparagraph{%
      \@startsection{subparagraph}%
      {5}%
      {\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-0.5em}%
      {\normalfont\normalsize\bfseries\itshape\typesectitle}}
    \makeatother
  
author: 
  - name          : "Sebastian Sciarra "
    affiliation   : "1"
    corresponding : yes    
    email         : "ssciarra@uoguelph.ca"
affiliation: 
  - id            : "1"
    institution   : "University of Guelph"
keywords          : "measurement timing, nonlinear "
wordcount         : "5554 words"
floatsintext      : yes
linkcolor         : blue
figsintext        : yes 
figurelist        : yes
tablelist         : no
footnotelist      : no

linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa7"
csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
classoption       : "man"        
output: 
  papaja::apa6_pdf:
    toc: true
    toc_depth: 5
    keep_tex: TRUE

editor_options: 
  markdown: 
    wrap: 72
bibliography: dissertation_references.bib
---


```{r package_loading_1, include=F}
#load packages'
library(easypackages)
packages <- c('devtools','tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'nonlinSims','papaja', 'ggbrace', 'cowplot')
libraries(packages)
load_all()
```

```{r knitting_setup_1, echo=F, message = F, warning = F}
#import raw data files (needed for computing variances)
exp_1_raw <- convert_raw_var_to_sd(raw_data = read_csv('data/exp_1_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)
  
exp_2_raw <-convert_raw_var_to_sd(raw_data = read_csv('data/exp_2_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "sample_size"), factor)

exp_3_raw <-convert_raw_var_to_sd(raw_data = read_csv('data/exp_3_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)

#unfiltered data 
param_summary_exp_1 <- readRDS(file = 'data/uf_param_summary_exp_1.RData')
param_summary_exp_2 <- readRDS(file = 'data/uf_param_summary_exp_2.RData')
param_summary_exp_3 <- readRDS(file = 'data/uf_param_summary_exp_3.RData')

#create analytical versions of summary data + converts vars to sds
exp_1_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1, exp_num = '1')
exp_2_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_2, exp_num = '2')
exp_3_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3, exp_num = '3')

combined_analytical_exp_1 <- rbind(exp_1_analytical$likert, exp_1_analytical$days)
combined_analytical_exp_2 <- rbind(exp_2_analytical$likert, exp_2_analytical$days)
combined_analytical_exp_3 <- rbind(exp_3_analytical$likert, exp_3_analytical$days)

#create condition summary data sets 
cond_summary_exp_1 <- compute_condition_summary(param_summary_data = combined_analytical_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))
cond_summary_exp_2 <- compute_condition_summary(param_summary_data = combined_analytical_exp_2, facet_var = 'measurement_spacing', 
                  ind_vars = c('number_measurements', 'measurement_spacing', 'sample_size'))

cond_summary_exp_3 <- compute_condition_summary(param_summary_data = combined_analytical_exp_3, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))
```

```{r pre_knitting_setup_unfiltered_1, echo=F, eval=F, include=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_data.csv') %>% filter(code == 0)
exp_2 <- read_csv(file = 'data/exp_2_data.csv')
exp_3 <- read_csv(file = 'data/exp_3_data.csv')

#compute parameter summary statistics  
exp_1_long <- exp_1 %>%
    filter(code == 0) %>%
    #place parameter estimates in one column
    pivot_longer(cols = contains(c('theta', 'alpha', 'beta', 'gamma', 'epsilon')),
                 names_to = 'parameter', values_to = 'estimate') %>%
    filter(parameter == 'beta_fixed') %>%
    mutate(pop_value = midpoint)

exp_1_ordered <- order_param_spacing_levels(data = exp_1_long)


compute_parameter_summary(data = exp_1, exp_num = '1')

param_summary_exp_1 <- compute_parameter_summary(data = exp_1, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3, exp_num = 3)

#necessary factor conversions 
param_summary_exp_1$number_measurements <- factor(param_summary_exp_1$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_1$midpoint <- factor(param_summary_exp_1$midpoint, levels = c(80, 180,280))

param_summary_exp_2$number_measurements <- factor(param_summary_exp_2$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_2$sample_size <- factor(param_summary_exp_2$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

param_summary_exp_3$number_measurements <- factor(param_summary_exp_3$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_3$sample_size <- factor(param_summary_exp_3$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/uf_param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_2, file = 'data/uf_param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/uf_param_summary_exp_3.RData')
```


# Experiment 1


In Experiment 1, I investigated the number of measurements needed to obtain accurate modelling (i.e., low bias and high precision) under different spacing schedules and natures of change. Before presenting the results of Experiment 1, I will present my design and analysis goals. For the design, I conducted a 4(measurement spacing:equal, time-interval increasing, time-interval decreasing, middle-and-extreme x 4(number of measurements: 5, 7, 9, 11) x 3(nature of change: population value for the fixed-effect days-to-halfway elevation parameter [$\upbeta_{fixed}$] of 80, 180, or 280) study. For the analysis, I was interested in answering two questions. First, I was interested in whether spacing measurements near periods of change leads to higher modelling accuracy. To answer the first question, I determined whether modelling accuracy under each spacing schedule increased when measurements were taken closer to periods of change.

Second, I was interested in how to space measurements when the nature of change is unknown. When the nature of change is unknown, this translates to a situation where a researcher has little to no knowledge of how change unfolds over time, and so any nature of change is a viable candidate for the true change. Therefore, to determine how to space measurements when the nature of change is unknown, I averaged the modelling accuracy of each spacing schedule across all possible nature-of-change curves and considered the spacing schedule with the highest modelling accuracy to be the best one.

## Methods
### Variables Used in Simulation Experiment

#### Independent Variables

To build on current research, Experiment 1 used independent variable manipulations from a select number of previous studies. In looking at the summary of the simulation literature in Table \ref{tab:systematicReview}, the study by @coulombe2016 was the only one to investigate three longitudinal issues of interest to my dissertation, and so represented the most comprehensive investigation. Because I was also interested in investigating measurement spacing, manipulations were inspired from the only other simulation study to manipulate measurement spacing [the study by @timmons2015]. The sections that follow will discuss each of the variables manipulated in Experiment 1. 

##### Spacing of Measurements {#spacing-measurements}

The only simulation study identified by my systematic review that manipulated measurement spacing was
@timmons2015. Measurement spacing in @timmons2015 was manipulated in the
following four ways:

1)  **Equal spacing**: measurements were divided by intervals of
    equivalent lengths.
    
2)  **Time-interval increasing spacing**: intervals that divided measurements
    increased in length over time.

3)  **Time-interval decreasing spacing**: intervals that divided measurements
    decreased in length over time.

4)  **Middle-and-extreme spacing**: measurements were clustered near the
    beginning, middle, and end of the data collection period.

\noindent To maintain consistency with the established literature, I manipulated measurement spacing in the same way as @timmons2015 presented above. Importantly, because @timmons2015 did not create their measurement spacing schedules with any systematicity, I developed a novel and replicable procedure for generating measurement schedules for each of the four measurement spacing conditions, which is described in [Appendix A](#appendix-A). I also automated the generation of measurement schedules by creating a set of functions in R [@rstudio]. 

Table \@ref(tab:measurementDays) lists the measurement days that were
used for all measurement spacing-measurement number cells. The first
column lists the type of measurement spacing (i.e., equal, time-interval
increasing, time-interval decreasing, or middle-and-extreme); the second
column lists the number of measurements (5, 7, 9, or 11); the third
column lists the measurement days that correspond to each measurement
number-measurement spacing condition; and the fourth column lists the
interval lengths that characterize each set of measurements. Note that
the interval lengths are equal for the equal spacing, increase over time
for the time-interval increasing spacing, and decrease over time for the
time-interval decreasing spacing, For cells with middle-and-extreme
spacing, the measurement days and and interval lengths corresponding to
the middle of the measurement window have been emboldened.

```{r measurementDays, echo=F}
time_period <- 360
num_measurements <- seq(from = 5, to = 11, by = 2)
smallest_int_length <- 30

#meausurement days 
equal_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_9 <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_11 <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'equal')$measurement_days

time_inc_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days
time_inc_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days
time_inc_9 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days, 2)
time_inc_11 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days, 2)

time_dec_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days
time_dec_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days
time_dec_9 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days, 2)
time_dec_11 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days, 2)

mid_ext_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_9 <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_11 <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days


#measurement intervals
equal_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_9_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_11_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'equal')$interval_lengths

time_inc_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths
time_inc_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths
time_inc_9_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths, 2)
time_inc_11_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths, 2)

time_dec_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths
time_dec_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths
time_dec_9_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths, 2)
time_dec_11_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths, 2)

mid_ext_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_9_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_11_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths


measurement_days_df <- data.frame('Spacing Schedule' = c('Equal', '', '', '', 
                                                         'Time-interval increasing', '', '', '', 
                                                         'Time-interval decreasing', '', '', '', 
                                                         'Middle-and-extreme', '', '', ''), 
                                  'Number of Measurements' = rep(num_measurements, times = 4), 
                                  'Measurement Days' = c(paste(equal_5, collapse = ', '), 
                                                         paste(equal_7, collapse = ', '), 
                                                         paste(equal_9, collapse = ', '), 
                                                         paste(equal_11, collapse = ', '), 
                                                         
                                                         paste(time_inc_5, collapse = ', '),
                                                         paste(time_inc_7, collapse = ', '),
                                                         paste(time_inc_9, collapse = ', '),
                                                         paste(time_inc_11, collapse = ', '),
                                                         
                                                         paste(time_dec_5, collapse = ', '),
                                                         paste(time_dec_7, collapse = ', '),
                                                         paste(time_dec_9, collapse = ', '),
                                                         paste(time_dec_11, collapse = ', '),
                                                         
                                                        '1, \\textbf{150, 180, 210}, 360',
                                                        '1, 30, \\textbf{150, 180, 210}, 330, 360',
                                                        '1, 30, 60, \\textbf{150, 180, 210}, 300, 330, 360',
                                                        '1, 30, 60, \\textbf{120, 150, 180, 210, 240,} 300, 330, 360'), 
                                  
                                  'Interval Lengths' = c(paste(equal_5_int, collapse = ', '), 
                                                         paste(equal_7_int, collapse = ', '), 
                                                         paste(equal_9_int, collapse = ', '), 
                                                         paste(equal_11_int, collapse = ', '), 
                                                         
                                                         paste(time_inc_5_int, collapse = ', '),
                                                         paste(time_inc_7_int, collapse = ', '),
                                                         paste(time_inc_9_int, collapse = ', '),
                                                         paste(time_inc_11_int, collapse = ', '),
                                                         
                                                         paste(time_dec_5_int, collapse = ', '),
                                                         paste(time_dec_7_int, collapse = ', '),
                                                         paste(time_dec_9_int, collapse = ', '),
                                                         paste(time_dec_11_int, collapse = ', '),
                                                         
                                                        '150, \\textbf{30, 30}, 150',
                                                         '30, 120, \\textbf{30, 30}, 120, 30',
                                                         '30, 30, 90, \\textbf{30, 30}, 90, 30, 30',
                                                         '30, 30, 60, \\textbf{30, 30, 30, 30}, 60, 30, 30'),
                                  check.names = F)

kbl(x = measurement_days_df, booktabs = TRUE, format = 'latex', longtable = T, 
      align = c('l', 'l'), 
    linesep = c(rep('', times = 3),
            '\\cmidrule{1-4}\\addlinespace'), 
      caption = 'Measurement Days Used for All Measurement Number-Measurement Spacing Conditions ', 
    escape=F) %>%
    column_spec(column = 1, width = '4.5cm') %>%
  column_spec(column = 2, width = '3cm') %>%
   column_spec(column = 3, width = '6.5cm') %>%
     column_spec(column = 4, width = '6cm') %>%

   kable_styling(latex_options= c('hold_position', 'repeat_header'), font_size = 10, position = 'left') %>%  
    footnote(general =  "For middle-and-extreme spacing levels, the measurement days and and interval lengths corresponding to the middle of measurement windows have been emboldened.",  threeparttable = T,  escape = F, general_title = '\\\\textit{Note.}\\\\hspace{-1.25pc}')%>%
  landscape(margin = '2.54cm')

```

##### Number of Measurements{#number-measurements}

(ref:loehlin2017) [(\textit{p}[{\textit{p} + 1}]/2\; see @loehlin2017]
(ref:coulombe2016three) @coulomble2016(i.e., three)

The smallest measurement number value in (ref:coulombe2016three) could not be used in Experiment 1 (or any other simulation experiment that manipulated measurement number in my dissertation) because doing so would have created non-identified models. The model used in my simulations estimated 9 parameters (*p* = 9; 4 fixed-effects + 4 random-effects + 1
error) and so the minimum number of measurements (or observed variables) required for model identification (and to allow model comparison) was 4.\footnote{Degrees of freedom is calculated by multiplying the number of observed variables (\textit{p})
by \textit{p} + 1 and dividing it by 2 (ref:loehlin2017)}. Although a measurement number of three could not be used in my manipulation of measurement number, the next highest measurement number values in @coulombe2016 of 5, 7, and 9 were used. Importantly, a larger value of 11 was added to test for a possible effect of a high measurement number. Therefore, my simulation experiments used the following values in manipulating the number of
measurements: 5, 7, 9, and 11. 

##### Population Values Set for The Fixed-Effect Days-to-Halfway Elevation Parameter $\upbeta_{fixed}$ (Nature of Change)

The nature of change was manipulated by setting the days-to-halfway elevation parameter ($\upbeta_{fixed}$) to a value of either 80, 180, or 280 days (see Figure \ref{fig:combined_plot}A). Note that no other study manipulated nature of change using logistic curves and so its manipulation in Experiment 1 is, to the best of my knowledge, unique (in this literature). Nature of change was manipulated to simulate situations where uncertainty exists in the nature of change. 

#### Constants 

Because sample size was not manipulated in Experiment 1, I set it to have a constant value across all cells. I decided to set the sample size value to the average sample size used in organizational research [*n* = 225\; @bosco2015]. Another variable set to a constant value across the cells was time structuredness (data were assumed to be time structured). That is, data were generated such that, at each time point, all data were obtained at the exact same time. 

#### Dependent Variables

##### Convergence Success Rate{#convergence}

The proportion of iterations in a cell where models converged defined
the *convergence success rate*.\footnote{Specifically, convergence was obtained if the convergence code returned by OpenMx was 0.} Equation \@ref(eq:convergence) below shows the calculation used to compute the convergence success rate:

```{=tex}
\begin{align}
  \text{Convergence success rate} =  \frac{\text{Number of models that successfully converged in a cell}}{n},
  (\#eq:convergence) 
\end{align}
```
\noindent where *n* represents the total number of models run in a cell.

##### Bias{#bias-comp}

Bias was calculated to evaluate the accuracy with which each logistic
function parameter was estimated in each experimental cell. As shown below in Equation
\@ref(eq:bias), *bias* was obtained by summing the differences
between the population value set for a parameter and the value estimated for the parameter by each $i$ converged model and then dividing the sum by the number of $N$ converged models. 

$$ \text{Bias} =  \frac{\sum_i^N\text{(Population value for parameter} - \text{Average estimated value}_i)}{N} $$
\useshortskip
```{=tex}
\begin{align}
  \text{Bias} =  \text{Population value for parameter} - \text{Average estimated value}
  (\#eq:bias) 
\end{align}
```

\noindent Bias was calculated for the fixed- and random-effect parameters of the baseline ($\uptheta_{fixed}$, $\uptheta_{random}$), maximal elevation ($\upalpha_{fixed}$, $\upalpha_{random}$), days-to-halfway elevation ($\upbeta_{fixed}$, $\upbeta_{random}$), and the halfway-triquarter delta parameters ($\upgamma_{fixed}$, $\upgamma_{random}$) and the error parameter ($\upepsilon$). 

##### Precision

In addition to computing bias, precision was calculated to evaluate the variability with which each parameter was estimated. Importantly, metrics used to evaluate precision in previous studies could not be used for two reasons. First, some metrics assume estimates are normally distributed (e.g., mean-squared error and empirical standard error). Because some parameters in my simulations had skewed distributions, using a metric that assumed a normal distribution would likely yield inaccurate results. Second, although some simulation studies have used confidence intervals to evaluate precision, there is no confidence interval calculation (to my knowledge) for structure latent growth curves. Therefore, I defined *precision* as the range of values covered by the middle 95% of values estimated for a logistic parameter, which could be interpreted as a range of plausible population estimates. 



### Overview of Data Generation  {#data-generation}

#### Data Generation
##### Function Used to Generate Each Data Set

Data for each simulation experiment were generated using R [@rstudio].
To generate the data, the *multilevel logistic function* shown below
in Equation \@ref(eq:logFunction-generation) was used:

```{=tex}
\begin{align}
  y_{ij} = \uptheta_j + \frac{\upalpha_j - \uptheta_j}{{1 + e^\frac{\upbeta_j - time_i}{\upgamma_j}}} + \upepsilon_{ij}, 
(\#eq:logFunction-generation)
\end{align}
```

\noindent where $\uptheta$ represents the baseline parameter, $\upalpha$
represents the maximal elevation parameter, $\upbeta$ represents the
days-to-halfway elevation parameter, and $\upgamma$ represents
triquarter-halfway delta parameter. Note that, values for $\uptheta$,
$\upalpha$, $\upbeta$, and $\upgamma$ were generated for each *j* person
across all *i* time points, with an error value being randomly generated
at each *i* time point($\upepsilon_{ij}$). In other words, unique
response patterns were generated for each person in each of the 1000
data sets generated per cell.

Figure \ref{fig:combined_plot}A shows that the baseline parameter
($\uptheta$) sets the starting value of the curve, which in the current
example has a value of 3.00 ($\uptheta$ = 3.00). Figure
\ref{fig:combined_plot}B shows that the maximal elevation parameter
($\upalpha$) sets the ending value of the curve, which in the current
example has a value of 3.32 ($\upalpha$ = 3.32). Note that a difference
of 0.32 was selected to represent the average effect size in
organizational research [@bosco2015\; for more information, see section on [population values][Population Values Used for Logistic Function Parameters]]. Figure \ref{fig:combined_plot}C shows that the days-to-halfway elevation
parameter ($\upbeta$) sets the number of days needed to reach 50% of the
difference between the baseline and maximal elevation. In the current
example, the baseline-maximal elevation difference is 0.32
($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32), and so the days-to-halfway
elevation parameter defines the number of days needed to reach a value
of 3.16. Given that the days-to-halfway elevation parameter is set to
180 in the current example ($\upbeta = 180$), then 180 days are needed
to go from a value of 3.00 to a value of 3.16. Figure
\ref{fig:combined_plot}D shows that the halfway-triquarter delta
parameter ($\upgamma$) sets the number of days needed to go from halfway
elevation to approximately 73% of the baseline-maximal elevation
difference of 0.32. Given that 73% of the baseline-maximal elevation
difference is 0.23 and the halfway-triquarter delta is set to 40 days
($\upgamma = 40$), then 40 days are needed to go from the halfway point
of 3.16 to the triquarter point of approximately 3.23.

```{r logistic-interpretation-plot1, eval=F, include=F}
#setup variables for logistic curve 
time <- seq(from = 1, to = 360, by = 1)
theta <- 3
alpha <- 3.32
beta <- 180
gamma <- 40

logistic_data <- data.frame('day' = time, 
                            'curve_score' = theta + (alpha - theta)/(1 + exp((beta - time)/gamma))) 

#make first and last values exactly equal to theta and alpha 
logistic_data$curve_score[c(1, 360)] <- c(theta, alpha)

baseline <- logistic_data$curve_score[logistic_data$day == 1]
halfway_value <- logistic_data$curve_score[logistic_data$day == beta]
triquarter_value <- logistic_data$curve_score[logistic_data$day == beta + gamma]
maximal_elevation <- logistic_data$curve_score[logistic_data$day == 360]

#df for points 
point_df <- data.frame('day' = c(1, beta, beta+gamma, 360), 
                       'curve_score' = c(baseline, halfway_value, triquarter_value, maximal_elevation), 
                       'beta_brace' = factor(c('beta', 'beta', 'NA', 'NA')),
                       'beta_label' = rep('d[beta]', times = 4), 
                       
                       'gamma_brace' = factor(c('NA', 'gamma', 'gamma', 'NA')), 
                       'gamma_label' = rep('d[gamma]', times = 4),
                       
                       'total_brace' = factor(c('total', 'NA', 'NA', 'total')), 
                       'total_label' = rep('d[total]', times = 4))

font_size <- 8
title_font <- 30
axis_text_size <- 20
axis_title_size <- 24

theta_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(A:~Baseline~(theta)))) + 
  #theta 
  geom_segment(x = 10, xend = 360, y = baseline, yend = baseline, linetype = 5, size = 1) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = baseline, yend = baseline, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text', x = 440, y = 3.05, label = 'Baseline \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 440, y = 3.00, label = 'theta == 3.00', parse = T, size = font_size) + 

   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))


alpha_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(B:~Maximal~elevation~(alpha)))) + 
  #theta 
  geom_segment(x = -3, xend = 360, y = maximal_elevation, yend = maximal_elevation, linetype = 5, size = 1) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = maximal_elevation, yend = maximal_elevation, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text',  x = 440, y = 3.27, label = 'Maximal \nelevation \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 440, y = 3.20, label = 'alpha == 3.32', parse = T, size = font_size) + 

   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))


beta_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label =  expression(bold(C:~Days~to~halfway~elevation~(beta)))) + 
  #theta 
    geom_segment(x = 130, xend = 175, y = 3.16, yend = 3.16, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 180, xend = 180, y = 3.16, yend = 2.98, linetype = 2, size = 1) + #vertical dashed line 
  annotate(geom = 'text', x = 55, y = 3.14, label = 'Days to halfway \nelevation', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 55, y = 3.08, label = 'beta == 180~days', parse = T, size = font_size) + 
  
   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))

gamma_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(D:~`Halfway-triquarter`~'delta'~(gamma)))) +
  
  #gamma 
  geom_segment(x = 175, xend = 215, y = 3.233, yend = 3.233, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 220, xend = 220, y = 3.233, yend = 2.98, linetype = 2, size = 1) + #vertical dashed line 
  annotate(geom = 'text', x = 100, y = 3.21, label = 'Halfway-triquarter delta', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 105, y = 3.15, label = 'gamma == 40~days', parse = T, size = font_size) + 
  
  #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))

combined_plot <- ggarrange(theta_plot, alpha_plot, beta_plot, gamma_plot)
ggsave(plot = combined_plot, filename = 'Figures/combined_plot.pdf', width = 18, height = 12)


complete_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 1) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360))+
  annotate(geom = 'text', x = 50, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = 5) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 3) +

  #beta
  annotate(geom = 'text', x = 85, y = 3.15, label = 'Days to halfway \nelevation', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 90, y = 3.12, label = 'beta == 180~days', parse = T, size = font_size) +
  geom_segment(x = 130, xend = 175, y = 3.16, yend = 3.16, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 180, xend = 180, y = 3.16, yend = 2.98, linetype = 2, size = 0.3) + #vertical dashed line 
  
  #gamma
  annotate(geom = 'text', x = 97, y = 3.233, label = 'Halfway-triquarter delta', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 105, y = 3.21, label = 'gamma == 40~days', parse = T, size = font_size) + 
  geom_segment(x = 175, xend = 215, y = 3.233, yend = 3.233, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 220, xend = 220, y = 3.233, yend = 2.98, linetype = 2, size = 0.3)+  #vertical dashed line  
  
  coord_cartesian(clip = 'off') + 
  #theta 
  geom_segment(x = 10, xend = 360, y = baseline, yend = baseline, linetype = 3, size = 0.3) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = baseline, yend = baseline, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text', x = 425, y = 3.03, label = 'Baseline \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 425, y = 3.00, label = 'theta == 3.00', parse = T, size = font_size) + 

  #alpha 
  geom_segment(x = -3, xend = 360, y = maximal_elevation, yend = maximal_elevation, linetype = 3, size = 0.3) + #vertical dashed line  
  geom_segment(x = 400, xend = 365, y = maximal_elevation, yend = maximal_elevation, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) +      #horizontal arrow
  annotate(geom = 'text', x = 430, y = 3.30, label = 'Maximal \nelevation \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 430, y = 3.26, label = 'alpha == 3.32', parse = T, size = font_size) + 
  
   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold',size = title_font), 
        axis.title = element_text(size = 16), 
        axis.text = element_text(size = 13, colour = 'black'))
  
    ##brace information
  #stat_brace(data = point_df %>% filter(beta_brace == 'beta'), 
  #           mapping = aes(group = beta_brace, label = beta_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) + 
  #
  #stat_brace(data = point_df %>% filter(gamma_brace == 'gamma'), 
  #           mapping = aes(group = gamma_brace, label = gamma_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) +
  #
  #stat_brace(data = point_df %>% filter(total_brace == 'total'), 
  #           mapping = aes(group = total_brace, label = total_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) + 
  #
  #description box 
  #annotate(geom = 'rect', xmin = 235, xmax = 355, ymin = 3.02, ymax = 3.15, alpha = 0.1, color = 'black') + 
  #annotate(geom = 'text', x = 295, y = 3.13, label = 'd[total] == alpha~-~theta == 0.32', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.09, label = 'd[beta] == 0.5~(d[total]) == 0.16', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.06, label = 'd[gamma] == 0.23~(d[total]) == 0.07', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.03, label = 'd[beta]~+~d[gamma] == 0.73~(d[total]) == 0.23', parse = T, size = 4.5) + 

ggsave(plot = complete_plot, filename = 'Figures/complete_logistic_exp_plot.pdf', width = 9, height = 6)
```

```{=tex}
\begin{figure}[H]
  \caption{Description of Each Parameter of Four-Parameter Logistic Function}
  \label{fig:combined_plot}
  \includegraphics[height = 11cm, width = 100cm]{Figures/combined_plot}
  \figurefootnote{Panel A: Baseline parameter ($\uptheta$) sets the starting value of the of curve, which 
in the current example has a value of 3.00 ($\uptheta$ = 3.00). Panel B: The maximal elevation parameter ($\upalpha$) sets the ending value of the curve, which in the current example has a value of 3.32 ($\upalpha$ = 3.32). Panel C: The days-to-halfway elevation parameter ($\upbeta$) sets the number of days needed to reach 50\% of the difference between the baseline and maximal elevation. In the current example, the baseline-maximal elevation difference is 0.32 ($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32), and so the days-to-halfway elevation parameter defines the number of days needed to reach a value of 3.16. Given that $\upbeta$ is set to 180 in the current example ($\upbeta = 180$), then 180 days are needed to go from a value of 3.00 to a value of 3.16. Panel D: The halfway-triquarter delta parameter ($\upgamma$) sets the number of days needed to go from the halfway elevation point to approximately 73\% of the baseline-maximal elevation difference of 0.32 ($\upalpha - \uptheta$ = 3.32 - 3.00 = 0.32). Given that 73\% of the baseline-maximal elevation difference is 0.23 and the $\upgamma$ is set to 40 days ($\upgamma = 40$), then 40 days are needed to go from the halfway point of 3.16 to the triquarter point of approximately 3.23).}
\end{figure}
```

The logistic growth function (Equation \ref{eq:logFunction-generation}
was used because it is a common pattern of organizational change [or
institutionalization\; @lawrence2001]. Institutionalization curves follow
an s-shaped pattern of the logistic growth function, and so their rates
of change can be represented by the days-to-halfway elevation and
triquarter-halfway delta parameters ($\upbeta$, $\upgamma$,
respectively), and the success of the change can be defined by the
magnitude of the difference between baseline and maximal elevation
parameters ($\upalpha$ - $\uptheta$, respectively).

##### Population Values Used for Function Parameters

(ref:bosco2015) [@bosco2015]

Table \@ref(tab:parameterValues) lists the parameter values that will be
used for the population parameters. Given that the decisions for setting the values for the baseline, maximal elevation, and residual variance parameters were informed by past research, the discussion that follows highlights how these decisions were made. The difference between the baseline and maximal elevation
parameters ($\uptheta$ and $\upalpha$, respectively) corresponded to the effect size most commonly observed in organizational research [i.e., the 50^th^ percentile effect size value\; @bosco2015]. Because the meta-analysis of @bosco2015 computed effect sizes as correlations, the the 50^th^ percentile effect size value of $r = .16$ was computed to a standardized effect size using the following conversion function shown in Equation \ref{eq:conversion-effect} [@borenstein2009, Chapter 7]:

\begin{align}
d = \frac{2r}{\sqrt{1 - r^2}}, 
(\#eq:conversion-effect)
\end{align}

\noindent where $r$ is the correlation effect size. Using Equation \ref{eq:conversion-effect}, a correlation value of $r = .16$ becomes a standardized effect size value of $d = 0.32$. For the value of the residual variance parameter, its value in @coulombe2016 was set to the value used for the value of the intercept variance parameter. In the current context, the intercept of the logistic function (Equation \ref{eq:logFunction-generation}) is the baseline parameter.\footnote{The definition of an intercept parameter is the value of a curve when no time has elapsed, and this is precisely the definition of the baseline parameter ($\uptheta$). Therefore, the variance of the intercept parameter carries the same meaning as the variance of the baseline parameter ($\uptheta_{random}$).} Given that the value for the variability of the baseline parameter was 0.05 (albeit in standard deviation units), the value used for the residual variance parameter was 0.05 ($\upepsilon = 0.05$). Because justification for the other parameters could not be found in any of the simulation studies identified in my systematic review, values set for the other parameters was largely arbitrary. 

To facilitate interpretation of the results, data were generated to resemble the commonly used Likert (range of 1--5) by using a standard deviation of 1.00 and change was assumed to occur over a
period of 360 days. The decision to generate data in the context of a
360-day period was made because many organizational processes are often
governed by annual events (e.g., performance reviews, annual returns,
regulations, etc.). Importantly, because @coulombe2016 set covariances
between parameters to zero, all the simulation experiments used
zero-value covariances.

```{r parameterValues, echo=F}
#specify parameters for parameter table 
theta <- 3
alpha <- 3 + .32*1
beta <- 180
gamma <- 20

sd_alpha <- 0.05
sd_theta <- 0.05
sd_beta <- 10
sd_gamma <- 4

sd_error <- 0.05


#table of parameter values
parameterValues_df <- data.frame('Parameter Means' = c(
                                         'Baseline, $\\uptheta$',
                                         'Maximal elevation, $\\upalpha$', 
                                         'Days-to-halfway elevation, $\\upbeta$', 
                                         'Triquarter-halfway delta, $\\upgamma$', 
                                         
                         'Variability and Covariability Parameters (in Standard Deviations)', 
                              'Baseline standard deviation, $\\uppsi_{\\uptheta}$',
                              'Maximal elevation standard deviation, $\\uppsi_{\\upalpha}$', 
                              'Days-to-halfway elevation standard deviation, $\\uppsi_{\\upbeta}$',
                              'Triquarter-halfway delta standard deviation, $\\uppsi_{\\upgamma}$',
                         
                              'Baseline-maximal elevation covariability, $\\uppsi_{\\uptheta\\upalpha}$',
                              'Baseline-days-to-halfway elevation covariability, $\\uppsi_{\\uptheta\\upbeta}$',
                              'Baseline-triquarter-halfway delta covariability, $\\uppsi_{\\uptheta\\upgamma}$',
                         
                              'Maximal elevation-days-to-halfway elevation covariability, $\\uppsi_{\\upalpha\\upbeta}$',
                              'Maximal elevation-triquarter-halfway delta covariability, $\\uppsi_{\\upalpha\\upgamma}$',
                         
                              'Days-to-halfway elevation-triquarter-halfway delta covariability, $\\uppsi_{\\upbeta\\upgamma}$',
                          
                              'Residual standard deviation, $\\uppsi_{\\upepsilon}$'), 
                         'Value' = c( theta, alpha, beta, gamma, 
                                     '', sd_theta, sd_alpha, sd_beta, sd_gamma, 
                                     0, 0, 0, 0, 0,0,  sd_error), check.names = F)

#round numbers to that they print with two significant numbers
parameterValues_df$Value <- round(as.numeric(as.character(parameterValues_df$Value)), 3)
parameterValues_df$Value <- formatC(round(parameterValues_df$Value, 3), format='f', digits=2)

#replace '  NA' with empty string 
parameterValues_df$Value[parameterValues_df$Value ==" NA"] <- ''

kbl(parameterValues_df, booktabs = TRUE, format = 'latex', longtable = T, 
    linesep = c(rep('', times = 3), '\\addlinespace\\addlinespace\\cmidrule{1-2}', '\\cmidrule{1-2}',
                rep('', times = 10)), 
    align = c('l', 'c'), 
    caption = "Values Used for Multilevel Logistic Function Parameters", 
    escape = F) %>%
   add_indent(positions = c(1:4, 6:16), level_of_indent = 2) %>%
   kable_styling(latex_options= c('hold_position', 'repeat_header'), position = 'left') %>%
  footnote(general =  "The difference between $\\\\alpha$ and $\\\\theta$ corresponds to the 50$\\\\mathrm{^{th}}$ percentile Cohen's $d$ value of 0.32 in organizational psychology (Bosco et al., 2015).",  threeparttable = T,  escape = F, general_title = '\\\\textit{Note.}\\\\hspace{-1pc}') %>%
   column_spec(column = 1, width = '12 cm')
```


### Modelling of Each Generated Data Set {#data-modelling}

Previously, I described how data were generated. Here, I describe how the generated data were modelled.

Each data set generated by the multilevel logistic function (Equation \ref{eq:logFunction-generation}) was analyzed using a modified latent growth curve model known as a structure latent growth curve model [@preacher2015]. Importantly, the model fit to each generated data set estimated nine parameters: A fixed-effect parameter for each of the four logistic function parameters, a random-effect parameter for each of the four logistic function parameters, and an error parameter. As with a multilevel model, values predicted for fixed-effect parameters are constant across all individuals, whereas values predicted
for random-effect parameters represent the variability of parameter values across the data from all modelled people.\footnote{Estimating a random-effect for a parameter allows person-specific values to be computed for the parameter.} To fit the logistic function to a given data set (Equation \ref{eq:logFunction-generation}), a linear approximation of the logistic function was needed so that it could fit within the structural equation modelling framework---a linear framework.\footnote{The logistic function (Equation \ref{eq:logFunction-generation}) cannot be directly inserted into the structural equation modelling framework because it is a linear framework: It on allows matrix-matrix, matrix-vector, and vector-vector operations. Unfortunately, the algebraic operations permitted in a linear framework cannot directly reproduce logistic function operations and so a linear approximation of the logistic function must be constructed so that the logistic function can be inserted into the structural equation modelling framework.} To construct a linear approximation of the logistic function, a first-order Taylor series was constructed for the logistic function. For a detailed explanation of how the logistic function was fit into the structural equation modelling framework, see [Technical Appendix B](#structured-latent). 

### Analysis of Data Modelling Output and Accompanying Visualizations

To analyse the performance each model, I calculated values for convergence success rate, bias, and precision (see [dependent variables](#dependent-variables)) in each experimental cell. The sections that follow provide details on I analysed each dependent variable and constructed plots to visualize bias and precision. 

#### Analysis of Convergence Success Rate {#convergence-analysis}

For the analysis of convergence success rate, the mean convergence
success rate was computed for each cell in each experiment (see section on
[convergence success rate](#convergence)). Because convergence rates exhibited little
variability across cells due to the nearly unanimous high rates (almost all cells across all experiments had convrergence success rates above 90%), examining the effects of any independent variable on these rates would have provided little information, and so only the average convergence success rate for each cell was reported (see [Appendix B](#appendix-a-convergence-rates)). 


#### Analysis and Visualization of Bias{#bias-analysis}
 
In accordance with several simulation studies, an estimate with a bias value within a $\pm10\%$ margin of error of the parameter's population value was deemed acceptable [@muthen1997]. To visualize bias, I constructed parameter estimation plots. Figure \ref{fig:param-estimation-ex} shows a parameter estimation plot for the fixed-effect halfway-triquarter parameter ($\upgamma_{fixed}$) for each measurement number and nature of change. The dots (squares, circles, triangles, diamonds) indicate the average estimated value (see [bias](#bias-comp)) The horizontal blue line indicates the population value ($\upgamma_{fixed}$ = 4.00) and the gray band indicates the acceptable margin of error of $\pm10\%$ of the parameter's population value. Dots that lie within the gray margin of error are filled and dots that lie outside of the margin remain unfilled. In the current example, the average value estimated for the fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$) is only biased (i.e., lies outside the margin of error) with five measurement and a nature of change with an early halfway-elevation point (i.e., $\upbeta_{fixed}$ = 80). Therefore, bias is acceptable in almost all cells.

```{=tex}
\begin{figure}
  \caption{Parameter Estimation Plot for the Fixed-Effect Days-to-Halfway Elevation Parameter ($\upgamma_{fixed}$)}
  \label{fig:param-estimation-ex}
  \includegraphics[height = 27cm, width = 11cm]{Figures/param_estimation_ex} \newline
  \figurefootnote{Dots (squares, circles, triangles, diamonds) indicate the average estimated value and error bars show the range of values covered by the middle 95\% of the estimated values (see \nameref{pres-precision}).  The horizontal blue line indicates the population value ($\upgamma_{fixed}$ = 4.00) and the gray band indicates the acceptable margin of error (i.e., $\pm$10\% of the population value) for bias. Dots that lie outside of the margin of error are unfilled and are considered biased estimates. Dots that lie inside the margin of error are filled and considered unbiased estimates. Error bars whose upper and/or lower whisker lengths exceed 10\% of the parameter's population value are light blue and indicate parameter estimation that is not precise. Error bars whose upper and/or lower whisker lengths do not excced 10\% of the parameter's population value are black and indicate parameter estimation that is precise.}
\end{figure}
```


#### Analysis and Visualization of Precision{#precision-analysis}

As discussed previously, precision was defined as the range of values covered by the middle 95% of estimated values for a given parameter (see [precision][Precision]). The cutoff value used to estimate precision directly followed from the cutoff value used for bias. Given that bias values within a $\pm10\%$ of a parameter's population value were deemed acceptable, an acceptable value for precision should not allow any bias values above the $\pm10\%$ cutoff. That is, the range covered by the middle 95% of estimated values should not allow a bias value outside the the $\pm10\%$ cutoff. Therefore, I deemed precision acceptable if all the values within the middle 95% interval lied with a margin of error of $\pm10\%$ of the population value from the actual population value. 

Like bias, I also depicted precision in parameter estimation plots using error bar. Each error bar in the parameter estimation plot of Figure \ref{fig:param-estimation-ex} indicates the range of values covered by the middle 95% of estimated values in the given cell for the fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$). Importantly, if estimation is not precise, then the lower and/or upper whisker lengths of the error bar exceed 10% of the parameter's population value). When estimation is not precise, the error bar is light blue. When estimation is precise (i.e., neither of the lower or upper whisker lengths exceed 10% of the parameter's population value), the corresponding error bar is black. In the current example, all error bars are light blue and so precision is low in all cells. 

```{r variability-histograms, eval=F, include=F}
exp_2 <- read_csv(file = 'data/exp_2_data.csv')

#function does not work anymore 
generate_param_density_plot(raw_exp_data = exp_2, param_summary_data = param_summary_exp_2, spacing = 'Equal', num_measurements = 5, sample_size = 30)


```

##### Effect Size Computation for Precision

One last statistic I calculated was an effect size value to estimate the variance in parameter estimates for each independent variable. Among the several effect size metrics---at a broad level, effect size
metrics can represent standardized differences or variance-accounted-for
measures that are corrected or uncorrected for sampling error---the corrected
variance-accounted-for effect size metric of partial $\upomega^2$ was
chosen because of three desirable properties. First, partial
$\upomega^2$ provides a less biased estimate of effect size than other
variance-accounted-for measures [@okada2013]. Second, partial $\upomega^2$ is more
robust to assumption violations of normality and homogeneity of variance
[@yigit2018]. Given that parameter estimates were often non-normally distributed across cells, effect size values computed with using partial $\upomega^2$ should be relatively less biased than
other variance-accounted-for effect size metrics (e.g., $\eta^2$). Third, being partial effect size, partial $\upomega^2$ provides an effect size estimate that is not diluted by the inclusion of unaccountable variance in the denominator. To compute partial $\upomega^2$ value for each experimental effect, Equation \ref{eq:partial-omega} shown below was used:

```{=tex}
\begin{align}
\text{partial} \upomega^2 = \frac{\sigma^2_{effect}}{\sigma^2_{effect} + MSE} 
(\#eq:partial-omega)
\end{align}
```

\noindent where $\sigma^2_{effect}$ represents the variance attributable
to an effect and $MSE$ is the mean squared error. Importantly, $\sigma^2_{effect}$ values were corrected values obtained by using the following formula in Equation \ref{eq:var-effect} for a two-way factorial design with fixed variables [@howell2009]: 

```{=tex}
\begin{align}
 \sigma^2_{effect} = \frac{(a - 1)(MS_{effect} - MS_{error})}{nab},
(\#eq:var-effect)
\end{align}
``` 

\noindent where $a$ is the number of levels in the effect, $b$ is the number of levels in the second effect, and $n$ is the cell size. The variance accounted by the interaction was computed using the following formula in Equation \ref{eq:var-interac}:

```{=tex}
\begin{align}
 \sigma^2_{A x B} = \frac{(a - 1)(b-1)(MS_{AxB} - MS_{error})}{nab}. 
(\#eq:var-interac)
\end{align}
``` 

To compute partial $\upomega^2$ values for effects, a Brown-Forsythe test was computed and the appropriate
sum-of-squares terms were used to compute partial $\upomega^2$ values. A Brown-Forsythe test was used because to protect against the biasing effects of skewed distributions that were observed in the parameter estimate distributions in the current simulation experiments [@brown1974].  To compute the Brown-Forsythe test, median absolute values were computed from the median value of each estimated value in each cell as shown in
Equation \ref{eq:brown-forsythe} shown below:

\begin{align}
\text{Median absolute deviation} = \lvert \text{Parameter estimate} - \text{Median parameter estimate}_{cell} \rvert.
(\#eq:brown-forsythe)
\end{align}

\noindent An ANOVA was then computed on the median absolute deviation
values (using the independent variables of the experiment as predictors), with the terms in Equation \ref{eq:partial-omega} extracted from
the ANOVA output to compute partial $\upomega^2$ values.



## Results and Discussion

In the sections that follow, I organize the results by presenting them for each spacing schedule (equal, time-interval increasing, time-interval decreasing, middle-and-extreme). The results are presented for each spacing schedule because answering my research questions first requires knowledge of these results. To answer my first question of whether modelling accuracy increases from spacing measurements during periods of change, I need to investigate this question for each spacing schedule. To answer my second question of how to space measurements when the nature of change is unknown, the modelling accuracy across all manipulated nature-of-change values must be calculated for each spacing schedule. 

For each spacing schedule, I will first present a concise...

### Framework for Interpreting Results

Because Experiment 1 (and all other experiments) had many cells (i.e., 48 cells in Experiment 1), the number of dependent variables to track in the results section can become overwhelming. Therefore, I will provide a framework to help the reader efficiently navigate the results section. Figure \ref{fig:results-plot-primer} shopws the entire set of results that will be presented for each spacing schedule. For each spacing schedule, a parameter estimation plot is created for each of the nine parameters estimated by the structured latent growth curve model used on each generated data set (for a review, see [modelling of each generated data set](#modelling-data-sets)). Parameter estimation plots with black outlines show the results for day-unit parameter and plots with gray outlines show the results for likert-unit parameters. Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and halfway-triquarter delta parameters [$\upbeta_{fixed}$, $\upbeta_{random}$, $\upgamma_{fixed}$, $\upgamma_{random}$, respectively]). The results for the likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters [$\uptheta_{fixed}$, $\uptheta_{random}$, $\upalpha_{fixed}$, $\upalpha_{random}$, respectively]) were largely trivial and so are presented in [Appendix C](#appendix-c)). 

```{=tex}
\begin{figure}[H]
  \caption{Modelling Procedure and Analysis for Individual Spacing Schedule }
  \label{fig:results-plot-primer}
  \includegraphics[height = 17cm, width = 25cm]{Figures/logistic_results_plot} \newline
  \figurefootnote{Each parameter of the logistic function (for a review, see Figure \ref{fig:combined_plot}) is modelled as a fixed and random effect. Values predicted for fixed-effect parameters are constant across all individuals, whereas values predicted for random-effect parameters are unique across individuals. In addition the random- and fixed-effects estimated for each logistic function parameter, an error term ($\upepsilon$) is also estimated. For each experimental cell, parameter estimation plots will be created for each logistic function parameter that show the accuracy with which each parameter is modelled.}
\end{figure}
```


### Pre-Processing of Data and Model Convergence

After collecting the output from the simulations, non-converged models
(and their corresponding parameter estimates) were removed from
subsequent analyses. Table \ref{tab:conv-exp-1} in [Appendix B](#appendix-a-convergence-rates) provides the convergence
success rates for each cell in Experiment 1. Model convergence was almost always above 90% and convergence rates
rates below 90% only occurred in two cells with five measurements. 


### Equal Spacing {#concise-tab}

For equal spacing, Table \ref{tab:summary-table-equal-spacing-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_equal} for the corresponding parameter estimation plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-equal-spacing-exp1} and provide elaboration when necessary. 

Before presenting the results for equal spacing, I provide a brief description of the concise summary table created for each spacing schedule and shown for equal spacing in Table \ref{tab:summary-table-equal-spacing-exp1}. Text within the 'Highest Modelling Accuracy' indicates the nature-of-change value that leads to the highest modelling accuracy for each day-unit parameter. Text within the 'Low Bias' and 'High Precision' columns indicates the number of measurements needed to, respectively, obtain low bias and high precision across all manipulated nature-of-change values. Bolded text in the 'Low Bias' and 'Qualitative Description' columns indicates the measurement number that, respectively, results in low bias and the greatest improvements in bias and precision across all day-unit parameters and manipulated nature-of-change values. The 'Error Bar Length' column indicates the error bar length that results from using the measurement number listed in the 'Qualitative Description' column. Note that error bar lengths were calculated by computing the average error bar length value across all nature-of-change values.

```{r summary-table-equal-spacing-exp1, echo=F}
errorbar_lengths <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Equal spacing', num_measurements = 7)

summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}D)}'), 
                            
                            'Highest Modelling Accuracy' = rep(x = '$\\upbeta_{fixed}$ = 180', times = 4), 

                            
                            'Low Bias' = c('All cells', 
                                           'All cells', 
                                           'All cells', 
                                           '\\textbf{NM $\\boldsymbol{\\ge}$ 9}'), 
                            
                            'High Precision' = c('All cells', 
                                            'No cells', 
                                            'No cells',
                                            'No cells'), 
                            

                            'Qualitative Description' = c('Largest improvements in precision with \\textbf{NM = 7}', 
                                                      'Largest improvements in precision with \\textbf{NM = 7}', 
                                                      'Largest improvements in precision with \\textbf{NM = 7}', 
                                                      'Largest improvements in bias and precision with \\textbf{NM = 7}'),
                            'Error Bar Length' = errorbar_lengths$errorbar_length, 
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
       align = c('l', 'c', 'c', 'c', 'l', 'c'), 
    linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Equal Spacing in Experiment 1') %>%
    #header
  column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.2pc}',
           general = "`Highest Modelling Accuracy' indicates the curve that results in the highest modelling accuracy. Bolded text in the `Low Bias' and `Qualitative Description' columns indicates the number of measurements needed to, respectively, achieve low bias and the greatest improvements in bias and precision across all day-unit parameters (high precision not achieved in the estimation of all day-unit parameters with equal spacing). `Error Bar Length' indicates the longest error bar length that results from using the measurement number in the `Qualitative Description` column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all nature-of-change values. NM = number of measurements.\\\\phantom{fillerfillerfiller}") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.35cm')

```

#### Nature of Change That Leads to Highest Modelling Accuracy {#nature-change-equal-exp1}

For equal spacing, Table \ref{tab:errorbar-equal-nc} lists precision values (i.e., error bar lengths) for each day-unit parameter across each nature-of-change value. Although modelling accuracy is determined by bias and precision, results for bias are not shown because the differences in bias across the nature-of-change values are negligible. Note that error bar lengths are obtained by computing the average length across all manipulated number of measurements. The columns shaded in gray indicate the nature of change where precision is highest (i.e., shortest error bar lengths) for equal spacing. Note For equal spacing, precision is lowest with a nature-of-change value of 180 for all day-unit parameters with one exception (i.e., midway change; see the 'Highest Modelling Accuracy' in Table \ref{tab:summary-table-equal-spacing-exp1}). 

One important result to discuss concerns the error bar length of the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$) across the nature-of-change values. Precision is highest (i.e, shortest error bars) when the halfway-elevation point occurred midway through the measurement period (i.e., 180 days) for each day-unit parameter except the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). For the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$), precision is lowest (i.e., longest error bars) when the halfway-elevation point occurred midway through the measurement period (i.e., 180 days). An inspection of the error bar lengths for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$) in Figure \ref{fig:exp1_plot_equal}D reveals that the lower precision (i.e., longer error bars) observed for $\upgamma_{random}$ with a nature of change of 180 largely results from a longer error bar with five measurements. 

To understand why precision for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$) is lower with a nature-of-change value of 180, I looked at the distribution of estimated values. Figure \ref{fig:density_gamma_equal} shows the distribution of values (i.e., density plots) estimated for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$) for each nature of change level with five measurements. Panel A shows the density plot with a nature of change 80 (i.e., early halfpoint). Panel A shows the density plot with a nature of change 180 (i.e., midway halfpoint). Panel C shows the density plot with a nature of change 280 (i.e., late halfpoint). Regions shaded in in gray represent the the middle 95% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. As originally confirmed by Table \ref{tab:errorbar-equal-nc}, Figure \ref{fig:density_gamma_equal}B shows that precision is indeed lowest (i.e., longer error bars) with a nature of change of 180. In looking across the density plots in Figure \ref{fig:density_gamma_equal}, precision is lowest (i.e., longest error bars) for the random-effect triquarter-halfway parameter ($\upgamma_{random}$) with a nature-of-change value of 180 because of the existence of high-value outliers. 

In summary, under equal spacing, modelling accuracy for all the day-unit parameters (with one exception) is greatest when the nature-of-change value set by the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) has a value of 180. As one exception, modelling accuracy (as indicated by precision) is lower for the random-effect triquarter-halfway elevation parameter ($\upgamma_random$) with a nature-of-change value of 180 because of high-value estimates. 

```{r errorbar-equal-nc, echo=F}
param_midpoint_equal <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Equal')) %>%
  group_by(parameter, midpoint) %>%
  summarize(
            lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
   total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')

param_midpoint_equal$parameter <- factor(x = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}A)', 
                                        '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}B)', 
                                        '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_equal}C)', 
                                       '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_equal}D)'))

param_midpoint_equal$`180_upper`<- c(as.character(round(param_midpoint_equal$`180_upper`[1:3], digits = 2)),
                                   paste(as.character(round(param_midpoint_equal$`180_upper`[4], digits = 2)), '\\textsuperscript{a}', sep = ''))
  
kbl(x = param_midpoint_equal, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
       align = c('l', rep('c', times = ncol(param_midpoint_equal) - 1)), col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Equal Spacing in Experiment 1') %>%
      #header
    add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
  
    column_spec(column = 5:7, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3.5cm') %>%
   # column_spec(column = c(2:4), width = '3cm') %>%
    footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1pc}',
           general = "`Total` indicates the total error bar length, which is a sum of the lower (`Lower') and upper (`Upper') whisker lengths. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.",
           alphabet_title = '\\\\newline', alphabet = "Whisker is longer than with other nature-of-change values because estimation procedure converges on larger $\\\\upgamma_{random}$ values with a nature-of-change value of $\\\\upbeta_{fixed}$ = 180 (see Figures \\\\ref{fig:density_gamma_equal}--\\\\ref{fig:density_gamma_equal_fixed} and Table \\\\ref{tab:equal-gamma-outlier}).") %>%
  kable_styling(position = 'left')
```

```{=tex}
\begin{figure} [H]
  \caption{Density Plots of the Random-Effect Halfway-Triquarter Delta ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_equal}D) With Equal Spacing in Experiment 1 (95\% Error Bars)}
  \label{fig:density_gamma_equal}
  \includegraphics[height = 15cm, width = 25cm]{Figures/density_plots_equal_gamma_exp1} \newline
  \figurefootnote{Regions shaded in in gray represent the the middle 95\% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. The error bar length if longest when the nature-of-change value is 180. $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter, with population value of 4.00, NM = number of measurements.}
\end{figure}
```


#### Bias {#bias-equal-exp1}

Before presenting the results for bias, I provide a description of the set of parameter estimation plots shown in Figure \ref{fig:exp1_plot_equal} and in the results sections for the other spacing schedules in Experiment 1. Figure \ref{fig:exp1_plot_equal} shows the parameter estimation plots for each day-unit parameter and Table \ref{tab:omega-exp1-equal} provides the partial $\upomega^2$ values for each independent variable of each day-unit parameter. In Figure \ref{fig:exp1_plot_equal}, error bars represent the middle 95% of estimated values, blue horizontal lines indicate the population values for each parameter (with population values of $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, and $\upgamma_{random}$ = 4.00), and gray bands specify the acceptable margins of error (i.e., 10% of the parameter's population value). I considered dots that fell outside the gray bands as biased and error bar lengths that exceeded 20% of the parameter's population value as indicative of low-precision estimation. Panels A--B show the parameter estimation plots for the fixed- and random-effect days-to-halfway elevation parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively). Panels C--D show the parameter estimation plots for the fixed- and random-effect triquarter-halfway delta parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively). Note that random-effect parameter units are in standard deviation units. Importantly, across all population values used for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180.

With respect to bias for equal spacing, it is high (i.e., above the acceptable 10% cutoff) with the following measurement numbers and nature-of-change values for each day-unit parameter:   

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_equal}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_equal}B): no cells.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_equal}C): no cells. 
* random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_equal}D): five measurements with all manipulated nature-of-change values and seven measurements with nature-of-change values of 180 and 280.

\noindent In summary, with equal spacing, low bias can be obtained in the estimation of all day-unit parameters across all manipulated nature-of-change values using nine or more measurements, which is indicated by the bolded text in the 'Low Bias' column of Table \ref{tab:summary-table-equal-spacing-exp1}.

#### Precision {#precision-equal-exp1}

With respect to precision for equal spacing, it is low (i.e., lower and/or upper whisker length above 10% of the parameter's population value) with the following measurement numbers and nature-of-change values for each day-unit parameter:  

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_equal}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_equal}B): all cells. 
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_equal}C): all cells. 
* random-effect halfway-triquarter delta parameter [$\upgamma_{random}$] in Figure \ref{fig:exp1_plot_equal}D): all cell. 

\noindent In summary, with equal spacing, high precision is only achieved in the estimation of the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) across all cells, but no manipulated measurement number achieves high precision in the estimation of any other parameters (see the 'High Precision' column of Table \ref{tab:summary-table-equal-spacing-exp1}). 

```{r plots-equal-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Equal spacing',
                                x_axis_name = expression("Nature of Change (Population Value Set for"~beta[fixed]~')'), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -30, beta_upper = 25, beta_ticks = 5)
```


```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Equal Spacing in Experiment 1}
  \label{fig:exp1_plot_equal}
  \includegraphics{Figures/exp1_plot_days_equal spacing} \hfill{}
\end{figure}
\begin{figure}[H]
\figurefootnote{Panel A: Parameter estimation plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Parameter estimation plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Parameter estimation plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Parameter estimation plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating cells with variability greater than 20\% of the parameter's population value. I considered dots that fell outside the gray bands as biased and error bar lengths that exceeded 20\% of the parameter's population value as indicative of low-precision estimation. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-equal} for $\upomega^2$ effect size values.}
\end{figure}
```

\newpage 
```{r omega-exp1-equal, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'equal', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Equal Spacing in Experiment 1',
footnote = 'NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_equal}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_equal}D)'))
```
 
 
#### Qualitative Description {#qualitative-equal-exp1}

```{r echo=F}
errorbar_lengths <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Equal spacing', num_measurements = 7)$errorbar_length
```

Although no manipulated measurement number obtains high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) are obtained using moderate measurements numbers. With respect to bias under equal spacing, the largest improvements in bias across all manipulated nature-of-change values occur with the following measurement numbers for the following day-unit parameters (note that only the random-effect triquarter halfway delta parameter [$\upgamma_{random}$] had instances of high bias): 

* random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): seven measurements.

\noindent With respect to precision under equal spacing, the largest improvements precision in the estimation of all day-unit parameters (except the fixed-effect days-to-halfway elevation parameter [$\upbeta_{fixed}$]) are obtained with following measurement numbers:

* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[2]` days.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[3]` days.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements,which results in a maximum error bar length of `r errorbar_lengths[4]` days.

\noindent Therefore, for equal spacing, seven measurements results leads to the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the 'Qualitative Description` column in Table \ref{tab:summary-table-equal-spacing-exp1}). 

#### Summary of Results 

In summarizing the results for equal spacing, modelling accuracy is greatest across all day-unit parameters with a nature-of-change value of 180, with the random-effect days-to-halfway elevation parameter ($\upgamma_{random}$) being an exception (see [highest modelling accuracy](#nature-change-equal-exp1)). Low bias is obtained in the estimation of all day-unit parameters across all manipulated nature-of-change values using nine or more measurements (see [bias](#bias-equal-exp1)). High precision is never obtained in the estimation of all day-unit parameters with any manipulated measurement number (see [precision](#precision-equal-exp1)). Although it may be discouraging that no manipulated measurement number under equal spacing obtains high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters are obtained with moderate measurement numbers. With equal spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values are obtained using seven measurements (see [Qualitative Description](#qualitative-equal-exp1)). 

### Time-Interval Increasing Spacing 

For time-interval increasing spacing, Table \ref{tab:summary-table-time-inc-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_inc} for the corresponding parameter estimation plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-inc-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-inc-exp1}, see [concise summary table](#concise-tab)). 

```{r summary-table-time-inc-exp1, echo=F}
errorbar_lengths_nm7 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, 
                                             iv_level = 'Time-interval increasing', num_measurements = 7)
errorbar_lengths_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, 
                                             iv_level = 'Time-interval increasing', num_measurements = 9)

errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], errorbar_lengths_nm9$errorbar_length[2], 
                     errorbar_lengths_nm7$errorbar_length[3], errorbar_lengths_nm9$errorbar_length[4])


summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}D)}'), 
                            
                              'Highest Modelling Accuracy' = rep(x = '$\\upbeta_{fixed}$ = 80', times = 4), 
                            
                            'Low Bias' = c('All cells', 
                                       'All cells', 
                                       'NM $\\ge$ 7', 
                                       '\\textbf{NM $\\ge$ 9}'), 
                            'High Precision' = c('NM $\\ge$ 7', 
                                            'NM $\\ge$ 9', 
                                            'No cells',
                                            'No cells'), 
                            
                        
                            
                            'Qualitative Description' = c('Largest improvement in precision with NM = 7', 
                                                      'Largest improvement in precision with \\textbf{NM = 9}', 
                                                      'Largest improvement in bias and precision with NM = 7', 
                                                     'Largest improvements in bias and precision with \\textbf{NM = 9}'), 
                            'Error Bar Length' = errorbar_lengths,
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
        linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Time-Interval Increasing Spacing in Experiment 1', 
    align = c('l','c', 'c', 'c', 'l', 'c')) %>%
   #header
   column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.2pc}',
           general = "`Highest Modelling Accuracy' indicates the curve that results in the highest modelling accuracy. Bolded text in the `Low Bias' and `Qualitative Description' columns indicates the number of measurements needed to, respectively, achieve low bias and the greatest improvements in bias and precision across all day-unit parameters (high precision not achieved in the estimation of all day-unit parameters with equal spacing). `Error Bar Length' indicates the longest error bar length that results from using the measurement number in the `Qualitative Description` column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all nature-of-change values. NM = number of measurements.\\\\phantom{fillerfillerfiller}") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.35cm')
```

```{r density-plot-functions, include=F, eval=F}
compute_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_95_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_80_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_80_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_90_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_90_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_density <- function(error_bar_range, group, param_name, density_data) { 
  
  density_data <- density_data[density_data$group == group , ]
  
  density_lower_x <- min(which(density_data$x >= error_bar_range[1]))
  density_upper_x <- max(which(density_data$x <= error_bar_range[2]))
  
  day_values <- density_data$x[density_lower_x:density_upper_x]
  
  
  density_df <- data.frame('parameter' = param_name,
                           'day_value' = day_values,
                           'probability' = density_data$y[density_lower_x:density_upper_x], 
                           'max_density_value' = max(density_data$y),
                           'lower_ci' = error_bar_range[1], 
                           'upper_ci' = error_bar_range[2])

    return(density_df)
}
```

```{r exp1-density-plot-time-inc, include=F, eval=F}
##generate figure showing density distributions if gamma_fizxd at N = 500 and N = 1000 with middle 95% area shaded. Emphasize
##that longer error bars in  N = 1000 are likely a statistical artifact of the random number generating procedure. 
exp_1 <- read_csv('data/exp_1_data.csv') %>% filter(code == 0) #load data 
exp_1 <- convert_raw_var_to_sd(raw_data = exp_1) #var to sd conversion 

parameter_names <- c(bquote(expr = bold(A:~gamma[random]~(beta[fixed]~" = 280, 5 measurements"))),
                     bquote(expr =bold(B:~gamma[random]~(beta[fixed]~" = 280, 7 measurements"))))
                     
#1) Extract estimates for four parameter gamma_fixed and beta_rand when N =500 or 1000, num_measurements == 5, spacing == equal. 
##Convert to long format, with parameter name going into unique column and estimate becoming new column 
param_data <- exp_1 %>%
  filter(number_measurements <= 7, measurement_spacing == 'time_inc', midpoint == 280) %>%
  select(locate_ivs(exp_1),'gamma_rand') %>%
  pivot_longer(cols = c(gamma_rand), values_to = 'estimate') %>%
  unite(col = 'parameter', c(number_measurements,name))

#2) Replace parameter values with tag labels. 
param_data$parameter <- factor(param_data$parameter, 
                               levels = c("5_gamma_rand", "7_gamma_rand"), 
                               labels = parameter_names)

base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
density_data <- ggplot_build(plot = base_density_plot)$data[[1]]

param_search_names <- c("A\\:", "B\\:")

param_error_bar_ranges <- lapply(X = param_search_names, compute_ind_param_error_bar_range, param_data = param_data)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


example_plot <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = example_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_time_inc_exp1.pdf')

```

```{r exp1-density-plot-time-inc-fixed, include=F, eval=F}
param_error_bar_ranges <- lapply(X = param_search_names, compute_80_ind_param_error_bar_range, param_data = param_data)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


time_inc_fixed_density <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = time_inc_fixed_density, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_time_inc_exp1_fixed.pdf')

```

#### Nature of Change That Leads to Highest Modelling Accuracy {#nature-change-time-inc-exp1}

For time-interval increasing spacing, Table \ref{tab:errorbar-time-inc-nc} lists the error bar lengths for each day-unit parameter and nature-of-change value. Although modelling accuracy is determined by bias and precision, results for bias are not discussed or computed because the differences in bias across the nature-of-change values are negligible. Note that error bar lengths are computed by computing the average length across all manipulated number-of-measurement values. The column shaded in gray indicates the nature-of-change value that results in the shortest error bar lengths under equal spacing. Across all the manipulated nature-of-change values, error bar lengths are shortest with a nature-of-change value of 80 (see 'Highest Modelling Accuracy' column in Table \ref{tab:summary-table-time-inc-exp1}). For time-interval increasing spacing, precision is lowest (i.e., longest error bars) with a nature-of-change value of 80 for all day-unit parameters  (i.e., early halfway point; see the 'Highest Modelling Accuracy' in Table \ref{tab:summary-table-time-inc-exp1}). 

```{r errorbar-time-inc-nc, echo=F}
param_midpoint_time_inc <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'increasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
            total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')

param_midpoint_time_inc$parameter <- factor(x = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_inc}A)', 
                                        '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_inc}B)', 
                                        '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_inc}C)', 
                                       '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_inc}D)'))


kbl(x = param_midpoint_time_inc, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
        align = c('l', rep('c', times = ncol(param_midpoint_equal) - 1)), 
    col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
    
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Time-Interval Increasing Spacing in Experiment 1') %>%
  
    add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
  
    column_spec(column = 2:4, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3.5cm') %>%
  
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1pc}',
           general = "`Total` indicates the total error bar length, which is a sum of the lower (`Lower') and upper (`Upper') whisker lengths. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.") %>%
  kable_styling(position = 'left')
```

#### Bias {#bias-time-inc-exp1}

With respect to bias for time-interval increasing spacing, it is high (i.e., above the acceptable 10% cutoff) with the following measurement numbers and nature-of-change values for each day-unit parameter:   

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}B): no cells
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_inc}C): no cells. 
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_inc}C): five measurements with a nature-of-change value of 280 seven measurements with nature-of-change values of 180 and 280.

\noindent In summary, with time-interval increasing spacing, low bias can be obtained in the estimation of all day-unit parameters across all manipulated nature-of-change values using nine or more measurements, which is indicated by the bolded text in the 'Low Bias' column of Table \ref{tab:summary-table-time-inc-exp1}.

#### Precision {#precision-time-inc-exp1}

With respect to precision for time-interval increasing spacing, it is low (i.e., error bar length above the 20% acceptable cutoff) with the following measurement numbers and nature-of-change values for each day-unit parameter:  

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}A): five measurements with a nature-of-change value of 280. 
* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}B): five and seven measurements across all manipulated nature-of-change values.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_inc}C): all cells.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_inc}D): all cells.

In summary, with time-interval increasing spacing, high precision is achieved in the estimation of the fixed-effect day-unit parameters across all manipulated nature-of-change values with nine or more measurements, but no manipulated measurement number achieves high precision in the estimation of the random-effect day-unit parameters (see the 'High Precision' column of Table \ref{tab:summary-table-time-inc-exp1}). 


```{r plots-time-increasing-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Time-interval increasing',
                                  x_axis_name = expression("Nature of Change (Population Value Set for"~beta[fixed]~')'), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -60, beta_upper = 60, beta_ticks = 10)
```

```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Time-Interval Increasing Spacing in Experiment 1}
  \label{fig:exp1_plot_time_inc}
  \includegraphics{Figures/exp1_plot_days_time-interval increasing_mod} \hfill{}
\end{figure}
\begin{figure}[H]
\figurefootnote{Panel A: Parameter estimation plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Parameter estimation plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Parameter estimation plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Parameter estimation plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating cells with variability greater than 20\% of the parameter's population value. I considered dots that fell outside the gray bands as biased and error bar lengths that exceeded 20\% of the parameter's population value as indicative of low-precision estimation. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-inc} for $\upomega^2$ effect size values.}
\end{figure}
```

\newpage 
```{r omega-exp1-time-inc, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'time_inc', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 1',
footnote = 'NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_inc}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_inc}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_inc}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_inc}D)'))
```


#### Qualitative Description {#qualitative-time-inc-exp1}

```{r echo=F} 
errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], errorbar_lengths_nm9$errorbar_length[2], 
                     errorbar_lengths_nm7$errorbar_length[3], errorbar_lengths_nm9$errorbar_length[4])
```

For time-interval increasing spacing in Figure \ref{fig:exp1_plot_time_inc}, although no manipulated measurement number obtains high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) are achieved using moderate measurements numbers. With respect to bias under time-interval increasing spacing, the largest improvements across all manipulated nature-of-change values in bias occur with the following measurement numbers for the random-effect day-unit parameters: 

* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements.
* random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): nine measurements.

\noindent With respect to precision under time-interval increasing spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values are achieved with following measurement numbers:

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[1]` days.
* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[2]` days.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[3]` days.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[4]` days. 

\noindent Therefore, for time-interval increasing spacing, nine measurements leads to the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the 'Qualitative Description` column in Table \ref{tab:summary-table-time-inc-exp1}). 

#### Summary of Results 

In summarizing the results for time-interval increasing spacing, modelling accuracy is highest for each day-unit parameter with a nature-of-change value of 80 (i.e., early halfway point; see [highest modelling accuracy](#nature-change-time-inc-exp1)). Low bias is obtained in the estimation of all day-unit parameters across all manipulated nature-of-change values using nine or more measurements (see [bias](#bias-time-inc-exp1)). High precision is never obtained in the estimation of all day-unit parameters with any manipulated measurement (see [precision](#precision-time-inc-exp1)). Although it may be discouraging that no manipulated measurement number under time-interval increasing spacing achieves high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters are achieved with moderate measurement numbers. With time-interval increasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values are achieved using nine measurements (see [qualitative description](#qualitative-time-inc-exp1)).  


### Time-Interval Decreasing Spacing 

For time-interval decreasing spacing, Table \ref{tab:summary-table-time-dec-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_dec} for the corresponding parameter estimation plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-dec-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-dec-exp1}, see [concise summary table](#concise-tab)). 

```{r summary-table-time-dec-exp1, echo=F}
errorbar_lengths_nm7 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval decreasing', num_measurements = 7)
errorbar_lengths_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval decreasing', num_measurements = 9)

errorbar_lengths <- errorbar_lengths_nm9$errorbar_length

summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}D)}'), 
                            
                            'Highest Modelling Accuracy' = rep(x = '$\\upbeta_{fixed}$ = 280', times = 4),

                            'Low Bias' = c('All cells', 
                                       'NM $\\ge$ 7', 
                                       'NM $\\ge$ 7', 
                                       '\\textbf{NM $\\boldsymbol{\\ge}$ 9}'), 
                            
                            'High Precision' = c('NM $\\ge$ 7', 
                                            'NM $\\ge$ 9', 
                                            'No cells',
                                            'No cells'), 
                            

                            'Qualitative Description' = c('Largest improvements in precision with \\textbf{NM = 9}', 
                                                      'Largest improvement in precision with \\textbf{NM = 9}', 
                                                      'Largest improvement in bias and precision with \\textbf{NM = 9}', 
                                                      'Largest improvements in bias and precision with \\textbf{NM = 9}'), 
                            'Error Bar Length' = errorbar_lengths,
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
        linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Time-Interval Decreasing Spacing in Experiment 1', 
 align = c(rep('l', times = ncol(summary_table)))) %>%
     #header
   column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.2pc}',
           general = "`Highest Modelling Accuracy' indicates the curve that results in the highest modelling accuracy. Bolded text in the `Low Bias' and `Qualitative Description' columns indicates the number of measurements needed to, respectively, achieve low bias and the greatest improvements in bias and precision across all day-unit parameters (high precision not achieved in the estimation of all day-unit parameters with equal spacing). `Error Bar Length' indicates the longest error bar length that results from using the measurement number in the `Qualitative Description` column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all nature-of-change values. NM = number of measurements.\\\\phantom{fillerfillerfiller}") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.35cm')
```

#### Nature of Change That Leads to Highest Modelling Accuracy {#nature-change-time-dec-exp1}

For time-interval decreasing spacing, Table \ref{tab:errorbar-time-dec-nc} lists the error bar lengths for each day-unit parameter and nature-of-change value. Although modelling accuracy is determined by bias and precision, results for bias are not discussed or computed because the differences in bias across the nature-of-change values are negligible. Note that error bar lengths are computed by computing the average length across all manipulated number-of-measurement values. The column shaded in gray indicates the nature-of-change value that results in the shortest error bar lengths under equal spacing. For time-interval decreasing spacing, precision is lowest (i.e., longest error bars) with a nature-of-change value of 280 for all day-unit parameters  (i.e., late halfway point; see the 'Highest Modelling Accuracy' in Table \ref{tab:summary-table-time-dec-exp1}). 



```{r errorbar-time-dec-nc, echo=F}
param_midpoint_time_dec <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'decreasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(
            lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
   total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')


param_midpoint_time_dec$parameter <- factor(x = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}A)', 
                                        '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}B)', 
                                        '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}C)', 
                                       '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}D)'))



kbl(x = param_midpoint_time_dec, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
        align = c('l', rep('c', times = ncol(param_midpoint_equal) - 1)), 
    col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
   
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Time-Interval Decreasing Spacing in Experiment 1') %>%
  
    #header
    add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
  
    column_spec(column = 8:10, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3.5cm') %>%
   # column_spec(column = c(2:4), width = '3cm') %>%
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.2pc}',
           general = "Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.")%>%
  kable_styling(position = 'left')
```

#### Bias {#bias-time-dec-exp1}

With respect to bias for time-interval decreasing spacing, it is high (i.e., above the acceptable 10% cutoff) with the following measurement numbers and nature-of-change values for each day-unit parameter:   

* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}B): five measurements with a nature-of-change value of 80.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_dec}C): five measurements with a nature-of-change value of 80. 
* random-effect halfway-triquarter delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_dec}D): five measurements across all manipulated nature-of-change values and seven measurements with nature-of-change values of 80 and 180. 

\noindent In summary, with time-interval decreasing spacing, low bias can be obtained in the estimation of all day-unit parameters across all manipulated nature-of-change values using nine or more measurements, which is indicated by the bolded text in the 'Low Bias' column of Table \ref{tab:summary-table-time-dec-exp1}.

#### Precision {#precision-time-dec-exp1}

With respect to precision for time-interval decreasing spacing, it is low (i.e., error bar length above the 20% acceptable cutoff) with the following measurement numbers and nature-of-change values for each day-unit parameter:  

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}A): five measurements with a nature-of-change value of 80.
* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}B): five and seven measurements across all manipulated nature-of-change values. 
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_dec}C): all cells. 
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_dec}D): all cells. 

In summary, with time-interval increasing spacing, high precision is achieved in the estimation of the fixed-effect day-unit parameters across all manipulated nature-of-change values with nine or more measurements, but no manipulated measurement number achieves high precision in the estimation of the random-effect day-unit parameters (see the 'High Precision' column of Table \ref{tab:summary-table-time-dec-exp1}). 

```{r plots-time-decreasing-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Time-interval decreasing',
                                  x_axis_name = expression("Nature of Change (Population Value Set for"~beta[fixed]~')'),
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -60, beta_upper = 80,  beta_ticks = 10)
```

```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 1}
  \label{fig:exp1_plot_time_dec}
  \includegraphics{Figures/exp1_plot_days_time-interval decreasing_mod} \hfill{}
\end{figure}
\begin{figure}[H]
\figurefootnote{Panel A: Parameter estimation plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Parameter estimation plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Parameter estimation plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Parameter estimation plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating cells with variability greater than 20\% of the parameter's population value. I considered dots that fell outside the gray bands as biased and error bar lengths that exceeded 20\% of the parameter's population value as indicative of low-precision estimation. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-dec} for $\upomega^2$ effect size values.}
\end{figure}
```

\newpage
```{r omega-exp1-time-dec, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'time_dec', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 1',
footnote = 'NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}D)'))
```


#### Qualitative Description {#qualitative-time-dec-exp1}

```{r echo=F}
errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], 
                      errorbar_lengths_nm9$errorbar_length[2], 
                      errorbar_lengths_nm7$errorbar_length[3], 
                      errorbar_lengths_nm9$errorbar_length[4])
```

For time-interval decreasing spacing in Figure \ref{fig:exp1_plot_time_dec}, although no manipulated measurement number achieves high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) are obtained using moderate measurements numbers. With respect to bias under time-interval decreasing spacing, the largest improvements across all manipulated nature-of-change values in bias occur with the following measurement numbers for the random-effect day-unit parameters: 

* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements
* random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): nine measurements

\noindent With respect to precision under time-interval decreasing spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values are obtained with following measurement numbers:

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[1]` days.
* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[2]` days.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[3]` days.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): nine measurements, which results in a maximum bar length of `r errorbar_lengths[4]` days.

\noindent Therefore, for time-interval decreasing spacing, nine measurements leads to the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the 'Qualitative Description` column in Table \ref{tab:summary-table-time-dec-exp1}). 

#### Summary of Results 

In summarizing the results for time-interval decreasing spacing, modelling accuracy is highest for each day-unit parameter with a nature-of-change value of 280 (i.e., late halfway point; see [highest modelling accuracy](#nature-change-time-dec-exp1)). Low bias is obtained in the estimation of all day-unit parameters across all manipulated nature-of-change values using nine or more measurements (see [bias](#bias-time-dec-exp1)). High precision is never obtained in the estimation of all day-unit parameters with any manipulated measurement (see [precision](#precision-time-dec-exp1)). Although it may be discouraging that no manipulated measurement number under time-interval decreasing spacing achieves high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters are obtained with moderate measurement numbers. With time-interval decreasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values are obtained using nine measurements (see [qualitative description](#qualitative-time-inc-exp1)).  


### Middle-and-Extreme Spacing  

For middle-and-extreme spacing, Table \ref{tab:summary-table-mid-ext-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_mid_ext} for the corresponding parameter estimation plots). The sections that follow will present the results for each column of Table  \ref{tab:summary-table-mid-ext-exp1} and provide elaboration when necessary (for a description of Table  \ref{tab:summary-table-mid-ext-exp1}, see [concise summary table](#concise-tab)). 

```{r summary-table-mid-ext-exp1, echo=F}
errorbar_lengths_nm7 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Middle-and-extreme spacing', num_measurements = 7)
errorbar_lengths_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Middle-and-extreme spacing', num_measurements = 9)

errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], 
                      errorbar_lengths_nm7$errorbar_length[2], 
                      errorbar_lengths_nm9$errorbar_length[3], 
                      errorbar_lengths_nm7$errorbar_length[4])

summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}D)}'), 
                            
                            'Highest Modelling Accuracy' = rep(x = '$\\upbeta_{fixed}$ = 180', times = 4),
                            
                            'Low Bias' = c('All cells', 
                                       'NM $\\ge$ 7',
                                       'NM $\\ge$ 9', 
                                       '\\textbf{NM = 11}'), 
                            
                            'High Precision' = c('NM $\\ge$ 7', 
                                            'NM = 11', 
                                            'No cells',
                                            'No cells'), 
                            
                             
                            
                            'Qualitative Description' = c('Largest improvements in precision with NM = 7', 
                                                      'Largest improvements in bias and precision with NM = 7', 
                                                      'Largest improvements in bias and precision with \\textbf{NM = 9}', 
                                                      'Largest improvements in bias and precision with NM = 7'), 
                            
                            'Error Bar Length' = errorbar_lengths, 
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
        linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Middle-and-Extreme Spacing in Experiment 1', 
    align = c(rep('l', times = ncol(summary_table)))) %>%
        #header
   column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.2pc}',
           general = "`Highest Modelling Accuracy' indicates the curve that results in the highest modelling accuracy. Bolded text in the `Low Bias' and `Qualitative Description' columns indicates the number of measurements needed to, respectively, achieve low bias and the greatest improvements in bias and precision across all day-unit parameters (high precision not achieved in the estimation of all day-unit parameters with equal spacing). `Error Bar Length' indicates the longest error bar length that results from using the measurement number in the `Qualitative Description` column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all nature-of-change values. NM = number of measurements.\\\\phantom{fillerfillerfiller}") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.35cm')
```

#### Nature of Change That Leads to Highest Modelling Accuracy {#nature-change-mid-ext-exp1}

For middle-and-extreme spacing, Table \ref{tab:errorbar-mid-ext-nc} lists the error bar lengths for each day-unit parameter and nature-of-change value. Although modelling accuracy is determined by bias and precision, results for bias are not discussed or computed because the differences in bias across the nature-of-change values are negligible. Note that error bar lengths are computed by computing the average length across all manipulated number-of-measurement values. The column shaded in gray indicates the nature-of-change value that results in the shortest error bar lengths under equal spacing. For middle-and-extreme spacing, precision is lowest (i.e., longest error bars) with a nature-of-change value of 180 for all day-unit parameters  (i.e., midway halfway point; see the 'Highest Modelling Accuracy' in Table \ref{tab:summary-table-mid-ext-exp1}). 


```{r errorbar-mid-ext-nc, echo=F}
param_midpoint_mid_ext <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Middle-and')) %>%
  group_by(parameter, midpoint) %>%
  summarize(
            lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
   total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')

param_midpoint_mid_ext$parameter <- factor(x = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}A)', 
                                        '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}B)', 
                                        '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}C)', 
                                       '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}D)'))


kbl(x = param_midpoint_mid_ext, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
        align = c('l', rep('c', times = ncol(param_midpoint_equal) - 1)), 
    col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
   
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Middle-and-Extreme Spacing in Experiment 1') %>%
  
    #header
     add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
    column_spec(column = 5:7, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3.5cm') %>%
  
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.2pc}',
           general = "Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.") %>%
  kable_styling(position = 'left')
```

#### Bias {#bias-mid-ext-exp1}

With respect to bias for middle-and-extreme spacing, it is high (i.e., above the acceptable 10% cutoff) with the following measurement numbers and nature-of-change values for each day-unit parameter:   

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_mid_ext}B): five measurements with  nature-of-change values of 80 and 280.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}C): five and seven measurements with nature-of-change values of 80 and 280.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}D): five and seven measurements with nature-of-change values of 80 and 280.

Therefore, using middle-and-extreme spacing, low bias can be achieved in the estimation of the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$) across all nature-of-change values by using 11 measurements. 

\noindent In summary, with middle-and-extreme spacing, low bias is achieved in the estimation of all day-unit parameters across all manipulated nature-of-change values using 11 measurements, which is indicated by the bolded text in the 'Low Bias' column of Table \ref{tab:summary-table-mid-ext-exp1}.

#### Precision {#precision-mid-ext-exp1}

With respect to precision for middle-and-extreme spacing, it is low (i.e., error bar length above the 20% acceptable cutoff) with the following measurement numbers and nature-of-change values for each day-unit parameter:  

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_mid_ext}A): five measurements with nature-of-change values of 80 and 280.
* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_mid_ext}B): five and seven, an nine measurements with nature-of-change values of 80 and 280 (shown on x-axis).
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}C): all cells.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}D): all cells. 

\noindent In summary, with middle-and-extreme spacing, high precision is achieved in the estimation of the fixed-effect day-unit parameters across all manipulated nature-of-change values with 11 measurements, but no manipulated measurement number achieves high precision in the estimation of the random-effect day-unit parameters (see the 'High Precision' column of Table \ref{tab:summary-table-mid-ext-exp1}). 

```{r plots-mid-ext-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Middle-and-extreme spacing',
                                  x_axis_name = expression("Nature of Change (Population Value Set for"~beta[fixed]~')'),
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -80, beta_upper = 80, beta_ticks = 20)
```

```{=tex}
\begin{figure}[H]
  \caption{Parameter Estimation Plots for Day-Unit Parameters With Middle-and-Extreme Spacing in Experiment 1}
  \label{fig:exp1_plot_time_mid_ext}
  \includegraphics{Figures/exp1_plot_days_middle-and-extreme spacing} 
\end{figure}
\begin{figure}[H]
\figurefootnote{Panel A: Parameter estimation plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Parameter estimation plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Parameter estimation plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Parameter estimation plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating cells with variability greater than 20\% of the parameter's population value. I considered dots that fell outside the gray bands as biased and error bar lengths that exceeded 20\% of the parameter's population value as indicative of low-precision estimation. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180.See Table \ref{tab:exp1-alpha-theta-param-est} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-mid-ext} for $\upomega^2$ effect size values.}
\end{figure}
```

\newpage
```{r omega-exp1-mid-ext, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'mid_ext', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Middle-and-Extreme Spacing in Experiment 1',
footnote = 'NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and population value set for $\\\\upbeta_{fixed}$. $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter,
           $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}D)'))
```



#### Qualitative Description {#qualitative-mid-ext-exp1}

```{r echo=F}
errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], 
                      errorbar_lengths_nm9$errorbar_length[2], 
                      errorbar_lengths_nm7$errorbar_length[3], 
                      errorbar_lengths_nm9$errorbar_length[4])
```

For middle-and-extreme spacing in Figure \ref{fig:exp1_plot_time_mid_ext}, although no manipulated measurement number achieves high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) are achieved using moderate measurements numbers. With respect to bias under middle-and-extreme spacing, the largest improvements across all manipulated nature-of-change values in bias occur with the following measurement numbers for the following day-unit parameters:

* random-effect days-to-halfway elevation parameter ($\upgamma_{fixed}$): seven measurements
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements
* random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): 11 measurements

\noindent With respect to precision under middle-and-extreme spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values are achieved with following measurement numbers:

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[1]` days.
* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[2]` days.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[3]` days.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[4]` days.

\noindent Therefore, for middle-and-extreme spacing, nine measurements achieves the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the 'Qualitative Description` column in Table \ref{tab:summary-table-mid-ext-exp1}). 

#### Summary of Results 

In summarizing the results for time-interval decreasing spacing, modelling accuracy is highestfor each day-unit parameter with a a nature-of-change value of 180 (i.e., midway halfway point; see [highest modelling accuracy](#nature-change-time-dec-exp1)). Low bias is obtained in the estimation of all day-unit parameters across all manipulated nature-of-change values using nine or more measurements (see [bias](#bias-time-dec-exp1)). High precision is never obtained in the estimation of all day-unit parameters with any manipulated measurement (see [precision](#precision-time-dec-exp1)). Although it may be discouraging that no manipulated measurement number under time-interval decreasing spacing achieves high precision in the estimation of all day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters are obtained with moderate measurement numbers. With time-interval decreasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values are obtained using nine measurements (see [qualitative description](#qualitative-time-inc-exp1)).  


### Addressing My Research Questions 


#### When the Nature of Change is Suspected, How Should Measurements be Spaced?

Table \ref{tab:summary-table-exp1-nc} lists the nature-of-change value that each spacing schedule obtains its highest modelling accuracy along with the corresponding precision with which each day-unit parameter is estimated. Text in the 'Highest Modelling Accuracy' column indicates the nature-of-change with which each spacing schedule obtains its modelling accuracy. The 'Error Bar Summary' columns list the error bar lengths obtained for each day-unit parameter using the nature-of-change value listed in the 'Highest Modelling Accuracy' column.\footnote{Bias values are not presented because the differences across the schedules are negligible.} Note that the error bar lengths are obtained by computing the average error bar length across all manipulated measurement numbers for the optimal nature-of-change value. Modelling accuracy for each spacing schedule is highest with the following nature-of-change values: 

* equal spacing: $\upbeta_{fixed}$ = 180 (i.e., midway halfway point)
* time-interval increasing spacing: $\upbeta_{fixed}$ = 80 (i.e., early halfway point)
* time-interval decreasing spacing: $\upbeta_{fixed}$ = 280 (i.e., late halfway point)
* middle-and-extreme spacing: $\upbeta_{fixed}$ = 180 (i.e., midway halfway point)

To understand why the modelling accuracy of each spacing schedule is highest with a specific nature of change, it is important to consider the locations on the curve where each schedule samples data. Figure \ref{fig:midpoint_plot} shows the measurement locations (indicates by dots) where each spacing schedule samples data for each manipulated nature of change ($\upbeta_{fixed} \in$ {80, 180, 180}). In Figure \ref{fig:midpoint_plot}A, data are sampled according to the equal spacing schedule. In Figure \ref{fig:midpoint_plot}B, data are sampled according to the time-interval increasing spacing schedule. In Figure \ref{fig:midpoint_plot}C, data are sampled according to the time-interval decreasing spacing schedule. In Figure \ref{fig:midpoint_plot}D, data are sampled according to the middle-and-extreme spacing schedule. Black curves indicate curves for which modelling accuracy is highest, with gray curves indicating curves where modelling accuracy is not at its highest. Error bar lengths printed on each panel to provide a reference indicate the precision with which each day-unit parameter is estimated when modelling accuracy is highest (values have been copied over from Table \ref{tab: summary-table-exp1-nc}). 

```{r summary-table-exp1-nc, echo=F}
#data set containing error bar widths for each parameter under each spacing schedule 
param_midpoint_equal <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Equal')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)


param_midpoint_time_inc <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'increasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)


param_midpoint_time_dec <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'decreasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)


param_midpoint_mid_ext <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Middle-and')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)

#combine vectors into a list 
errorbar_lengths_list <- list('equal' = param_midpoint_equal[[3]], 
                              'time_inc' = param_midpoint_time_inc[[2]], 
                              'time_dec' =  param_midpoint_time_dec[[4]], 
                              'mid_ext' =  param_midpoint_mid_ext[[3]])

beta_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[1])})))
gamma_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[2])})))
beta_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[3])})))
gamma_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[4])})))


summary_table <- data.frame('Spacing Schedule' = c('\\thead[lt]{Equal \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_equal} and Table \\ref{tab:errorbar-equal-nc})}',
                                                   '\\thead[lt]{Time-interval increasing \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_inc} and Table \\ref{tab:errorbar-time-inc-nc})}', 
                                                   '\\thead[lt]{Time-interval decreasing \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_dec} and Table \\ref{tab:errorbar-time-dec-nc})}', 
                                                   '\\thead[lt]{Middle-and-extreme \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_mid_ext} and Table \\ref{tab:errorbar-mid-ext-nc})}'), 
                            'Highest Modelling Accuracy' = c('$\\upbeta_{fixed}$ = 180', 
                                                         '$\\upbeta_{fixed}$ = 80', 
                                                         '$\\upbeta_{fixed}$ = 280', 
                                                         '$\\upbeta_{fixed}$ = 180'), 
                        
                            '$\\upbeta_{fixed}$' = beta_fixed_errorbar_lengths, 
                            '$\\upgamma_{fixed}$' = gamma_fixed_errorbar_lengths, 
                            '$\\upbeta_{random}$' = beta_rand_errorbar_lengths, 
                            '$\\upgamma_{random}$' = gamma_rand_errorbar_lengths, 
                            
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex', digits = 2,
    linesep = c('\\cmidrule{1-6}', '\\cmidrule{1-6}', '\\cmidrule{1-6}'), 
       longtable = T, booktabs = T, centering = T, escape = F,
    caption = 'Nature-of-Change Values That Lead to the Highest Modelling Accuracy for Each Spacing Schedule in Experiment 1', 
   align = c(rep('l', times = 1), rep('c', times = 4))) %>%
     #header
    add_header_above(header = c(' ' = 2, 'Error Bar Summary' = 4)) %>%
  column_spec(column = 1, width = '4.86cm') %>%
  column_spec(column = 2, width = '6cm') %>%
  column_spec(column = 3:6, width = '1.5cm') %>%
    footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1pc}',
           general = "`Highest Modelling Accuracy' indicates the curve that results in the highest modelling accuracy. `Error Bar Summary' columns lists error bar lengths for each day-unit parameter such that error bar lengths are computed by taking the average error bar length value across all the number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\\\{80, 180, 280\\\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4.") %>%
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```

```{r midpoint_plot, echo=F, eval=F}
#log function data 
t <- 0:360
theta <- 3
alpha <- 3.32
beta_80 <- 80
beta_180 <- 180
beta_280 <- 280
gamma <- 20

#log function
log_function <- expression(theta + (alpha - theta)/(1 + exp((beta_180 - t)/gamma)))


log_function_80 <- theta + (alpha - theta)/((1 + exp((beta_80 - t)/gamma)))
log_function_180 <- theta + (alpha - theta)/((1 + exp((beta_180 - t)/gamma)))
log_function_280 <- theta + (alpha - theta)/((1 + exp((beta_280 - t)/gamma)))
log_function_180b <- theta + (alpha - theta)/((1 + exp((beta_280 - t)/gamma)))

log_func_wide <- data.frame(cbind(t, log_function_180, log_function_80, log_function_280, log_function_180b,
                                  'midpoint_80' = log_function_80,
                                  'midpoint_180' = log_function_180,
                                  'midpoint_280' = log_function_280))

log_func_long <- log_func_wide %>%
  pivot_longer(cols = 2:5,
               #names_pattern = c('^log', '^midpoint'), 
               names_to = c('midpoint'),# 'midpoint_grouping'), 
               values_to = c('curve_value'), 
                names_transform = factor) %>% 
  pivot_longer(cols = 2:4, 
             names_to = c('midpoint_grouping'), 
            values_to = c('curve_value_group'), 
             names_transform = factor)

#add grouping variable for curve_value_group to indicate if the curve is the optimal one or not
##find the rows where the number in midpoint matches that in midpoint_grouping 
#1) Extract number from midpoint column 

log_func_long$optimal <- factor(extract_numeric(x = log_func_long$midpoint) != extract_numeric(x = log_func_long$midpoint_grouping))

log_func_long$midpoint <-  recode_factor(log_func_long$midpoint,   
                                    'log_function_180' = "atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))",
                                    'log_function_80' = "atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))",
                                    'log_function_280' = "atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))",
                                    'log_function_180b' = "atop(bold(D:beta[fixed]==180~With~`Middle-and-`~phantom(text~forleftaligni)), bold(`Extreme`~Spacing)~phantom(text~forleftalandalmorerand))")


#spacing schedule data
num_measurements <- 5
time_period <- 360 
smallest_int_length <- 30
schedules <- c('equal', 'time_inc', 'time_dec', 'mid_ext')

list_out <- unlist(do.call(rbind, pmap(.l = list('num_measurements' = num_measurements, 
               'time_period' = time_period, 
               'smallest_int_length' = smallest_int_length, 
               measurement_spacing = schedules), 
     .f = compute_measurement_schedule))[, 2])

measurement_days_wide <- data.frame(matrix(data = list_out, nrow = 4, ncol = num_measurements, byrow = T, 
       dimnames = list(schedules, sprintf('measurement_day_%d', 1:num_measurements)))) %>%
  rownames_to_column(var = 'schedule')

measurement_days_wide$midpoint <- c('180', '80', '280', '180a')

#add midpoint 
measurement_days_wide$midpoint <-  recode_factor(measurement_days_wide$midpoint,  
                                    '180' = "atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))",
                                    '80' = "atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))",
                                    '280' = "atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))",
                                    '180a' = "atop(bold(D:beta[fixed]==180~With~`Middle-and-`~phantom(text~forleftaligni)), bold(`Extreme`~Spacing)~phantom(text~forleftalandalmorerand))")

measurement_days_long <- measurement_days_wide %>% 
  pivot_longer(cols = 2:(num_measurements + 1), names_to = 'measurement_num', values_to = 'day_number') %>%
  mutate_if(.predicate = is.character, .funs = factor)

#add curve values; match log_func_long on midpoint and then add the corresponding curve value 
measurement_days_long <- left_join(x = measurement_days_long, y = log_func_long, by = c('midpoint', 'day_number' = 't'))



#combine vectors into a list 
errorbar_lengths_list <- list('equal' = round(param_midpoint_equal[[3]], digits = 2),  
                              'time_inc' = round(param_midpoint_time_inc[[2]], digits = 2), 
                              'time_dec' =  round(param_midpoint_time_dec[[4]], digits = 2), 
                              'mid_ext' =  round(param_midpoint_mid_ext[[3]], digits = 2))

beta_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[1])})))
gamma_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[2])})))
beta_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[3])})))
gamma_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[4])})))

equation_data <- data.frame(
  midpoint =c(rep("atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))", times = 4), 
               rep("atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))", times = 4), 
               rep("atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))", times = 4), 
               rep("atop(bold(D:beta[fixed]==180~With~`Middle-and-`~phantom(text~forleftaligni)), bold(`Extreme`~Spacing)~phantom(text~forleftalandalmorerand))", times = 4)),
  
  label = c(paste("beta[fixed] == ", beta_fixed_errorbar_lengths[1], sep = ''), 
            paste("gamma[fixed] == ", gamma_fixed_errorbar_lengths[1], sep = ''), 
            paste("beta[random] == ", beta_rand_errorbar_lengths[1], sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[1], sep = ''), 
            
            paste("beta[fixed] == ", beta_fixed_errorbar_lengths[2], sep = ''), 
            paste("gamma[fixed] == ", gamma_fixed_errorbar_lengths[2], sep = ''), 
            paste("beta[random] == ", beta_rand_errorbar_lengths[2], sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[2], sep = ''), 
            
            paste("beta[fixed] == ", beta_fixed_errorbar_lengths[3], sep = ''), 
            paste("gamma[fixed] == ", gamma_fixed_errorbar_lengths[3], sep = ''), 
            paste("beta[random] == ", beta_rand_errorbar_lengths[3], sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[3], sep = ''), 
            
            paste("beta[fixed] == ", beta_fixed_errorbar_lengths[4], sep = ''), 
            paste("gamma[fixed] == ", gamma_fixed_errorbar_lengths[4], sep = ''), 
            paste("beta[random] == ", beta_rand_errorbar_lengths[4], sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[4], sep = '')), 

  x = c(rep(c(-10, -10, -3, 0), times = 4)),
        #280, 280, 287, 290, 
        #rep(c(80, 80, 87, 90), times = 2)), 
  y = c(rep(c(3.24, 3.20, 3.16, 3.12), times = 4)))


#add optimal spacing midpoint column
midpoint_plot <- ggplot(data = log_func_long, mapping = aes(x = t, y = curve_value_group, 
                                                            group = midpoint_grouping, color = optimal, alpha = optimal)) + 
  geom_line(size = 4) +
  scale_y_continuous(name = 'Curve Value (Likert Units [Scale 1-5])') + 
  geom_point(data = measurement_days_long, aes(x = day_number, y = curve_value_group,
                                               group = midpoint_grouping, color = optimal, alpha = optimal), size = 15) +
  scale_color_manual(name = 'Highest Modelling Accuracy?', values = c('#0C0301', '#D3CFCE'),  labels = c('Yes', 'No')) + 
  scale_alpha_manual(name = 'Highest Modelling Accuracy?', values = c(1, 1),labels = c('Yes', 'No')) + 
  
  geom_text(data = equation_data, inherit.aes = F, mapping = aes(x = x, y = y, label = label), parse = T, size = 17.5) +
  facet_wrap_custom( ~ midpoint, scales = "free", ncol = 2, nrow = 2 , dir = 'h',
                     labeller = label_parsed,  

                            scale_overrides = list(
                            scale_override(1,
                              scale_x_continuous(name = 'Measurement Number', 
                                breaks = c(0, 80, 120, 180, 240, 300, 360),
                                limits = c(-60, 360))), 
                          
                             scale_override(which = 2,
                              scale_x_continuous(name = 'Measurement Number', 
                                breaks = c(0, 60, 120, 180, 240, 300, 360),
                                limits = c(-60, 360))), 
                            
                            scale_override(which = 3,
                              scale_x_continuous(name = 'Measurement Number', 
                                breaks = c(0, 60, 120, 180, 280, 360),
                                limits = c(-60, 360))), 
                            
                              
                            scale_override(which = 4,
                              scale_x_continuous(name = 'Measurement Number', 
                                breaks = c(0, 60, 120, 180, 240, 300, 360),
                                limits = c(-60, 360))))) +
  
     
                         
  theme_classic(base_family = 'Helvetica') + 
  theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
       
      #axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #legend details
      legend.text = element_text(size = 50),
      legend.margin = margin(unit(c(0, 0, 0, 10), "cm")),
      legend.title = element_text(size = 60),
      legend.key.size = unit(3, 'cm'),
      legend.position = c(0.5, 0.52), 
      legend.direction = 'vertical',
      legend.box.background = element_rect(colour = 'black', size = 3),

      #panel details
      panel.spacing.y = unit(x = 18, units = 'cm'), 
       panel.spacing.x = unit(x = 2, units = 'cm')) 


set_panel_size(p = midpoint_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/midpoint_plot.pdf')
```

```{=tex}
\begin{figure}[H]
  \caption{Nature-of-Change Curves for Each Spacing Schedule Have Highest Modelling Accuracy When Measurements are Taken Near Periods of Change}
  \label{fig:midpoint_plot}
  \includegraphics{Figures/midpoint_plot} 
\end{figure}
\begin{figure}[H]
 \figurefootnote{Panel A: Measurement sampling locations on each manipulated nature-of-change curve under equal spacing. Panel B: Measurement sampling locations on each manipulated nature-of-change curve under time-interval increasing spacing. Panel C: Measurement sampling locations on each manipulated nature-of-change curve under time-interval decreasing spacing. Panel D: Measurement sampling locations on each manipulated nature-of-change curve under middle-and-extreme spacing. Black curves indicate the natures of change that lead to the highest modelling accuracy for each spacing schedule, and so are optimal. Gray curves indicate the natures of change that lead to suboptimal modelling accuracy for each spacing schedule, and so are not optimal. Text on each panel indicates the error bar lengths when modelling accuracy is highest (see Table \ref{tab:summary-table-exp1-nc}).}
\end{figure}
```

Before explaining why each spacing schedule has an optimal curve, it is important to define change. For the purpose of this discussion, change occurs when the first derivative of the logistic function has a nonzero value, with larger absolute first derivative values implying greater change. Figure \ref{fig:logistic_function_first_dev} shows each nature of change used in Experiment 1 (solid line) along with its corresponding first derivative curve (dotted line). For each nature of change, the first derivative value reaches its peak at the value set for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). In Figure \ref{fig:logistic_function_first_dev}A, the first derivative is greatest at day 80. In Figure \ref{fig:logistic_function_first_dev}B, the first derivative is greatest at day 180. In Figure \ref{fig:logistic_function_first_dev}C, the first derivative is greatest at day 280.  Therefore, for each manipulated nature of change, change is greatest at the value set for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). 

```{r first-deriv-curve, echo=F, eval=F}
#log function data 
t <- 0:360
theta <- 0
alpha <- 0.25
beta_80 <- 80
beta_180 <- 180
beta_280 <- 280
gamma <- 20

theta_deriv <- 0
alpha_deriv <- 10

#log function
log_function_80 <- expression(theta + (alpha - theta)/(1 + exp((beta_80 - t)/gamma)))
log_function_180 <- expression(theta + (alpha - theta)/(1 + exp((beta_180 - t)/gamma)))
log_function_280 <- expression(theta + (alpha - theta)/(1 + exp((beta_280 - t)/gamma)))

#expressions for derivatives (allows lines to occupy same y-axis range)
log_function_80_der <- expression(theta_deriv + (alpha_deriv - theta_deriv)/(1 + exp((beta_80 - t)/gamma)))
log_function_180_der <- expression(theta_deriv + (alpha_deriv - theta_deriv)/(1 + exp((beta_180 - t)/gamma)))
log_function_280_der <- expression(theta_deriv + (alpha_deriv - theta_deriv)/(1 + exp((beta_280 - t)/gamma)))

#compute derivatives
log_function_list <- list(log_function_80_der, log_function_180_der, log_function_280_der)
log_function_deriv_ls <- rapply(object = log_function_list, f = D, name = 't', how = 'unlist')

log_function_df <- data.frame('time' = t,
                              'log_function_80' = eval(log_function_80),
                              'log_function_180' = eval(log_function_180),
                              'log_function_280' = eval(log_function_280))

deriv_function_df <- data.frame('time' = t, 
  'log_function_80' =  eval(log_function_deriv_ls[[1]]), 
                                'log_function_180' =  eval(log_function_deriv_ls[[2]]), 
                                'log_function_280' =  eval(log_function_deriv_ls[[3]]))

#convert long function and deriv curves to long and then join on log_curve
log_func_long <- log_function_df %>% 
  pivot_longer(cols = log_function_80:log_function_280, names_to = 'log_curve', values_to = 'curve_value', names_transform = factor) 

deriv_func_long <- deriv_function_df %>% 
  pivot_longer(cols = log_function_80:log_function_280, names_to = 'log_curve', values_to = 'deriv_value', names_transform = factor)

log_deriv_func_long <- log_func_long %>% 
  left_join(y = deriv_func_long, by = c('log_curve', 'time')) 
log_deriv_func_long$log_curve <- recode_factor(.x =log_deriv_func_long$ log_curve, 
                     'log_function_80' = 'bold(A:beta[fixed]==80)', 
                     'log_function_180' = 'bold(B:beta[fixed]==180)', 
                     'log_function_280' = 'bold(C:beta[fixed]==280)')

log_deriv_func_long <- log_deriv_func_long %>% pivot_longer(cols = 'curve_value':'deriv_value', values_to = 'value', names_to = 'curve_type', 
                                     names_transform = factor)

deriv_plot <- ggplot(data = log_deriv_func_long, mapping = aes(x = time, y = value, 
                                                               group = curve_type, linetype = curve_type)) + 
  geom_line(size = 4) + 
  theme_classic() +
  scale_y_continuous(name = ' ', breaks = NULL) + 
  scale_linetype_manual(name = 'Curve Type', values = c(1, 3), 
                        labels = c('Logistic curve', 'Rate of change \n (first derivative')) + 
 facet_wrap_custom( ~ log_curve, scales = "free", ncol = 1, nrow = 3 , dir = 'h',
                     labeller = label_parsed,  

                            scale_overrides = list(
                            scale_override(1,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 80, 180, 240, 300, 360),
                                limits = c(0, 360))), 
                          
                             scale_override(which = 2,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 60, 120, 180, 240, 300, 360),
                                limits = c(0, 360))), 
                            
                            scale_override(which = 3,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 60, 120, 180, 280, 360),
                                limits = c(0, 360))))) + 
    
                         
  theme_classic(base_family = 'Helvetica') + 
  theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
       
      #axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #legend details
      legend.text = element_text(size = 50),
      legend.margin = margin(unit(c(0, 0, 0, 10), "cm")),
      legend.title = element_text(size = 60),
      legend.key.size = unit(3, 'cm'),
     # legend.position = c(0.2, 0.3), 
     legend.position = 'right', 
      legend.direction = 'vertical',
      legend.box.background = element_rect(colour = 'black', size = 3),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'))

set_panel_size(p = deriv_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/deriv_plot.pdf')

```
 
```{=tex}
\begin{figure}[H]
  \caption{Rate of Change (First Derivative Curve) for Each Nature of Change Curve Manipulated in Experiment 1}
    \includegraphics[width=6in, height = 8in]{Figures/deriv_plot} 
    \label{fig:logistic_function_first_dev}
\end{figure}
\begin{figure}[H]
  \figurefootnote{Panel A: Logistic curve defined by $\upbeta_{fixed}$ = 80, with first-derivative curve peaking at day 80. Panel B: Logistic curve defined by $\upbeta_{fixed}$ = 180, with first-derivative curve peaking at day 180. Panel C: Logistic curve defined by $\upbeta_{fixed}$ = 280, with first-derivative curve peaking at day 280.} 
\end{figure}
```

Figure \ref{fig:midpoint_plot} provides three reasons to suggest that sampling measurements closer to the period of greatest change increases modelling accuracy. First, for each spacing schedule, more measurements lie closer to the area of greatest change on the optimal black curve than on the suboptimal gray curves. One clear example can be observed for the measurement locations under middle-and-extreme spacing (see Figure \ref{fig:midpoint_plot}D). In looking across the nature-of-change curves, only the measurement locations of the middle three measurements on each curve are different. For the optimal black nature of change, the middle three measurements are centered on the period of greatest change. For the gray suboptimal nature-of-change curves, the middle three measurements are taken near regions of little change (near-zero first derivative). Therefore, nature-of-change curves are optimal for their respective spacing schedules because measurements are taken closest to the curves' periods of change.

Second, modelling accuracy under time-interval increasing and decreasing spacing is nearly identical because each spacing schedule samples data at the exact same regions of change. In looking at Table \ref{tab:summary-table-exp1-nc}, it is important to realize that the precision values (i.e., error bar lengths) obtained with time-interval increasing and decreasing spacing are nearly identical when modeling accuracy is highest. As an example, the average error bar length obtained for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) is 5.80 days with time-interval increasing spacing and a nature-of-change value of 80 (i.e., early halfway point) and 5.84 days with time-interval decreasing spacing and a nature-of-change value of 280 (i.e., late halfway point). The nearly equivalent precision obtained with time-interval increasing and decreasing spacing occurs because the rates of change (i.e., first derivative values) at the sampled locations are the exact same. Table \ref{tab:first-deriv} lists the curve values and measurement days when the time-interval increasing and decreasing spacing schedules sample the same first-derivative values. Note that, because the time-interval increasing and decreasing spacing schedules sample data in opposite orders, the first-derivative values are sampled in opposite orders. In summary, although the time-interval increasing and decreasing spacing schedules sample data on different days on their respective optimal curves, they result in (nearly) identical modelling accuracy because the first-derivative values of the optimal curves at the sampled locations are the exact same. 

```{r first-deriv, echo=F}
#log function data 
t <- 0:360
theta <- 3
alpha <- 3.32
beta_80 <- 80
beta_180 <- 180
beta_280 <- 280
gamma <- 20

#log function
log_function <- expression(theta + (alpha - theta)/(1 + exp((beta_180 - t)/gamma)))
log_function_deriv <- eval(D(log_function, name = 't'))

log_function_df <- data.frame('time' = t, 
                              'log_function' = round(eval(log_function), digits = 2), 
                              'first_deriv' = log_function_deriv)

#compute measurements days 
time_inc_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'time_inc')$measurement_days
time_dec_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'time_dec')$measurement_days

#combine measurement days into df
time_inc_table <- data.frame('id' = 1:length(time_inc_days),
           'time_inc' = time_inc_days) %>%
  pivot_longer(cols = 2, names_to = 'schedule', values_to = 'measurement_day', names_transform = factor) %>%
  left_join(y = log_function_df, by = c('measurement_day' = 'time')) %>%
   pivot_wider(names_from = 'schedule', values_from = c('measurement_day', 'first_deriv', 'log_function')) %>% 
  select(first_deriv_time_inc, log_function_time_inc, measurement_day_time_inc)


time_dec_table <- data.frame('id' = 1:length(time_dec_days),
           'time_dec' = time_dec_days) %>%
  pivot_longer(cols = 2, names_to = 'schedule', values_to = 'measurement_day', names_transform = factor) %>%
  left_join(y = log_function_df, by = c('measurement_day' = 'time')) %>%
   pivot_wider(names_from = 'schedule', values_from = c('measurement_day', 'first_deriv', 'log_function')) %>%
  select(first_deriv_time_dec, log_function_time_dec, measurement_day_time_dec) %>% 
  arrange(desc(measurement_day_time_dec))

time_inc_table$first_deriv_time_inc <- signif(x = time_inc_table$first_deriv_time_inc, digits = 3)
time_dec_table$first_deriv_time_dec <- signif(x = time_dec_table$first_deriv_time_dec, digits = 3)

combined_table <- cbind(time_inc_table, time_dec_table) %>% 
  select(first_deriv_time_inc, log_function_time_inc, measurement_day_time_inc, 
         log_function_time_dec, measurement_day_time_dec)

kbl(x = combined_table, format = 'latex', 
   longtable = T, booktabs = T, centering = T, escape = F, 
   col.names = c('First Derivative Value', 'Curve Value', 'Measurement Day', 'Curve Value', 'Measurement Day'), 
    align = c('l', rep(x = 'c', times = ncol(combined_table) - 1)), 
    caption = 'Identical First-Derivative Sampling of Time-Interval Increasing and Decreasing Spacing Schedules') %>% 
  kable_styling(position = 'left') %>% 
   #header
  column_spec(column = 1, width = '4cm') %>%
  column_spec(column = 2:5, width = '2.5cm') %>%
  add_header_above(header = c(' ' = 1, 'Time-Interval Increasing' = 2,' Time-Interval Decreasing' = 2)) %>% 
   footnote(escape = F, threeparttable = T, general_title =  ' ', general = " ")
```

```{r echo=F} 
equal_5_180 <- exp_1_analytical$days %>% 
  filter (measurement_spacing == 'Equal spacing', number_measurements == 5, midpoint == 180) %>% 
  group_by(parameter) %>% 
  summarize(errorbar_length = mean(upper_ci) - mean(lower_ci))

mid_5_180 <- exp_1_analytical$days %>% 
  filter (measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 5, midpoint == 180) %>% 
  group_by(parameter) %>% 
  summarize(errorbar_length = mean(upper_ci) - mean(lower_ci))
```

Third, middle-and-extreme spacing obtains higher modelling accuracy than equal spacing by sampling data at periods of greater change. Importantly, both equal and middle-and-extreme spacing obtain their highest modelling accuracy with a curve whose greatest change occurs at 180 days (i.e., midway halfway point), with middle-and-extreme spacing obtaining higher precision (i.e., shorter error bars) than equal spacing (see Figure \ref{fig:midpoint_plot} and Table \ref{tab:summary-table-exp1-nc}). An inspection of Figures \ref{fig:midpoint_plot}A and \ref{fig:midpoint_plot}D reveals that middle-and-extreme spacing samples measurements at moments of greater change. As an example, consider the measurement locations of equal and middle-and-extreme spacing with five measurements, where only second and fourth measurement locations differ between the schedules. For equal spacing, the second and fourth measurements are respectively sampled on days 90 and 270. For middle-and-extreme spacing, the second and fourth measurements are respectively taken on days 150 and 210. By consulting the first-derivative curve in Figure \ref{fig:first-deriv}, change is greater on days 150 and 210 than on days 90 and 270. Therefore, precision across all manipulated measurement numbers is greater (i.e., shorter error bars) with middle-and-extreme spacing than with equal spacing because middle-and-extreme spacing takes measurements closer to periods of change than equal spacing (see Figures \ref{fig:midpoint_plot}A and \ref{fig:midpoint_plot}D and Table \ref{tab:summary-table-exp1-nc}). 

The idea that modelling accuracy increases when data are sampled during periods of greater change has received considerable discussion and preliminary support. Over the past 20 years, researchers have recommended that measurements be sampled during periods of greater change [@siegler2006; @ployhart2010], with one recent simulation study finding evidence support this idea [@timmons2015]. Unfortunately, the evidence from @timmons2015 is preliminary for two reasons. First, the model used to estimate nonlinear change only ever included one random-effect parameter. Given that multilevel models often include several random-effect parameter in practice, the model employed in @timmons2015 may not necessary be realistic. Second, the estimates were obtained by using an impractical starting value procedure: Population values were used as starting values. Because practitioners never know the population value, it is not known whether the results of @timmons2015 replicate with a realistic starting value procedure. 

My simulations in Experiment 1 replicated the finding that modelling accuracy increases from measuring change near periods of change under more realistic conditions. In contrast to the one-random-effect-parameter models used in @timmons2015, my simulations used a four-parameter model where each parameter was modelled as a fixed and random effect. For the starting value procedure, my simulations did not use the population values as starting values, but used the starting value procedure available in OpenMx.

Therefore, three results in Experiment 1 suggest that sampling data closer to periods of change leads to higher modelling accuracy. First, for each spacing schedule, modelling accuracy is highest when measurements are taken closer to periods of change. Second, the time-interval increasing and decreasing spacing schedules obtain nearly identical modelling accuracies for different curves because the sampled locations have the exact same rates of change. Third, middle-and-extreme spacing results in higher modelling accuracy than equal spacing by sampling measurements at periods of greater change. Although several researchers have posited modelling accuracy increases by sampling data closer to periods of change, with one simulation study (to my knowledege) having confirmed this notion under unrealistic modelling conditions, my simulations in Experiment 1 confirm it under realistic modelling conditions. 

#### When the Nature of Change is Unknown, How Should Measurements be Spaced?

Table \ref{tab:summary-table-exp1} provides a summary of the results for each spacing schedule. Text within the 'Low Bias' column indicates the number of measurements needed to obtain low bias in the estimation of all day-unit parameters across all manipulated nature-of-change values for each spacing schedule. Text within the 'Qualitative Description' column indicates the number of measurements that obtains the largest improvements in bias and precision across all manipulated nature-of-change values for each spacing schedule. The 'Error Bar Summary' columns list the error bar lengths obtained for each day-unit parameter of the logistic function using the measurement number listed in the 'Qualitative Description' column. Importantly, the error bar lengths in the 'Error Bar Summary' column are obtained by computing the average length across all manipulated nature-of-change values for the measurement number listed Qualitative Description' column. The following number of measurements are needed to obtain low bias and the greatest improvements in bias and precision across all manipulated nature-of-change values for all day-unit parameters under each spacing schedule: 

* equal spacing: nine or more measurements to obtain low bias and seven measurements to obtain the greatest improvements in bias and precision. 
* time-interval increasing spacing: nine or more measurements to obtain low bias and nine measurements to obtain the greatest improvements in bias and precision. 
* time-interval decreasing spacing: nine or more measurements to obtain low bias and nine measurements to obtain the greatest improvements in bias and precision. 
* middle-and-extreme spacing: 11  measurements to obtain low bias and nine measurements to obtain the greatest improvements in bias and precision. 

```{r summary-table-exp1, echo=F}
#error bar lengths for each spacing schedule
errorbar_lengths_equal <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Equal spacing', num_measurements = 7)$errorbar_length

errorbar_lengths_time_inc_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval increasing', num_measurements = 9)$errorbar_length

errorbar_lengths_time_dec_nm9<- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval decreasing', num_measurements = 9)$errorbar_length

errorbar_lengths_mid_ext_nm9<- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Middle-and-extreme spacing', num_measurements = 9)$errorbar_length

#combine vectors into a list 
errorbar_lengths_list <- list('equal' = errorbar_lengths_equal, 
                              'time_inc' = errorbar_lengths_time_inc_nm9, 
                              'time_dec' = errorbar_lengths_time_dec_nm9, 
                              'mid_ext' = errorbar_lengths_mid_ext_nm9)

beta_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[1])})))
gamma_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[2])})))
beta_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[3])})))
gamma_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[4])})))


summary_table <- data.frame('Spacing Schedule' = c('\\thead[lt]{Equal \\\\ (see Figure \\ref{fig:exp1_plot_equal} and Table \\ref{tab:summary-table-equal-spacing-exp1})}', 
                                                   '\\thead[lt]{Time-interval increasing \\\\
                                                   (see Figure \\ref{fig:exp1_plot_time_inc} and Table \\ref{tab:summary-table-time-inc-exp1})}', 
                                                   
                                                   '\\thead[lt]{Time-interval decreasing \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_dec} and Table \\ref{tab:summary-table-time-dec-exp1})}', 
                                                   '\\thead[lt]{Middle-and-extreme \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_mid_ext} and Table \\ref{tab:summary-table-time-dec-exp1})}'), 
                                                   
                            'Low Bias' = c('NM $\\ge$ 9', 
                                           'NM $\\ge$ 9', 
                                           'NM $\\ge$ 9', 
                                           'NM = 11'), 
                            'High Precision' = c('No cells', 
                                            'No cells', 
                                            'No cells',
                                            'No cells'), 
                            'Qualitative Description' = c('Largest improvements in bias and precision with NM = 7', 
                                                      'Largest improvements in bias and precision with NM = 9', 
                                                      'Largest improvements in bias and precision with NM = 9', 
                                                      'Largest improvements in bias and precision with NM = 9'), 
                            
                            '$\\upbeta_{fixed}$' = beta_fixed_errorbar_lengths, 
                            '$\\upgamma_{fixed}$' = gamma_fixed_errorbar_lengths, 
                            '$\\upbeta_{random}$' = beta_rand_errorbar_lengths, 
                            '$\\upgamma_{random}$' = gamma_rand_errorbar_lengths, 
                            
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
    linesep = c('\\cmidrule{1-8}', '\\cmidrule{1-8}', '\\cmidrule{1-8}'), #\\cmidrule(l{0.25cm}r{0.25cm}){1-8}
       longtable = T, booktabs = T, centering = T, escape = F,
    caption = 'Concise Summary of Results Across All Spacing Schedule Levels in Experiment 1', 
   align = c(rep('l', times = 4), rep('c', times = 4))) %>%
     #header
  column_spec(column = 1, width = '4.86cm') %>%
  column_spec(column = 2, width = '2cm') %>%
  column_spec(column = 3, width = '2cm') %>%
  column_spec(column = 4, width = '7cm') %>%
  column_spec(column = 5:8, width = '1cm') %>%
  add_header_above(header = c(' ' = 4, 'Error Bar Summary' = 4)) %>%
  
  #row highlighting 
  row_spec(1, background = "#DFDEDE") %>%

   #footnotes
  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.1pc}',
           general = "`Qualitative Description' column indicates the number of measurements that obtains the greatest improvements in bias and precision across all day-unit parameters and manipulated nature-of-change values. `Error Bar Summary' columns list the error bar lengths that result for each day-unit parameter using the measurement number listed in the `Qualitative Description' column. Note that error bar lengths were calculated by computing the average length across all manipulated measurement numbers for the nature-of-chang value listed in the `Optimal Nature-of-Change Value` column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\\\{80, 180, 280\\\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.") %>%
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
``` 

An important point to mention is that the error bar lengths for each day-unit parameter across each spacing schedule are comparable. That is, each spacing schedule obtains similar modelling accuracy when using the number of measurements listed in the 'Qualitative Description' column. Because modelling accuracy is similar across the spacing schedules, then the schedule that requires the fewest number of measurements to obtain the greatest improvements in bias and precision models change most accurately when the nature of change is unknown. With equal spacing using fewer measurements than all the other manipulated spacing schedules to obtain similar modelling accuracy---using seven measurements instead of the nine measurements use by all other spacing schedules---equal spacing is the most effective schedule to use when the nature of change is unknown. 

The finding that equal spacing results in the highest modelling accuracy when the nature of change is unknown is not unexpected. Given the previous finding that modelling accuracy increases by sampling data closer to periods of change, then, if the nature of change is unknown, change may occur at any point in time, and so it is prudent to space measurements equally over time. 

## Summary of Experiment 1

I designed Experiment 1 to investigate two questions. The first question was how to space measurements when the nature of change is suspected. For each spacing schedule, modelling accuracy was highest when measurements were sampled at periods of greaterc change. Therefore, when the nature of change is suspected, measurements should be taken near periods of change to increase modelling accuracy. 

The second question was how to space measurements when the nature of change is unknown. Although no manipulated measurement number under any spacing schedule resulted in accurate modelling of all parameters, the improvements in modelling accuracy began to diminish under each spacing schedule at a specific measurement number. Given that each spacing schedule obtained comparable modelling accuracy when it began to diminish, I concluded that the spacing schedule that used the fewest number of measurements was most effective at modelling change when the nature of change was unknown. With equal spacing using the fewest number of measurements to obtain the greatest improvements in modelling accuracy, equal spacing was the most effective schedule to use when the nature of change was unknown. 












