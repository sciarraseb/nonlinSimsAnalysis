---
shorttitle        : "Measurement timing"
format          : "pandoc"
header-includes:
  - \usepackage{nccmath}
  - \usepackage{caption}
  - \usepackage{textcomp} #for copyright symbol on title page
  - \usepackage{longtable}
  - \usepackage{setspace}
  - \usepackage{biblatex}
  - \usepackage{booktabs}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
  - \usepackage{amsthm} 
  - \usepackage{amsmath} ##needed for argmax
  - \DeclareMathOperator*{\argmax}{arg\,max}
  - \usepackage{setspace} #needed to doublespace caption text (using \doublespacing)
  - \usepackage[labelfont = {bf, up}]{caption} 
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \usepackage{upgreek}  #required for non-italicized Greek letters
  - \usepackage{subcaption}
  - \captionsetup[figure]{labelfont={normalfont, bf}, singlelinecheck=false, labelsep=newline}
  - \DeclareCaptionJustification{double}{\DoubleSpacing}
  - \DeclareCaptionFont{figCaptionFont}{\fontfamily{phv}} #sets caption font to sans serif font of Helvetica 
  - \DeclareCaptionFont{figCaptionSize}{\footnotesize} #set caption font size to footnote 
  - \DeclareCaptionFont{figCaptionStyle}{\textup}  #set caption font to non-italicized font  
  - \DeclareCaptionLabelSeparator{captionSep}{\newline\newline} #separates figure label and figure title with required white space
  - \captionsetup[figure]{labelfont={figCaptionStyle, bf}, font = {figCaptionFont,figCaptionSize, figCaptionStyle}, labelsep = captionSep, justification=raggedright}
  - \captionsetup[table]{font = {figCaptionFont,figCaptionSize,figCaptionStyle}, labelfont={bf}, labelsep=captionSep, justification = raggedright, margin = {0cm,0cm}}
  - \newenvironment{helvenv}{\fontfamily{phv}\selectfont}{}
  - \raggedbottom #ensures text starts from top of page and any white space is at the botom

#environment numbering 
  - \setcounter{section}{0} 
  - \makeatletter \renewcommand\thesection{} \renewcommand\thesubsection{\@arabic\c@section.\@arabic\c@subsection} \makeatother
  
  - \newtheorem{theorem}{Theorem}
  - \newtheorem{example}[theorem]{Example}
  
  #modifies heading levels of 4-5 to follow apa7
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

  
author: 
  - name          : "Sebastian Sciarra "
    affiliation   : "1"
    corresponding : yes    
    email         : "ssciarra@uoguelph.ca"
affiliation: 
  - id            : "1"
    institution   : "University of Guelph"
keywords          : "measurement timing, nonlinear "
wordcount         : "5554 words"
floatsintext      : yes
linkcolor         : blue
figsintext        : yes 
figurelist        : no
tablelist         : no
footnotelist      : no
numbersections    : yes
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa7"
csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  markdown: 
    wrap: 72
bibliography: dissertation_references.bib
---

```{r package_loading, include=F}
#load packages
library(easypackages)
packages <- c('devtools','tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'nonlinSims','papaja', 
              'ggbrace', 'cowplot')
libraries(packages)
load_all()
```

```{r knitting_setup, echo=F, message = F, warning = F, eval=F}
#import raw data files (needed for computing variances)
exp_1_raw <-convert_raw_var_to_sd(raw_data = read_csv('Data/exp_1A.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)
  
exp_2_raw <-convert_raw_var_to_sd(raw_data = read_csv('Data/exp_2.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "sample_size"), factor)

exp_3_raw <-convert_raw_var_to_sd(raw_data = read_csv('Data/exp_3.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)

#unfiltered data 
param_summary_exp_1 <- readRDS(file = 'data/uf_param_summary_exp_1.RData')
param_summary_exp_2 <- readRDS(file = 'data/uf_param_summary_exp_2.RData')
param_summary_exp_3 <- readRDS(file = 'data/uf_param_summary_exp_3.RData')

#create analytical versions of summary data 
exp_1_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1, exp_num = 1)
exp_2_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_2, exp_num = 2)
exp_3_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3, exp_num = 3)

#create condition summary data sets 
cond_summary_exp_1 <- compute_condition_summary(param_summary_data = param_summary_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))
cond_summary_exp_2 <- compute_condition_summary(param_summary_data = param_summary_exp_2, facet_var = 'measurement_spacing', 
                  ind_vars = c('number_measurements', 'measurement_spacing', 'sample_size'))
cond_summary_exp_3 <- compute_condition_summary(param_summary_data = param_summary_exp_3, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))
```

```{r ergodicity, include=F, eval=F}
num_people <- 100 
num_occasions <- 100

data_set_1 <- matrix(data = list('ID' = NA, 
           'occasion' = NA), 
           nrow = num_people, ncol = num_occasions) 

data_set_2 <- matrix(data = list('ID' = NA, 
           'occasion' = NA), 
           nrow = num_people, ncol = num_occasions) 

for (person in 1:num_people) {
  
  #homogeneity = same mean and SD across all people 
  #stationarity = constant mean and variance over time 
  data_set_1[person, ] <- rnorm(n = num_occasions, mean = runif(n = 1, min = 5, max = 50), 
                              sd = runif(n = 1, min = 2, max = 5))
}

for (person in 1:num_people) {
  
  #homogeneity = same mean and SD across all people 
  #stationarity = constant mean and variance over time 
  data_set_2[person, ] <- rnorm(n = num_occasions, mean = runif(n = 1, min = 5, max = 50), 
                              sd = runif(n = 1, min = 2, max = 5))
}

mode(data_set_1) <- 'numeric'
data_df <- as.data.frame(x = data_set_1)

mode(data_set_2) <- 'numeric'
data2_df <- as.data.frame(x = data_set_2)

var(rowMeans(data_df))
var(colMeans(data_df))

##BETWEEN PERSON VARIANCE
mean_value <- mean(colMeans(data_df)) 
between_var <- sum((rowMeans(data_df) - mean_value)^2)/100

##WITHIN PERSON VARIANCE
within_var <- mean(apply(X = data_df, MARGIN = 1, FUN = var)) #person 

##total_variance
total_var <- var(unlist(data_df))



within_cors <- rep(NA, times = num_people)

#compute correlations within people 
for(person in 1:num_people) {
  
  within_cors[person] <- cor(as.numeric(data_df[person, ]), as.numeric(data2_df[person, ]))
}

between_cors <- rep(NA, times = num_people)

#compute correlations between people 
for(occasion in 1:num_occasions) {
  
  between_cors[occasion] <- cor(as.numeric(data_df[ ,occasion]), as.numeric(data2_df[ ,occasion]))
}

sd(within_cors)
sd(between_cors)

mean(within_cors)
mean(between_cors)

mean(rowMeans(data_df))
mean(colMeans(data_df[sample(x = 1:100, size = 60, replace = F), ]))

sqrt(mean(apply(X = data_df, MARGIN = 2, FUN = var))) #variable sds
sqrt(mean(apply(X = data_df, MARGIN = 1, FUN = var))) #person sds
```

```{=tex}
\newpage
\vspace*{-\topskip}
\vspace*{\fill}
\nointerlineskip
```

10.1037/a0019365

### Summary 

Importantly, 
1000 data sets were generated for each cell (*n* = 1000), and so 48 000 data sets were generated for the 48 cells in Experiment 1, 96 000 data sets were generated for the 96 cells in Experiment 2, and 72 000 data sets were generated for the 72 cells in Experiment 3.

```{r experimentOverview, echo=F}

exp_overview_df <- data.frame(
'\\textbf{Experiment 1}'= c(
'\\hspace{2pc}IV1: Number of measurements (5, 7, 9, 11)',
'\\hspace{2pc}IV2: Spacing of measurements (equal, time-interval increasing, time-interval decreasing, middle-and-extreme)',
'\\hspace{2pc}IV3: Nature of change (fixed-effect days-to-halfway elevation parameter $\\upbeta_{fixed}$ value of 80, 180, or 280)',
'\\hspace{2pc}DV1: Convergence success rate',
'\\hspace{2pc}DV2: Percent bias',
'\\hspace{2pc}Constants: time-structured data, sample size (\\textit{N} = 225), independent and identically distributed errors, no missing data', 
'\\hspace{2pc}Number of data sets: 48 000',

'\\textbf{Experiment 2 (see Cells 5 \\& 9 of Table @ref(tab:systematicReviewCount-exp))}',
'\\hspace{2pc}IV1: Number of measurements (5, 7, 9, 11)',
'\\hspace{2pc}IV3: Spacing of measurements (equal, time-interval increasing, time-interval decreasing, middle-and-extreme)',
'\\hspace{2pc}IV2: Sample size (30, 50, 100, 200, 500, 1000)',
'\\hspace{2pc}DV1: Convergence success rate',
'\\hspace{2pc}DV2: Percent bias',
'\\hspace{2pc}Constants: fixed-effect days-to-halfway elevation parameter ($\\upbeta_{fixed}$ = 180), time-structured data, independent and \\phantom{andd}identically distributed errors, no missing data', 
'\\hspace{2pc}Number of data sets: 96 000',


'\\textbf{Experiment 3 (see Cells 1 \\& 10 of Table @ref(tab:systematicReviewCount-exp))}',
'\\hspace{2pc}IV1: Number of measurements (5, 7, 9, 11)',
'\\hspace{2pc}IV2: Sample size (30, 50, 100, 200, 500, 1000)',
'\\hspace{2pc}IV3: Time structuredness (time-structured data, fast response rate, slow response rate) ',
'\\hspace{2pc}DV1: Convergence success rate',
'\\hspace{2pc}DV2: Percent bias',
'\\hspace{2pc}Constants: fixed-effect days-to-halfway elevation parameter ($\\upbeta_{fixed}$ = 180), measurement spacing (equal), independent and \\phantom{andd}identically distributed errors, no missing data', 
'\\hspace{2pc}Number of data sets: 72000'

), check.names = F)

kbl(x = exp_overview_df, format = 'latex', caption = 'Summary of Simulation Experiments', 
    align = 'l', 
    toprule = '\\cmidrule[\\heavyrulewidth](r{5cm}){1-1}', 
    midrule = '\\cmidrule(r{5cm}){1-1}',
    bottomrule = '\\cmidrule[\\heavyrulewidth](r{5cm}){1-1}', 
booktabs = T, longtable = T, escape=F,
linesep = c(rep('', times = 6),
            '\\addlinespace\\addlinespace\\cmidrule(r{5cm}){1-1}', '\\cmidrule(r{5cm}){1-1}', 
            rep('', times = 6), 
            '\\addlinespace\\addlinespace\\addlinespace\\cmidrule(r{5cm}){1-1}','\\cmidrule(r{5cm}){1-1}', 
            rep('', times = 6), 
            '\\addlinespace\\addlinespace\\cmidrule(r{5cm}){1-1}', '\\cmidrule(r{5cm}){1-1}',
            rep('', times = 7))) %>% 
  kable_styling(position = 'left') %>%

footnote(general = 'A 1000 data sets will be generated for each
condition (\\\\textit{n} = 1000) in each simulation experiment. \\\\phantom{filler content to set alignmentfiller content to set alignment}', 
         general_title = '\\\\textit{Note.\\\\hspace{-1pc}}', escape = F) %>%
row_spec(row = 8, background = '#9fc5e8') %>%
  column_spec(column = 1, width = '23.3cm') %>%
  #cell_spec(x = exp_overview_df[8, ], background = '#9fc5e8', latex_background_in_cell = T) %>%
row_spec(row = 16, background = '#9fc5e8') %>%
landscape(margin = '2cm') 
```

Because the study by @coulombe2016 represented the most comprehensive investigation into the effects of longitudinal design and analysis factors on modelling accuracy (see Table \ref{tab:systematicReview}), the
independent variable manipulations used in the current simulation experiments largely mirrored the
independent variable manipulations from @coulombe2016. As a reference,
Table \ref{tab:coulombe2016} lists the levels used for the independent
variables in @coulombe2016. One last point to mention is that the
independent variable manipulations were computed in the context of a
360-day period since many organizational processes are governed by
annual events (e.g., performance reviews, annual returns, regulatory
processes, etc.). Table \ref{tab:myValues} lists the levels used for
the independent variables in my simulations experiments.

(ref:coulombe2016) @coulombe2016

```{r coulombe2016, echo=F}

coulombe_df <- data.frame('Independent variable' = c('Number of measurements (NM)', 'Time structuredness (TS)', 'Sample size (S)'), 
                          'Levels' = c('3, 5, 7, 9', '40\\%, 100\\% of response window length', '30, 50, 100, 200, 500'), check.names = F)

kbl(x = coulombe_df, booktabs = TRUE, format = 'latex', longtable = T, 
      align = c('l', 'c'),
      caption = 'Levels Used for Independent Variables in (ref:coulombe2016)', 
    escape=F) %>%
   kable_styling(latex_options= c('hold_position'), font_size = 10, position =
                   'left')
```

```{r myValues, echo=F}
 myValues_df <- data.frame('Independent variabe' = c('Number of measurements (NM)', 'Time structuredness (TS)', 'Sample size (S)', 'Measurement spacing (MS)', 'Nature of change (population value set for the fixed-effect days-to-halfway elevation parameter [$\\upbeta_{fixed}$])'), 
                          'Levels' = c('5, 7, 9, and 11', 
                                       'Time structured, fast response rate ($a_{fast}$ = 0.37), and slow response rate ($a_{slow}$ = 0.15)', 
                                       '30, 50, 100, 200, 500, and 1000', 
                                       'Equal, time-interval increasing, time-interval decreasing, middle-and-extreme', 
                                       '80, 180, and 280 days'), check.names = F)

kbl(x = myValues_df, booktabs = TRUE, format = 'latex', longtable = T, 
      align = c('l', 'l'),
      caption = 'Levels Used for Independent Variables in my Simulations', 
    escape=F) %>%
  column_spec(column = 1, width = '6cm') %>%
  column_spec(column = 2, width = '10cm') %>%
   kable_styling(latex_options= c('hold_position', 'repeat_header'), font_size = 10, position = 'left')
```


## high-value outliers


Importantly, the high-value outliers in the density plot of Figure \ref{fig:density_gamma_equal}B correspond to the maximum possible value that was set in the model specification (specifically, a maximum value of $\upgamma_{random}$ = 45.00). Table \ref{tab:equal-gamma-outlier} shows the number of maximum-value estimates obtained for the random-effect triquarter-halfway parameter ($\upgamma_{random}$) for each nature-of-change value. With a nature-of-change value of 180, 36 maximum-value estimates are obtained. With nature-of-change values of 80 and 280, no maximum-value estimates are obtained. Therefore, precision with a nature-of-change value of 180 may be artificially lower because of the presence of maximum-value estimates. 

To investigate whether maximum-value estimations decreased precision for the random-effect triquarter-halfway parameter ($\upgamma_{random}$), I removed the maximum-value estimates (see Table \ref{tab:equal-gamma-outlier}) and then recomputed the 95% error bars. Figure \ref{fig:density_gamma_equal_fixed} shows the density plots of the random-effect triquarter-halfway parameter ($\upgamma_{random}$) with the maximum-value estimates removed. Although the error bar length with a nature-of-change value of 180 decreases when the maximum-value estimates are removed (see Figure \ref{fig:density_gamma_equal}B for comparison), it is still longer than the error bar lengths with the other nature-of-change values of 80 and 180 due to the existence of high-value estimates. Therefore, with equal spacing with a nature-of-change value of 180, precision is counterintuitively lower (i.e., longer error bars) for the estimation of the triquarter-halfway parameter ($\upgamma_{random}$) than with other nature-of-change values because the parameter estimation procedure converges on more high-value estimates. 

```{r density-nature-of-change-equal, include=F, eval=F}
compute_density <- function(error_bar_range, group, param_name, density_data) { 
  
  density_data <- density_data[density_data$group == group , ]
  
  density_lower_x <- min(which(density_data$x >= error_bar_range[1]))
  density_upper_x <- max(which(density_data$x <= error_bar_range[2]))
  
  day_values <- density_data$x[density_lower_x:density_upper_x]
  
  
  density_df <- data.frame('parameter' = param_name,
                           'day_value' = day_values,
                           'probability' = density_data$y[density_lower_x:density_upper_x], 
                           'max_density_value' = max(density_data$y),
                           'lower_ci' = error_bar_range[1], 
                           'upper_ci' = error_bar_range[2])

    return(density_df)
}

compute_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_95_estimate(param_data = ind_param_data))
  
  return(param_range)
}

##generate figure showing density distributions if gamma_fizxd at N = 500 and N = 1000 with middle 95% area shaded. Emphasize
##that longer error bars in  N = 1000 are likely a statistical artifact of the random number generating procedure. 
exp_1 <- read_csv('data/exp_1_data.csv') %>% filter(code == 0) #load data 
exp_1 <- convert_raw_var_to_sd(raw_data = exp_1) #var to sd conversion 

parameter_names <- c(bquote(expr = bold(A:~gamma[random]~"("~beta[fixed]~" = 80, NM = 5)")),
                     quote(expr = bold(B:~gamma[random]~"("~beta[fixed]~" = 180, NM = 5)")),
                     bquote(expr = bold(C:~gamma[random]~"("~beta[fixed]~" = 280, NM = 5)")))

                     
#1) Extract estimates for four parameter gamma_fixed and beta_rand when N =500 or 1000, num_measurements == 5, spacing == equal. 
##Convert to long format, with parameter name going into unique column and estimate becoming new column 
 param_data <- exp_1 %>%
  filter(number_measurements == 5, measurement_spacing == 'equal') %>%
  select(locate_ivs(exp_1),'gamma_rand') %>%
  pivot_longer(cols = c(gamma_rand), values_to = 'estimate') %>%
  unite(col = 'parameter', c(midpoint,name)) #%>%
  #filter(estimate < 45)

#2) Replace parameter values with tag labels. 
param_data$parameter <- factor(param_data$parameter, 
                               levels = c("80_gamma_rand", "180_gamma_rand", "280_gamma_rand"), 
                               labels = parameter_names)


#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
density_data <- ggplot_build(plot = base_density_plot)$data[[1]]

param_search_names <- c("A\\:", "B\\:", "C\\:")

param_error_bar_ranges <- lapply(X = param_search_names, compute_ind_param_error_bar_range, param_data = param_data)


##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


example_plot <- base_density_plot +
  scale_x_continuous(limits = c(0, 50), breaks = seq(from = 0, to = 50, by = 10), 
                       name = 'Value of Parameter Estimate (Days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
  
  facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 3,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,scale_y_continuous(name =  'Density (Proportion of Estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (Proportion of Estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))), 
                                                                 scale_override(3, scale_y_continuous(name = 'Density (Proportion of Estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
    
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 75, margin = unit(c(t = 0, r = 20, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  #create PDF of faceted plot
 set_panel_size(p = example_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_equal_gamma_exp1.pdf')
 
 #set_panel_size(p = example_plot, height = unit(x = 28, units = 'cm'),
 #               width = unit(x = 40, units = 'cm'),
 #               file =  'Figures/density_plots_equal_gamma_filtered_exp1.pdf')
```


```{=tex}
\begin{figure} [H]
  \caption{Density Plots of the Random-Effect Halfway-Triquarter Delta ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_equal}D) With Equal Spacing in Experiment 1 (95\% Error Bars)}
  \label{fig:density_gamma_equal}
  \includegraphics[height = 15cm, width = 25cm]{Figures/density_plots_equal_gamma_exp1} \newline
  \figurefootnote{Regions shaded in in gray represent the the middle 95\% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. The error bar length if longest when the nature-of-change value is 180. $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter, with population value of 4.00, NM = number of measurements.}
\end{figure}
```

```{r equal-gamma-outlier, echo=F}
##generate figure showing density distributions if gamma_fizxd at N = 500 and N = 1000 with middle 95% area shaded. Emphasize
##that longer error bars in  N = 1000 are likely a statistical artifact of the random number generating procedure. 
exp_1 <- read_csv('data/exp_1_data.csv') %>% filter(code == 0) #load data 
exp_1 <- convert_raw_var_to_sd(raw_data = exp_1) #var to sd conversion 


equal_gamma <- exp_1 %>%
  filter(number_measurements == 5, measurement_spacing == 'equal') %>%
  select(locate_ivs(exp_1),'gamma_rand') %>%
  pivot_longer(cols = c(gamma_rand), values_to = 'estimate') %>%
  unite(col = 'parameter', c(midpoint,name))

table_ready <- equal_gamma %>% 
  group_by(parameter) %>%
  summarize(`Number of Maximum-Value Estimates`= sum(estimate == 45)) %>%
  separate(col = parameter, into = c('Nature-of-Change Value', 'Parameter'), extra = 'drop') %>%
  select(Parameter, `Nature-of-Change Value`, `Number of Maximum-Value Estimates`) %>% 
  arrange(as.numeric(`Nature-of-Change Value`))

table_ready$Parameter <- c('$\\upgamma_{random}$ (Figure \\ref{fig:density_gamma_equal}A)', 
                           '$\\upgamma_{random}$ (Figure \\ref{fig:density_gamma_equal}B)', 
                           '$\\upgamma_{random}$ (Figure \\ref{fig:density_gamma_equal}C)')


kbl(x = table_ready, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
       align = c('l', rep('c', times = ncol(table_ready) - 1)),
    caption = 'Number of Number of Maximum-Value Estimates Obtained for $\\upgamma_{random}$ With Each Nature-of-Change Value Under Equal Spacing in Experiment 1') %>%
    #header
  column_spec(column = 1, width = '4cm') %>%
 column_spec(column = 2, width = '5cm') %>%
   column_spec(column = 3, width = '8cm') %>%

  footnote(escape = F, threeparttable = T, general_title = '\\\\textit{Note.}\\\\hspace{-1.1pc}',
           general = " $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter, with population value of 4. The maximum $\\\\upgamma_{random}$ value is 45.00.") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')

```

```{=tex}
\begin{figure} [H]
  \caption{Density Plots of $\upgamma_{random}$ (Figure \ref{fig:exp1_plot_equal}D) With Equal Spacing in Experiment 1 (95\% Error Bars With Maximum-Value Estimates Removed)}
  \label{fig:density_gamma_equal_fixed}
  \includegraphics[height = 15cm, width = 25cm]{Figures/density_plots_equal_gamma_filtered_exp1} \newline
  \figurefootnote{Regions shaded in in gray represent the the middle 95\% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. Maximum-value estimates correspond to $\upgamma_{random}$ estiamtes of 45.00. $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter, with population value of 4.00 and NM = number of measurements. Maximum-value estimates of $\upgamma_{random}$ have a value of 45.00.}
\end{figure}
```
# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```
