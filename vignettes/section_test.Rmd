---
shorttitle        : "Measurement timing"
format          : "pandoc"
header-includes:
  - \usepackage{nccmath}
  - \usepackage{caption}
  - \usepackage{textcomp} #for copyright symbol on title page
  - \usepackage{longtable}
  - \usepackage{setspace}
  - \usepackage{biblatex}
  - \usepackage{booktabs}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
  - \usepackage{amsthm} 
  - \usepackage{amsmath} ##needed for argmax
  - \DeclareMathOperator*{\argmax}{arg\,max}
  - \usepackage{setspace} #needed to doublespace caption text (using \doublespacing)
  - \usepackage[labelfont = {bf, up}]{caption} 
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \usepackage{upgreek}  #required for non-italicized Greek letters
  - \usepackage{subcaption}
  - \captionsetup[figure]{labelfont={normalfont, bf}, singlelinecheck=false, labelsep=newline}
  - \DeclareCaptionJustification{double}{\DoubleSpacing}
  - \DeclareCaptionFont{figCaptionFont}{\fontfamily{phv}} #sets caption font to sans serif font of Helvetica 
  - \DeclareCaptionFont{figCaptionSize}{\footnotesize} #set caption font size to footnote 
  - \DeclareCaptionFont{figCaptionStyle}{\textup}  #set caption font to non-italicized font  
  - \DeclareCaptionLabelSeparator{captionSep}{\newline\newline} #separates figure label and figure title with required white space
  - \captionsetup[figure]{labelfont={figCaptionStyle, bf}, font = {figCaptionFont,figCaptionSize, figCaptionStyle}, labelsep = captionSep, justification=raggedright}
  - \captionsetup[table]{font = {figCaptionFont,figCaptionSize,figCaptionStyle}, labelfont={bf}, labelsep=captionSep, justification = raggedright, margin = {0cm,0cm}}
  - \newenvironment{helvenv}{\fontfamily{phv}\selectfont}{}
  - \raggedbottom #ensures text starts from top of page and any white space is at the botom

#environment numbering 
  - \setcounter{section}{0} 
  - \makeatletter \renewcommand\thesection{} \renewcommand\thesubsection{\@arabic\c@section.\@arabic\c@subsection} \makeatother
  
  - \newtheorem{theorem}{Theorem}
  - \newtheorem{example}[theorem]{Example}
  

  #modifies heading levels of 4-5 to follow apa7
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

  
author: 
  - name          : "Sebastian Sciarra "
    affiliation   : "1"
    corresponding : yes    
    email         : "ssciarra@uoguelph.ca"
affiliation: 
  - id            : "1"
    institution   : "University of Guelph"
keywords          : "measurement timing, nonlinear "
wordcount         : "5554 words"
floatsintext      : yes
linkcolor         : blue
figsintext        : yes 
figurelist        : no
tablelist         : no
footnotelist      : no
numbersections    : yes
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa7"
csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  markdown: 
    wrap: 72
bibliography: dissertation_references.bib
---

```{r package_loading, include=F}
#load packages
library(easypackages)
packages <- c('devtools','tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'nonlinSims','papaja', 
              'ggbrace', 'cowplot')
libraries(packages)
load_all()
```

```{r knitting_setup, echo=F, message = F, warning = F}
#import raw data files (needed for computing variances)
exp_1_raw <- convert_raw_var_to_sd(raw_data = read_csv('data/exp_1_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)
  
exp_2_raw <-convert_raw_var_to_sd(raw_data = read_csv('data/exp_2_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "sample_size"), factor)

exp_3_raw <-convert_raw_var_to_sd(raw_data = read_csv('data/exp_3_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)

#unfiltered data 
param_summary_exp_1 <- readRDS(file = 'data/uf_param_summary_exp_1.RData')
param_summary_exp_2 <- readRDS(file = 'data/uf_param_summary_exp_2.RData')
param_summary_exp_3 <- readRDS(file = 'data/uf_param_summary_exp_3.RData')

#create analytical versions of summary data + converts vars to sds
exp_1_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1, exp_num = '1')
exp_2_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_2, exp_num = '2')
exp_3_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3, exp_num = '3')

combined_analytical_exp_1 <- rbind(exp_1_analytical$likert, exp_1_analytical$days)
combined_analytical_exp_2 <- rbind(exp_2_analytical$likert, exp_2_analytical$days)
combined_analytical_exp_3 <- rbind(exp_3_analytical$likert, exp_3_analytical$days)

#create condition summary data sets 
cond_summary_exp_1 <- compute_condition_summary(param_summary_data = combined_analytical_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))
cond_summary_exp_2 <- compute_condition_summary(param_summary_data = combined_analytical_exp_2, facet_var = 'measurement_spacing', 
                  ind_vars = c('number_measurements', 'measurement_spacing', 'sample_size'))

cond_summary_exp_3 <- compute_condition_summary(param_summary_data = combined_analytical_exp_3, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))
```


```{r pre_knitting_setup_unfiltered, echo=F, eval=F, include=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_data.csv')
exp_2 <- read_csv(file = 'data/exp_2_data.csv')
exp_3 <- read_csv(file = 'data/exp_3_data.csv')

#compute parameter summary statistics  
param_summary_exp_1 <- compute_parameter_summary(data = exp_1, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3, exp_num = 3)

#necessary factor conversions 
param_summary_exp_1$number_measurements <- factor(param_summary_exp_1$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_1$midpoint <- factor(param_summary_exp_1$midpoint, levels = c(80, 180,280))

param_summary_exp_2$number_measurements <- factor(param_summary_exp_2$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_2$sample_size <- factor(param_summary_exp_2$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

param_summary_exp_3$number_measurements <- factor(param_summary_exp_3$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_3$sample_size <- factor(param_summary_exp_3$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/uf_param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_2, file = 'data/uf_param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/uf_param_summary_exp_3.RData')
```

```{r pre_knitting_setup, echo=F, eval=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_data.csv')  
exp_2 <- read_csv(file = 'data/exp_2_data.csv')
exp_3 <- read_csv(file = 'data/exp_3_data.csv')

#data cleaning procedure for each data set
#filter out values for each parameter in each condition 
exp_1_filtered <- remove_outliers(data = exp_1)
exp_2_filtered <- remove_outliers(data = exp_2)
exp_3_filtered <- remove_outliers(data = exp_3)
  
#convert variance values to SD values for random effect parameters 
exp_1_cleaned <- convert_var_to_sd(param_summary_datadata = exp_1_filtered)
exp_2_cleaned <- convert_var_to_sd(data = exp_2_filtered)
exp_3_cleaned <- convert_var_to_sd(data = exp_3_filtered)

#compute summary values 
param_summary_exp_1 <- compute_parameter_summary(data = exp_1_cleaned, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2_cleaned, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3_cleaned, exp_num = 3)

#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_2, file = 'data/param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/param_summary_exp_3.RData')
```

```{r obsolete_metadata_storing_importing, eval=F, include=F}
##store classes of each column 
col_types_exp_1 <- unlist(lapply(X = param_summary_exp_1, FUN = class))
col_types_exp_2 <- unlist(lapply(X = param_summary_exp_2, FUN = class))
col_types_exp_3 <- unlist(lapply(X = param_summary_exp_3, FUN = class))

#create data.frame that stores classes of data columns 
col_types_df <- data.frame('exp_num' = c(rep(x = 1, times = length(col_types_exp_1)),
                                         rep(x = 2, times = length(col_types_exp_2)),
                                         rep(x = 3, times = length(col_types_exp_3))), 
                           'variable_types' = c(col_types_exp_1, col_types_exp_2, col_types_exp_3))

#create data fame that stores levels of factor variables 
exp_1_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_1)
exp_2_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_2)
exp_3_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_3)

##store classes of each column 
col_types_exp_1 <- unlist(lapply(X = param_summary_exp_1, FUN = class))
col_types_exp_2 <- unlist(lapply(X = param_summary_exp_2, FUN = class))
col_types_exp_3 <- unlist(lapply(X = param_summary_exp_3, FUN = class))

#create data.frame that stores classes of data columns 
col_types_df <- data.frame('exp_num' = c(rep(x = 1, times = length(col_types_exp_1)),
                                         rep(x = 2, times = length(col_types_exp_2)),
                                         rep(x = 3, times = length(col_types_exp_3))), 
                           'variable_types' = c(col_types_exp_1, col_types_exp_2, col_types_exp_3))

#create data fame that stores levels of factor variables 
exp_1_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_1)
exp_2_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_2)
exp_3_factor_levels <- extract_factor_levels(param_summary_data = param_summary_exp_3)

#write meta data + data for factor levels 
write_csv(x = col_types_df, file = 'data/col_types.csv')
write_csv(x = exp_1_factor_levels, file = 'data/exp_1_factor_levels.csv')
write_csv(x = exp_2_factor_levels, file = 'data/exp_2_factor_levels.csv')
write_csv(x = exp_3_factor_levels, file = 'data/exp_3_factor_levels.csv')

#read in .csv files with experimental data already in summarized version 
col_types_df <-read_csv(file = 'data/col_types.csv')
exp_1_factor_levels <- read_csv(file = 'data/exp_1_factor_levels.csv')
exp_2_factor_levels <- read_csv(file = 'data/exp_2_factor_levels.csv')
exp_3_factor_levels <- read_csv(file = 'data/exp_3_factor_levels.csv')

#relevel factors columns 
param_summary_exp_1 <- relevel_factors(param_summary_data = param_summary_exp_1, factor_levels_df = exp_1_factor_levels)
param_summary_exp_2 <- relevel_factors(param_summary_data = param_summary_exp_2, factor_levels_df = exp_2_factor_levels)
param_summary_exp_3 <- relevel_factors(param_summary_data = param_summary_exp_3, factor_levels_df = exp_3_factor_levels)
```


### Experiment 1

```{r eval=F, echo=F}
pop_values <- list('theta_fixed' = 3.00, 
                   'alpha_fixed' = 3.32, 
                   'beta_fixed' = 180, 
                   'gamma_fixed' = 20, 
                   'theta_rand' = 0.05, 
                   'alpha_rand' = 0.05, 
                   'beta_rand' = 10, 
                   'gamma_rand' = 4) 



errorbar_data <- generate_errorbar_data(param_summary_data = param_summary_exp_1, bias_col_num = 5, wide_var = 'midpoint', first_col = 'measurement_spacing', second_col = 'number_measurements')

 #identify columns that contain parameter estimate information by finding column names with numbers in them
  parameter_estimate_index <- which(str_detect(string = names(p_est_data), pattern = '\\d'))

  for (col_number in parameter_estimate_index) {

    pop_value_index <- str_detect(pattern = names(pop_values), string = names(p_est_data)[5])
    print(pop_values[pop_value_index])
    ##escape = FALSE so that latex code can be interpreted by compiler
    ##notice use of [[]] for indexing
#    p_est_data[[col_number]] <- cell_spec(x = format(round(p_est_data[[col_number]], digits = 2), nsmall = 2),
#                                                  background = ifelse(test = abs(errorbar_data[[col_number]]) > #.2*as.numeric(pop_values[pop_value_index]),
#                                                                      yes = '#8cb9e3', no = '#ffffff'),
#                                                  format = 'latex', escape = F)
  }
  

#reference data set in numeric form 
p_est_data_num <- generate_parameter_est_data(param_summary_data = param_summary_exp_1, bias_col_num = 5, wide_var = 'midpoint', first_col = 'measurement_spacing', second_col = 'number_measurements')

#data set that will be modified for kable table (estimate columns will be converted to character as code loops through columns) 
p_est_data_char <- generate_parameter_est_data(param_summary_data = param_summary_exp_1, bias_col_num = 5, wide_var = 'midpoint', first_col = 'measurement_spacing', second_col = 'number_measurements')

format(round(p_est_data_char[[5]], digits = 2), nsmall = 2)

p_est_data_char$est_theta_fixed_midpoint80 <- as.character(p_est_data_char$est_theta_fixed_midpoint80)

ifelse(test = p_est_data_num$est_theta_fixed_midpoint80 > 3, yes = str_c(p_est_data_num$est_theta_fixed_midpoint80, '^\\square', sep = ''), no = str_c(p_est_data_num$est_theta_fixed_midpoint80))


#append superscript square to 

  

```


```{r exp-table-generation, echo=F}
exp_1_tables <- create_table_data_sets(param_summary_data = param_summary_exp_1, 
                                       wide_var = 'midpoint', first_col = 'measurement_spacing', second_col = 'number_measurements')

exp_2_tables <- create_table_data_sets(param_summary_data = param_summary_exp_2, 
                                       wide_var = 'sample_size', first_col = 'measurement_spacing', second_col = 'number_measurements')

exp_3_tables <- create_table_data_sets(param_summary_data = param_summary_exp_3, 
                                       wide_var = 'sample_size', first_col = 'time_structuredness', second_col = 'number_measurements') 

#remove measurement spacing columns 
col_to_remove <- which(str_detect(string = names(exp_3_tables$estimate_table), pattern = 'measurement_spacing'))

exp_3_tables$estimate_table <- exp_3_tables$estimate_table[, -col_to_remove]
exp_3_tables$removed_value_table <- exp_3_tables$removed_value_table[ , -col_to_remove]
```

\renewcommand{\arraystretch}{0.7}{0.8}

```{r exp1-alpha-theta-param-est, echo=F}
usepackage_latex('makecell')

print_param_table(table_ready_data = exp_1_tables$estimate_table, parameter_name = 'theta|alpha', 
            caption_name = 'Parameter Values Estimated in Experiment 1', 
            col_header_name = c('\\\\thead{$\\\\uptheta_{fixed}$ (Baseline)  \\\\\\\\ Pop Value = 3.00}', 
                                '\\\\thead{$\\\\uptheta_{random}$ (Baseline) \\\\\\\\ Pop Value = 0.05}',
                                '\\\\thead{$\\\\upalpha_{fixed}$ (Maximal \\\\\\\\ Elevation)  \\\\\\\\ Pop Value = 3.32}', 
                                '\\\\thead{$\\\\upalpha_{random}$ (Maximal \\\\\\\\ Elevation) \\\\\\\\ Pop Value = 0.05}'), 
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c('80', '180', '280'))
```

\addtocounter{table}{-1}

```{r exp1-beta-gamma-param-est, echo=F}
print_param_table(table_ready_data = exp_1_tables$estimate_table, parameter_name = 'beta|gamma', 
            caption_name = 'Parameter Values Estimated in Experiment 1 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upbeta_{fixed}$ (Days to \\\\\\\\ Halfway Elevation)}', 
                                '\\\\thead{$\\\\upbeta_{random}$ (Days to \\\\\\\\ Halfway Elevation) \\\\\\\\ Pop Value = 10.00}', 
                                '\\\\thead{$\\\\upgamma_{fixed}$ (Triquarter- \\\\\\\\ Halfway Delta) \\\\\\\\ Pop Value = 20.00}', 
                                '\\\\thead{$\\\\upgamma_{random}$ (Triquarter- \\\\\\\\ Halfway Delta) \\\\\\\\ Pop Value = 4.00}'),
             IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c(80, 180, 280))
```

\addtocounter{table}{-1}
```{r exp1-epsilon-param-est, echo=F}
print_param_table(table_ready_data = exp_1_tables$estimate_table, parameter_name = 'epsilon', 
            caption_name = 'Parameter Values Estimated in Experiment 1 (continued)', 
            col_header_name = c('\\\\thead{$\\\\upepsilon$(error) \\\\\\\\ Pop value = 0.05}'),
            IV_names =  c('Measurement Spacing', 'Number of Measurements'), 
            column_names = c(80, 180, 280))
```



# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```

